<!DOCTYPE html>
<!-- saved from url=(0075)https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the -->
<html lang="en" class="" style="background: rgb(255, 255, 255);"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        
        <meta name="norton-safeweb-site-verification" content="24usqpep0ejc5w6hod3dulxwciwp0djs6c6ufp96av3t4whuxovj72wfkdjxu82yacb7430qjm8adbd5ezlt4592dq4zrvadcn9j9n-0btgdzpiojfzno16-fnsnu7xd">
        
        <link rel="preconnect" href="https://substackcdn.com/">
        

        

        

        <style>
          @layer legacy, tailwind, pencraftReset, pencraft;
        </style>

        
        <link rel="preload" as="style" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/main.88280fc045592e54bb5e.css">
        
        
        

        
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5340.e1c57fe5.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1832.1f3239f5.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/main.b8ef093a.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9335.1cd242d9.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1481.8fbd7ad5.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9294.03de8b18.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5758.602fd321.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1333.27122476.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7294.aabc06b7.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6364.9c2db661.css">
            
                <link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3191.f2f22825.css">
            
        

        
        
        
        
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0, viewport-fit=cover">
        <meta name="author" content="Sebastian Raschka, PhD">
        <meta property="og:url" content="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the">
        <title>From GPT-2 to gpt-oss: Analyzing the Architectural Advances</title>
        
        <link rel="canonical" href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the">
        

        

        

        
            
                <link rel="shortcut icon" href="https://substackcdn.com/image/fetch/$s_!H1CS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Ffavicon.ico">
            
        
            
                <link rel="icon" type="image/png" sizes="16x16" href="https://substackcdn.com/image/fetch/$s_!fDFi!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Ffavicon-16x16.png">
            
        
            
                <link rel="icon" type="image/png" sizes="32x32" href="https://substackcdn.com/image/fetch/$s_!flCl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Ffavicon-32x32.png">
            
        
            
                <link rel="icon" type="image/png" sizes="48x48" href="https://substackcdn.com/image/fetch/$s_!ktrK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Ffavicon-48x48.png">
            
        
            
                <link rel="apple-touch-icon" sizes="57x57" href="https://substackcdn.com/image/fetch/$s_!_bhP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-57x57.png">
            
        
            
                <link rel="apple-touch-icon" sizes="60x60" href="https://substackcdn.com/image/fetch/$s_!Ilxb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-60x60.png">
            
        
            
                <link rel="apple-touch-icon" sizes="72x72" href="https://substackcdn.com/image/fetch/$s_!AKdi!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-72x72.png">
            
        
            
                <link rel="apple-touch-icon" sizes="76x76" href="https://substackcdn.com/image/fetch/$s_!MbC4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-76x76.png">
            
        
            
                <link rel="apple-touch-icon" sizes="114x114" href="https://substackcdn.com/image/fetch/$s_!R5rH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-114x114.png">
            
        
            
                <link rel="apple-touch-icon" sizes="120x120" href="https://substackcdn.com/image/fetch/$s_!naEp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-120x120.png">
            
        
            
                <link rel="apple-touch-icon" sizes="144x144" href="https://substackcdn.com/image/fetch/$s_!kvAt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-144x144.png">
            
        
            
                <link rel="apple-touch-icon" sizes="152x152" href="https://substackcdn.com/image/fetch/$s_!5uKp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-152x152.png">
            
        
            
                <link rel="apple-touch-icon" sizes="167x167" href="https://substackcdn.com/image/fetch/$s_!HPVF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-167x167.png">
            
        
            
                <link rel="apple-touch-icon" sizes="180x180" href="https://substackcdn.com/image/fetch/$s_!oGr3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-180x180.png">
            
        
            
                <link rel="apple-touch-icon" sizes="1024x1024" href="https://substackcdn.com/image/fetch/$s_!VgZ6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F342e39ec-514c-4b4d-8a76-6acf0cbd8248%2Fapple-touch-icon-1024x1024.png">
            
        
            
        
            
        
            
        

        

        
            <link rel="alternate" type="application/rss+xml" href="https://magazine.sebastianraschka.com/feed" title="Ahead of AI">
        

        
        
        

        <style>:root{--color_theme_bg_pop:#c5030c;--background_pop:#c5030c;--cover_bg_color:#FFFFFF;--background_pop_darken:#ac030a;--print_on_pop:#ffffff;--color_theme_bg_pop_darken:#ac030a;--color_theme_print_on_pop:#ffffff;--color_theme_bg_pop_20:rgba(197, 3, 12, 0.2);--color_theme_bg_pop_30:rgba(197, 3, 12, 0.3);--border_subtle:rgba(204, 204, 204, 0.5);--background_subtle:rgba(246, 217, 219, 0.4);--print_pop:#c5030c;--color_theme_accent:#c5030c;--cover_print_primary:#363737;--cover_print_secondary:#757575;--cover_print_tertiary:#b6b6b6;--cover_border_color:#c5030c;--font_family_body_preset:'SF Pro Display', -apple-system, system-ui, BlinkMacSystemFont, 'Inter', 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';--font_weight_body_preset:400;--font_preset_body:sans;--home_hero:newspaper;--home_posts:custom;--home_show_top_posts:true;--web_bg_color:#ffffff;--background_contrast_1:#f0f0f0;--color_theme_bg_contrast_1:#f0f0f0;--background_contrast_2:#dddddd;--color_theme_bg_contrast_2:#dddddd;--background_contrast_3:#b7b7b7;--color_theme_bg_contrast_3:#b7b7b7;--background_contrast_4:#929292;--color_theme_bg_contrast_4:#929292;--background_contrast_5:#515151;--color_theme_bg_contrast_5:#515151;--color_theme_bg_elevated:#ffffff;--color_theme_bg_elevated_secondary:#f0f0f0;--color_theme_detail:#e6e6e6;--background_contrast_pop:rgba(197, 3, 12, 0.4);--color_theme_bg_contrast_pop:rgba(197, 3, 12, 0.4);--input_background:#ffffff;--cover_input_background:#ffffff;--tooltip_background:#191919;--web_bg_color_h:0;--web_bg_color_s:0%;--web_bg_color_l:100%;--print_on_web_bg_color:#363737;--print_secondary_on_web_bg_color:#868787;--selected_comment_background_color:#fdf9f3;--background_pop_rgb:197, 3, 12;--background_pop_rgb_pc:197 3 12;--color_theme_bg_pop_rgb:197, 3, 12;--color_theme_bg_pop_rgb_pc:197 3 12;--color_theme_accent_rgb:197, 3, 12;--color_theme_accent_rgb_pc:197 3 12;}</style>

        
            <link rel="stylesheet" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/main.88280fc045592e54bb5e.css">
        

        <style></style>

        

        

        

        
            <script async="" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/js(2)"></script><script async="" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/datadog-rum.js.download"></script><script async="true" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/js(3)">
            </script>
        
    <style type="text/css">/*
  code is extracted from Calendly's embed stylesheet: https://assets.calendly.com/assets/external/widget.css
*/

.calendly-inline-widget,
.calendly-inline-widget *,
.calendly-badge-widget,
.calendly-badge-widget *,
.calendly-overlay,
.calendly-overlay * {
    font-size:16px;
    line-height:1.2em
}

.calendly-inline-widget iframe,
.calendly-badge-widget iframe,
.calendly-overlay iframe {
    display:inline;
    width:100%;
    height:100%
}

.calendly-popup-content {
    position:relative
}

.calendly-popup-content.calendly-mobile {
    -webkit-overflow-scrolling:touch;
    overflow-y:auto
}

.calendly-overlay {
    position:fixed;
    top:0;
    left:0;
    right:0;
    bottom:0;
    overflow:hidden;
    z-index:9999;
    background-color:#a5a5a5;
    background-color:rgba(31,31,31,0.4)
}

.calendly-overlay .calendly-close-overlay {
    position:absolute;
    top:0;
    left:0;
    right:0;
    bottom:0
}

.calendly-overlay .calendly-popup {
    box-sizing:border-box;
    position:absolute;
    top:50%;
    left:50%;
    -webkit-transform:translateY(-50%) translateX(-50%);
    transform:translateY(-50%) translateX(-50%);
    width:80%;
    min-width:900px;
    max-width:1000px;
    height:90%;
    max-height:680px
}

@media (max-width: 975px) {
    .calendly-overlay .calendly-popup {
        position:fixed;
        top:50px;
        left:0;
        right:0;
        bottom:0;
        -webkit-transform:none;
        transform:none;
        width:100%;
        height:auto;
        min-width:0;
        max-height:none
    }
}

.calendly-overlay .calendly-popup .calendly-popup-content {
    height:100%;
}

.calendly-overlay .calendly-popup-close {
    position:absolute;
    top:25px;
    right:25px;
    color:#fff;
    width:19px;
    height:19px;
    cursor:pointer;
    background:url(https://assets.calendly.com/assets/external/close-icon.svg) no-repeat;
    background-size:contain
}

@media (max-width: 975px) {
    .calendly-overlay .calendly-popup-close {
        top:15px;
        right:15px
    }
}

.calendly-badge-widget {
    position:fixed;
    right:20px;
    bottom:15px;
    z-index:9998
}

.calendly-badge-widget .calendly-badge-content {
    display:table-cell;
    width:auto;
    height:45px;
    padding:0 30px;
    border-radius:25px;
    box-shadow:rgba(0,0,0,0.25) 0 2px 5px;
    font-family:sans-serif;
    text-align:center;
    vertical-align:middle;
    font-weight:bold;
    font-size:14px;
    color:#fff;
    cursor:pointer
}

.calendly-badge-widget .calendly-badge-content.calendly-white {
    color:#666a73
}

.calendly-badge-widget .calendly-badge-content span {
    display:block;
    font-size:12px
}

.calendly-spinner {
    position:absolute;
    top:50%;
    left:0;
    right:0;
    -webkit-transform:translateY(-50%);
    transform:translateY(-50%);
    text-align:center;
    z-index:-1
}

.calendly-spinner>div {
    display:inline-block;
    width:18px;
    height:18px;
    background-color:#e1e1e1;
    border-radius:50%;
    vertical-align:middle;
    -webkit-animation:calendly-bouncedelay 1.4s infinite ease-in-out;
    animation:calendly-bouncedelay 1.4s infinite ease-in-out;
    -webkit-animation-fill-mode:both;
    animation-fill-mode:both
}

.calendly-spinner .calendly-bounce1 {
    -webkit-animation-delay:-0.32s;
    animation-delay:-0.32s
}

.calendly-spinner .calendly-bounce2 {
    -webkit-animation-delay:-0.16s;
    animation-delay:-0.16s
}

@-webkit-keyframes calendly-bouncedelay {
    0%,80%,100% {
        -webkit-transform:scale(0);
        transform:scale(0)
    } 
    
    40%{
        -webkit-transform:scale(1);
        transform:scale(1)
    }
}

@keyframes calendly-bouncedelay{ 
    0%,80%,100% {
        -webkit-transform:scale(0);
        transform:scale(0)
    }
    
    40% {
        -webkit-transform:scale(1);
        transform:scale(1)
    }
}</style><meta property="og:type" content="article" data-preact-helmet="true"><meta name="theme-color" content="#ffffff" data-preact-helmet="true"><meta name="twitter:card" content="summary_large_image" data-preact-helmet="true"><link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4918.b663e246.css"><link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3280.8db3c09e.css"><script type="text/javascript" async="" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/f(2).txt"></script><meta property="og:title" content="From GPT-2 to gpt-oss: Analyzing the Architectural Advances" data-preact-helmet="true"><meta name="twitter:title" content="From GPT-2 to gpt-oss: Analyzing the Architectural Advances" data-preact-helmet="true"><meta name="description" content="And How They Stack Up Against Qwen3" data-preact-helmet="true"><meta property="og:description" content="And How They Stack Up Against Qwen3" data-preact-helmet="true"><meta name="twitter:description" content="And How They Stack Up Against Qwen3" data-preact-helmet="true"><meta property="og:image" content="https://substackcdn.com/image/fetch/$s_!kftt!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F529c4cc7-161c-4d7c-b186-06e68c771776_1564x926.png" data-preact-helmet="true"><meta name="twitter:image" content="https://substackcdn.com/image/fetch/$s_!AoSP!,f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fsebastianraschka.substack.com%2Fapi%2Fv1%2Fpost_preview%2F170506328%2Ftwitter.jpg%3Fversion%3D4" data-preact-helmet="true"><meta property="interactionStatistic" content="[{&quot;@type&quot;:&quot;InteractionCounter&quot;,&quot;interactionType&quot;:&quot;https://schema.org/LikeAction&quot;,&quot;userInteractionCount&quot;:563},{&quot;@type&quot;:&quot;InteractionCounter&quot;,&quot;interactionType&quot;:&quot;https://schema.org/CommentAction&quot;,&quot;userInteractionCount&quot;:45}]" data-preact-helmet="true"><link rel="stylesheet" type="text/css" href="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9290.a028dfa8.css"></head>

    <body class=" ">
        

        

        

        

        

        

        <div id="entry"><iframe src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/channel-frame.html" width="0" height="0" class="channel-frame"></iframe><iframe src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/session-attribution-frame.html" width="0" height="0" class="visitedSurfacesIFrame-yy8AJL"></iframe><div id="main" class="main typography use-theme-bg"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div data-testid="navbar" class="main-menu"><div class="mainMenuContent-DME8DR" style="position: fixed;"><div style="position: relative; height: 87px;" class="pencraft pc-display-flex pc-gap-12 pc-paddingLeft-20 pc-paddingRight-20 pc-justifyContent-space-between pc-alignItems-center pc-reset border-bottom-detail-k1F6C4 topBar-pIF0J1"><div style="flex-basis: 0px; flex-grow: 1;" class="logoContainer-p12gJb"><a href="https://magazine.sebastianraschka.com/" native="true" class="pencraft pc-display-contents pc-reset"><div draggable="false" class="pencraft pc-display-flex pc-position-relative pc-reset"><div style="width: 40px; height: 40px;" class="pencraft pc-display-flex pc-reset bg-white-ZBV5av pc-borderRadius-sm overflow-hidden-WdpwT6 sizing-border-box-DggLA4"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!96vs!,w_80,h_80,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png" sizes="100vw" alt="Ahead of AI" width="80" height="80" style="width: 40px; height: 40px;" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div><div style="flex-grow: 0;" class="titleContainer-DJYq5v"><h1 class="pencraft pc-reset font-pub-headings-FE5byy reset-IxiVJZ title-oOnUGd titleWithWordmark-GfqxEZ"><a href="https://magazine.sebastianraschka.com/" class="pencraft pc-display-contents pc-reset"><img alt="Ahead of AI" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/https___substack-post-media.s3.amazonaws.com_public_images_5083e6d3-fbc9-4870-95b9-6e85d02f62a6_9366x2023.png" style="display: block; height: 36px;"></a></h1></div><div style="flex-basis: 0px; flex-grow: 1;" class="pencraft pc-display-flex pc-justifyContent-flex-end pc-alignItems-center pc-reset"><div class="buttonsContainer-SJBuep"><div class="pencraft pc-display-flex pc-gap-8 pc-justifyContent-flex-end pc-alignItems-center pc-reset navbar-buttons"><div class="pencraft pc-display-flex pc-gap-4 pc-reset"><span><button type="button" aria-label="Search" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></span><button type="button" aria-label="View more" id="trigger1" aria-expanded="false" aria-haspopup="dialog" aria-controls="dialog2" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg></button></div><button type="button" data-testid="noncontributor-cta-button" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_primary-RfbeYt size_md-gCDS3o" tabindex="0">Upgrade to paid</button><button type="button" native="true" data-href="https://substack.com/sign-in?redirect=%2Fp%2Ffrom-gpt-2-to-gpt-oss-analyzing-the&amp;for_pub=sebastianraschka" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_tertiary-rlke8z size_md-gCDS3o" tabindex="0">Sign in</button></div></div></div></div></div><div style="height: 88px;"></div></div></div><div><script type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","url":"https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the","mainEntityOfPage":"https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the","headline":"From GPT-2 to gpt-oss: Analyzing the Architectural Advances","description":"And How They Stack Up Against Qwen3","image":[{"@type":"ImageObject","url":"https://substack-post-media.s3.amazonaws.com/public/images/529c4cc7-161c-4d7c-b186-06e68c771776_1564x926.png"}],"datePublished":"2025-08-09T16:53:07+05:30","dateModified":"2025-08-09T16:53:07+05:30","isAccessibleForFree":true,"author":[{"@type":"Person","name":"Sebastian Raschka, PhD","url":"https://substack.com/@rasbt","description":"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \"Build a Large Language Model From Scratch\" (amzn.to/4fqvn0D).","identifier":"user:27393275","sameAs":["https://twitter.com/rasbt"],"image":{"@type":"ImageObject","contentUrl":"https://substackcdn.com/image/fetch/$s_!CfW_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg","thumbnailUrl":"https://substackcdn.com/image/fetch/$s_!CfW_!,w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg"}}],"publisher":{"@type":"Organization","name":"Ahead of AI","url":"https://magazine.sebastianraschka.com","description":"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.","interactionStatistic":{"@type":"InteractionCounter","name":"Subscribers","interactionType":"https://schema.org/SubscribeAction","userInteractionCount":100000},"identifier":"pub:1174659","logo":{"@type":"ImageObject","url":"https://substackcdn.com/image/fetch/$s_!96vs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png","contentUrl":"https://substackcdn.com/image/fetch/$s_!96vs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png","thumbnailUrl":"https://substackcdn.com/image/fetch/$s_!96vs!,w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png"},"image":{"@type":"ImageObject","url":"https://substackcdn.com/image/fetch/$s_!96vs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png","contentUrl":"https://substackcdn.com/image/fetch/$s_!96vs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png","thumbnailUrl":"https://substackcdn.com/image/fetch/$s_!96vs!,w_128,h_128,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png"},"sameAs":["https://twitter.com/rasbt"]}}</script><div aria-label="Post" role="main" class="single-post-container"><div class="container"><div class="single-post"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><article class="typography newsletter-post post"><div role="region" aria-label="Post header" class="post-header"><h1 dir="auto" class="post-title published title-X77sOw">From GPT-2 to gpt-oss: Analyzing the Architectural Advances</h1><h3 dir="auto" class="subtitle subtitle-HEEcLo">And How They Stack Up Against Qwen3</h3><div aria-label="Post UFI" role="region" class="pencraft pc-display-flex pc-flexDirection-column pc-paddingBottom-16 pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-paddingTop-16 pc-paddingBottom-16 pc-reset"><div class="pencraft pc-display-flex pc-gap-12 pc-alignItems-center pc-reset byline-wrapper"><div class="pencraft pc-display-flex pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-row pc-gap-8 pc-alignItems-center pc-justifyContent-flex-start pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-row pc-alignItems-center pc-justifyContent-flex-start pc-reset ltr-qDBmby" style="--scale: 36px; --offset: 9px; --border-width: 4.5px;"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/@rasbt" aria-label="View Sebastian Raschka, PhD&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-36 pc-height-36 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB last-JfNEJ_" style="--scale: 36px;"><div title="Sebastian Raschka, PhD" class="pencraft pc-display-flex pc-width-36 pc-height-36 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 36px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CfW_!,w_36,h_36,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 36w, https://substackcdn.com/image/fetch/$s_!CfW_!,w_72,h_72,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 72w, https://substackcdn.com/image/fetch/$s_!CfW_!,w_108,h_108,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 108w" sizes="36px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpg" sizes="36px" alt="Sebastian Raschka, PhD&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!CfW_!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 36w, https://substackcdn.com/image/fetch/$s_!CfW_!,w_72,h_72,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 72w, https://substackcdn.com/image/fetch/$s_!CfW_!,w_108,h_108,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg 108w" width="36" height="36" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div></div></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><div class="pencraft pc-reset color-pub-primary-text-NyXPlw line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/@rasbt" class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ">Sebastian Raschka, PhD</a></div></div><div class="pencraft pc-display-flex pc-gap-4 pc-reset"><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Aug 09, 2025</div></div></div></div></div><div class="pencraft pc-display-flex pc-gap-16 pc-paddingTop-16 pc-paddingBottom-16 pc-justifyContent-space-between pc-alignItems-center pc-reset flex-grow-rzmknG border-top-detail-themed-k9TZAY border-bottom-detail-themed-Ua9186 post-ufi"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="like-button-container post-ufi-button style-button state-liked"><a role="button" aria-label="Like (564)" aria-pressed="true" class="post-ufi-button style-button state-liked has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><div class="label">564</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><a role="button" href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comments" aria-label="View comments (45)" class="post-ufi-button style-button post-ufi-comment-button has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></g></svg><div class="label">45</div></a><a role="button" class="post-ufi-button style-button has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><path d="M21 3V8M21 8H16M21 8L18 5.29962C16.7056 4.14183 15.1038 3.38328 13.3879 3.11547C11.6719 2.84766 9.9152 3.08203 8.32951 3.79031C6.74382 4.49858 5.39691 5.65051 4.45125 7.10715C3.5056 8.5638 3.00158 10.2629 3 11.9996M3 21V16M3 16H8M3 16L6 18.7C7.29445 19.8578 8.89623 20.6163 10.6121 20.8841C12.3281 21.152 14.0848 20.9176 15.6705 20.2093C17.2562 19.501 18.6031 18.3491 19.5487 16.8925C20.4944 15.4358 20.9984 13.7367 21 12" stroke-linecap="round" stroke-linejoin="round"></path></g></svg><div class="label">52</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><a role="button" href="javascript:void(0)" aria-label="View share options" class="post-ufi-button style-button no-icon has-label with-border"><div class="label">Share</div></a></div></div></div></div><div class="visibility-check"></div><div><button tabindex="0" type="button" aria-label="Table of Contents" class="pencraft pc-position-fixed pc-reset pencraft trigger-V8d1vI fixed-n4RrZu"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-12 pc-paddingLeft-8 pc-paddingRight-8 pc-paddingTop-12 pc-paddingBottom-12 pc-alignItems-flex-end pc-reset"><div class="line-DsYVXw active-Yh0Zwm"></div><div class="line-DsYVXw"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw indent-1-vdeuvl"></div><div class="line-DsYVXw"></div></div></button><div class="available-content"><div dir="auto" class="body markup"><p>OpenAI just released their new open-weight LLMs this week: gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019. And yes, thanks to some clever optimizations, they can run locally (but more about this later).</p><p>This is the first time since GPT-2 that OpenAI has shared a large, fully open-weight model. Earlier GPT models showed how the transformer architecture scales. The 2022 ChatGPT release then made these models mainstream by demonstrating concrete usefulness for writing and knowledge (and later coding) tasks. Now they have shared some long-awaited weight model, and the architecture has some interesting details.</p><p>I spent the past few days reading through the code and technical reports to summarize the most interesting details. (Just days after, OpenAI also announced GPT-5, which I will briefly discuss in the context of the gpt-oss models at the end of this article.)</p><p>Below is a quick preview of what the article covers. For easier navigation, I recommend using the Table of Contents on the left of on the article page.</p><ul><li><p>Model architecture comparisons with GPT-2</p></li><li><p>MXFP4 optimization to fit gpt-oss models onto single GPUs</p></li><li><p>Width versus depth trade-offs (gpt-oss vs Qwen3)</p></li><li><p>Attention bias and sinks</p></li><li><p>Benchmarks and comparisons with GPT-5</p></li></ul><p>I hope you find it informative!</p><h2 class="header-anchor-post"><strong>1. Model Architecture Overview</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§model-architecture-overview" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/model-architecture-overview" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><p>Before we discuss the architecture in more detail, let's start with an overview of the two models, gpt-oss-20b and gpt-oss-120b, shown in Figure 1 below.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!PKaP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!PKaP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 424w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 848w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 1272w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/e804b20e-7196-4529-9ca1-13a946123c7c_1589x734.jpg" width="1456" height="673" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:673,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:248008,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!PKaP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 424w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 848w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 1272w, https://substackcdn.com/image/fetch/$s_!PKaP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe804b20e-7196-4529-9ca1-13a946123c7c_1589x734.png 1456w" sizes="100vw" fetchpriority="high" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 1: The two gpt-oss models side by side.</figcaption></figure></div><p></p><p><span>If you have looked at recent LLM architecture diagrams before, or read my previous </span><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" rel="">Big Architecture Comparison</a><span> article, you may notice that there is nothing novel or unusual at first glance. </span></p><div data-component-name="DigestPostEmbed" class="digestPostEmbed-flwiST"><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" rel="noopener" target="_blank"><div class="pencraft pc-display-flex pc-gap-16 pc-reset"><div class="pencraft pc-reset" style="width: 70px; height: 70px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!83ox!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd72e5a99-1a11-42b7-8831-8f5785ed2bc1_1600x1116.png"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/d72e5a99-1a11-42b7-8831-8f5785ed2bc1_1600x1116.jpg" sizes="100vw" alt="The Big LLM Architecture Comparison" width="140" height="140" class="img-OACg1c smSquare-NGbPBa pencraft pc-reset"></picture></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><h4 class="pencraft pc-reset color-pub-primary-text-NyXPlw line-height-24-jnGwiv font-display-nhmvtD size-20-P_cSRT weight-bold-DmI9lw reset-IxiVJZ">The Big LLM Architecture Comparison</h4><div class="pencraft pc-display-flex pc-gap-4 pc-alignItems-center pc-reset"><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA"><a href="https://substack.com/profile/27393275-sebastian-raschka-phd" class="inheritColor-WetTGJ">Sebastian Raschka, PhD</a></div><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T reset-IxiVJZ">·</div><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Jul 19</div></div><div class="pencraft pc-display-flex pc-gap-16 pc-paddingTop-0 pc-paddingBottom-0 pc-alignItems-center pc-reset"><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" class="pencraft pc-reset align-center-y7ZD4w line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ"><div class="pencraft pc-display-flex pc-gap-8 pc-alignItems-center pc-reset link-HREYZo"><span class="pencraft pc-reset color-accent-BVX_7M line-height-20-t4M0El font-text-qe4AeH size-14-MLPa7j weight-semibold-uqA4FV reset-IxiVJZ">Read full story</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></div></a></div></div></div></a></div><p>This is not surprising, since leading LLM developers tend to use the same base architecture and then apply smaller tweaks. This is pure speculation on my part, but I think this is because</p><ul><li><p>There is significant rotation of employees between these labs.</p></li><li><p><span>We still have not found anything better than the transformer architecture. Even though state space models and text diffusion models exist, as far as I know no one has shown that they perform as well as transformers at this scale. (Most of the comparisons I found focus only on benchmark performance. It is still unclear how well the models handle real-world, multi-turn writing and coding tasks. At the time of writing, the highest-ranking non-purely-transformer-based model on the </span><a href="https://lmarena.ai/leaderboard/text" rel="">LM Arena</a><span> is Jamba, which is a transformer–state space model hybrid, at rank 96. EDIT: </span><a href="https://news.ycombinator.com/item?id=44858076" rel="">Someone kindly pointed out</a><span> that there's a higher-ranking hybrid model: Hunyuan-TurboS at rank 22.)</span></p></li><li><p>Most of the gains likely come from data and algorithm tweaks rather than from major architecture changes.</p></li></ul><p>That being said, there are still many interesting aspects of their design choices. Some are shown in the figure above (while others are not, but we will discuss them later as well). In the rest of this article, I will highlight these features and compare them to other architectures, one at a time.</p><p>I should also note that I am not affiliated with OpenAI in any way. My information comes from reviewing the released model code and reading their technical reports. If you want to learn how to use these models locally, the best place to start is OpenAI's official model hub pages:</p><ul><li><p><a href="https://huggingface.co/openai/gpt-oss-20b" rel="">https://huggingface.co/openai/gpt-oss-20b</a></p></li><li><p><a href="https://huggingface.co/openai/gpt-oss-120b" rel="">https://huggingface.co/openai/gpt-oss-120b</a></p></li></ul><p>The 20B model can run on a consumer GPU with up to 16 GB of RAM. The 120B model can run on a single H100 with 80 GB of RAM or newer hardware. I will return to this later, as there are some important caveats.</p><h2 class="header-anchor-post"><strong>2. Coming From GPT-2</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§coming-from-gpt" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/coming-from-gpt" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><p>Before we jump into comparisons between gpt-oss and a more recent architecture, let's hop into the time machine and take a side-by-side look at GPT-2 (Figure 2) to see just how far things have come.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!-dhg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!-dhg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 424w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 848w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 1272w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/a8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.jpg" width="1425" height="769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:769,&quot;width&quot;:1425,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:247426,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!-dhg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 424w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 848w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 1272w, https://substackcdn.com/image/fetch/$s_!-dhg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fb9d66-b650-441c-a2da-a0931fddb068_1425x769.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 2: A side-by-side comparison between gpt-oss-20b and GPT-2 XL 1.5B.</figcaption></figure></div><p></p><p><span>Both gpt-oss and GPT-2 are decoder-only LLMs built on the transformer architecture introduced in the </span><a href="https://arxiv.org/abs/1706.03762" rel="">Attention Is All You Need (2017)</a><span> paper. Over the years, many details have evolved.</span></p><p><span>However, these changes are not unique to gpt-oss. And as we will see later, they appear in many other LLMs. Since I discussed many of these aspects in the previous </span><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" rel="">Big Architecture Comparison</a><span> article, I will try to keep each subsection brief and focused.</span></p><h3 class="header-anchor-post"><strong>2.1 Removing Dropout</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§removing-dropout" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/removing-dropout" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p><a href="https://arxiv.org/abs/1207.0580" rel="">Dropout (2012)</a><span> is a traditional technique to prevent overfitting by randomly "dropping out" (i.e., setting to zero) a fraction of the layer activations or attention scores (Figure 3) during training. However, dropout is rarely used in modern LLMs, and most models after GPT-2 have dropped it (no pun intended).</span></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!BS-w!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!BS-w!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 424w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 848w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 1272w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/b25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png" width="554" height="557.2781065088758" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:850,&quot;width&quot;:845,&quot;resizeWidth&quot;:554,&quot;bytes&quot;:130475,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!BS-w!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 424w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 848w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 1272w, https://substackcdn.com/image/fetch/$s_!BS-w!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb25371fe-9ee0-4a65-a5aa-46f3bca4b349_845x850.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 3: An illustration of dropout applied to the attention score matrix.</figcaption></figure></div><p></p><p>I assume that dropout was originally used in GPT-2 because it was inherited from the original transformer architecture. Researchers likely noticed that it does not really improve LLM performance (I observed the same in my small-scale GPT-2 replication runs). This is likely because LLMs are typically trained for only a single epoch over massive datasets, which is in contrast to the multi-hundred-epoch training regimes for which dropout was first introduced. So, since LLMs see each token only once during training, there is little risk of overfitting.</p><p><span>Interestingly, while Dropout is kind of ignored in LLM architecture design for many years, I found a </span><a href="https://arxiv.org/abs/2505.24788" rel="">2025 research paper</a><span> with small scale LLM experiments (Pythia 1.4B) that confirms that Dropout results in worse downstream performance in these single-epoch regimes.</span></p><h3 class="header-anchor-post"><strong>2.2 RoPE Replaces Absolute Positional Embeddings</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§rope-replaces-absolute-positional-embeddings" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/rope-replaces-absolute-positional-embeddings" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>In transformer-based LLMs, positional encoding is necessary because of the attention mechanism. By default, attention treats the input tokens as if they have no order. In the original GPT architecture, absolute positional embeddings addressed this by adding a learned embedding vector for each position in the sequence (Figure 4), which is then added to the token embeddings.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!YCov!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!YCov!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 424w, https://substackcdn.com/image/fetch/$s_!YCov!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 848w, https://substackcdn.com/image/fetch/$s_!YCov!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 1272w, https://substackcdn.com/image/fetch/$s_!YCov!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/62fdfc32-605c-4065-abc6-689756d53b87_1195x533.jpg" width="1195" height="533" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:533,&quot;width&quot;:1195,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:123823,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!YCov!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 424w, https://substackcdn.com/image/fetch/$s_!YCov!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 848w, https://substackcdn.com/image/fetch/$s_!YCov!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 1272w, https://substackcdn.com/image/fetch/$s_!YCov!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62fdfc32-605c-4065-abc6-689756d53b87_1195x533.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 4: Illustration of absolute positional embeddings.</figcaption></figure></div><p></p><p></p><p><span>RoPE (</span><a href="https://arxiv.org/abs/2104.09864" rel="">Rotary Position Embedding</a><span>) introduced a different approach: instead of adding position information as separate embeddings, it encodes position by rotating the query and key vectors in a way that depends on each token's position. (RoPE is an elegant idea but also a bit of a tricky topic to explain. I plan to cover separately in more detail one day.)</span></p><p>While first introduced in 2021, RoPE became widely adopted with the release of the original Llama model in 2023 and has since become a staple in modern LLMs.</p><h3 class="header-anchor-post"><strong>2.3 Swish/SwiGLU Replaces GELU</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§swishswiglu-replaces-gelu" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/swishswiglu-replaces-gelu" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>Early GPT architectures used GELU. Why now use Swish over GELU? Swish (also referred to as sigmoid linear unit or SiLU) is considered computationally slightly cheaper, and in my opinion, that all there is to it. Depending on which paper you look at, you will find that one is slightly better than the other in terms of modeling performance. In my opinion, these small differences are probably within a standard error, and your mileage will vary based on hyperparameter sensitivity.</p><p>Activation functions used to be a hot topic of debate until the deep learning community largely settled on ReLU more than a decade ago. Since then, researchers have proposed and tried many ReLU-like variants with smoother curves, and GELU and Swish (Figure 5) are the ones that stuck.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!WIz6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WIz6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 424w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 848w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 1272w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.jpg" width="1407" height="775" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:775,&quot;width&quot;:1407,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:237022,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!WIz6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 424w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 848w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 1272w, https://substackcdn.com/image/fetch/$s_!WIz6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa7b74a-6520-4124-99fd-6df60b9e0e7e_1407x775.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 5: Comparison between Swish and GELU activations, which are both smoother versions or ReLU.</figcaption></figure></div><p></p><p></p><p></p><p></p><p><span>Early GPT architectures used GELU, which is defined as </span><code>0.5x * [1 + erf(x / sqrt(2))]</code><span>. Here, </span><code>erf</code><span> (short for error function) is the integral of a Gaussian and it is computed using polynomial approximations of the Gaussian integral, which makes it more computationally expensive than simpler functions like the sigmoid used in Swish, where Swish is simply </span><code>x * sigmoid(x)</code><span>.</span></p><p>In practice, Swish is computationally slightly cheaper than GELU, and that's probably the main reason it replaced GELU in most newer models. Depending on which paper we look at, one might be somewhat better in terms of modeling performance. But I'd say these gains are often within standard error, and the winner will depend heavily on hyperparameter tuning.</p><p>Swish is used in most architectures today. However, GELU is not entirely forgotten; for example, Google's Gemma models still use GELU.</p><p><span>What's more notable, though, is that the feed forward module (a small multi-layer perceptron) is replaced by a gated "GLU" counterpart, where GLU stands for gated linear unit and was proposed in a </span><a href="https://arxiv.org/pdf/2002.05202" rel="">2020 paper</a><span>. Concretely, the 2 fully connected layers are replaced by 3 fully connected layers that are used as shown in Figure 6 below.</span></p><p></p><p></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!8gzt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!8gzt!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 424w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 848w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 1272w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.jpg" width="655" height="550.0696517412936" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:844,&quot;width&quot;:1005,&quot;resizeWidth&quot;:655,&quot;bytes&quot;:190423,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!8gzt!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 424w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 848w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 1272w, https://substackcdn.com/image/fetch/$s_!8gzt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F10a8befb-b407-45a4-b38b-486c3d7a65d6_1005x844.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 6: A comparison between Swish and GELU and their gated counterparts, SwiGLU and GEGLU.</figcaption></figure></div><p></p><p><span>At first glance, it may appear that the GEGLU/SwiGLU variants may be better than the regular feed forward layers because there are simply more parameters due to the extra layer. But this is deceiving because in practice, the </span><code>W</code><span> and </span><code>V</code><span> weight layers in SwiGLU/GEGLU are usually chosen to be half the size each of the </span><code>W_1</code><span> layer in a traditional feed forward layer.</span></p><p>To illustrate this better, consider the concrete code implementations of the regular and GLU variants:</p><p></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!T1lR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!T1lR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 424w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 848w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 1272w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.jpg" width="682" height="508.8869731800766" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:779,&quot;width&quot;:1044,&quot;resizeWidth&quot;:682,&quot;bytes&quot;:266681,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!T1lR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 424w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 848w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 1272w, https://substackcdn.com/image/fetch/$s_!T1lR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6cc115d2-4f0a-4d54-8edd-d737ea4dc221_1044x779.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 7: Regular feed forward module (top) and SwiGLU variant (bottom) next to each other. Note that the Swish function is implemented as “silu” in PyTorch.</figcaption></figure></div><p></p><p>So, suppose we have an embedding dimension of 1024. In the regular feed forward case, this would then be</p><ul><li><p>fc1: 1024 × 4096 = 4,194,304</p></li><li><p>fc2: 1024 × 4096 = 4,194,304</p></li></ul><p>That is fc1 + fc2 = 8,388,608 parameters.</p><p>For the GLU variant, we have</p><ul><li><p>fc1: 1024 × 1024 = 1,048,576</p></li><li><p>fc2: 1024 × 1024 = 1,048,576</p></li><li><p>fc3: 1024 × 1024 = 1,048,576</p></li></ul><p>I.e., 3 × 1,048,576 = 3,145,728 weight parameters.</p><p>So, overall, using the GLU variants results in fewer parameters, and they perform better as well. The reason for this better performance is that these GLU variants provide an additional multiplicative interaction, which improves expressivity (the same reason deep &amp; slim neural nets perform better than shallow &amp; wide neural nets, provided they are trained well).</p><h3 class="header-anchor-post"><strong>2.4 Mixture-of-Experts Replaces Single FeedForward Module</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§mixture-of-experts-replaces-single-feedforward-module" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/mixture-of-experts-replaces-single-feedforward-module" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>In addition to upgrading the feed forward module to a SwiGLU, as discussed in the previous section, gpt-oss replaces the single feed forward module with multiple feed forward modules, using only a subset for each token generation step. This approach is known as a Mixture-of-Experts (MoE) and illustrated in Figure 8 below.</p><p></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!SYqb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!SYqb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 424w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 848w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 1272w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/fa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png" width="1307" height="640" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:640,&quot;width&quot;:1307,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:120915,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!SYqb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 424w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 848w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 1272w, https://substackcdn.com/image/fetch/$s_!SYqb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa3367a4-914a-49e0-8c94-016969397ab3_1307x640.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 8: The feed forward module is replaced by a Mixture-of-Expert (MoE) module.</figcaption></figure></div><p></p><p></p><p><span>So, replacing </span><em>a single</em><span> feed forward module with </span><em>multiple</em><span> feed forward modules (as done in a MoE setup) substantially increases the model's total parameter count. However, the key trick is that we don't use ("activate") all experts for every token. Instead, a router selects only a small subset of experts per token.</span></p><p><span>Because only a few experts are active at a time, MoE modules are often referred to as </span><em>sparse</em><span>, in contrast to </span><em>dense</em><span> modules that always use the full parameter set. However, the large total number of parameters via an MoE increases the capacity of the LLM, which means it can take up more knowledge during training. The sparsity keeps inference efficient, though, as we don't use all the parameters at the same time.</span></p><p>(Fun fact: In most MoE models, expert weights account for more than 90% of the total model parameters.)</p><h3 class="header-anchor-post"><strong>2.5 Grouped Query Attention Replaces Multi-Head Attention</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§grouped-query-attention-replaces-multi-head-attention" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/grouped-query-attention-replaces-multi-head-attention" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>As mentioned in my previous articles, Grouped Query Attention (GQA) has emerged in recent years as a more compute- and parameter-efficient alternative to Multi-Head Attention (MHA).</p><p>In MHA, each head has its own set of keys and values. GQA reduces memory usage by grouping multiple heads to share the same key and value projections.</p><p>For example, as shown in Figure 9, if there are 2 key–value groups and 4 attention heads, heads 1 and 2 might share one set of keys and values, while heads 3 and 4 share another. This grouping decreases the total number of key and value computations, leading to lower memory usage and improved efficiency without noticeably affecting modeling performance, according to ablation studies.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Kohq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Kohq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 424w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 848w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 1272w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/a2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png" width="637" height="302.7938561034762" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:588,&quot;width&quot;:1237,&quot;resizeWidth&quot;:637,&quot;bytes&quot;:83420,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Kohq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 424w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 848w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 1272w, https://substackcdn.com/image/fetch/$s_!Kohq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2347cc2-3685-4547-b31b-be7bbfb21201_1237x588.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 9: A comparison between MHA and GQA. Here, the group size is 2, where a key and value pair is shared among 2 queries.</figcaption></figure></div><p></p><p></p><p>So, the core idea behind GQA is to reduce the number of key and value heads by sharing them across multiple query heads. This (1) lowers the model's parameter count and (2) reduces the memory bandwidth usage for key and value tensors during inference since fewer keys and values need to be stored and retrieved from the KV cache.</p><p><span>(If you are curious how GQA looks in code, see my</span><a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/07_gpt_to_llama/converting-llama2-to-llama3.ipynb" rel=""> GPT-2 to Llama 3 conversion guide</a><span> for a version without KV cache and my KV-cache variant </span><a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/pkg/llms_from_scratch/llama3.py" rel="">here</a><span>.)</span></p><p><span>While GQA is mainly a computational-efficiency workaround for MHA, ablation studies (such as those in the</span><a href="https://arxiv.org/abs/2305.13245" rel=""> original GQA paper</a><span> and the </span><a href="https://arxiv.org/abs/2307.09288" rel="">Llama 2 paper</a><span>) show it performs comparably to standard MHA in terms of LLM modeling performance.</span></p><h3 class="header-anchor-post"><strong>2.6 Sliding Window Attention</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§sliding-window-attention" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/sliding-window-attention" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p><span>Sliding-window attention (Figure 10 below) was first introduced in the </span><a href="https://arxiv.org/abs/2004.05150" rel="">LongFormer paper (2020)</a><span> and later popularized by Mistral. Interestingly, gpt-oss applies it in every second layer. You can think of it as a variation of multi-head attention, or in this case grouped query attention (GQA), where the attention context is restricted to a smaller window, reducing both memory usage and compute costs.</span></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wwFe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wwFe!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/e79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpg" width="1456" height="721" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:721,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:225815,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wwFe!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wwFe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe79d48c3-2bdf-41bb-9e18-45f128cd5c01_1600x792.jpeg 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 10: Comparison between regular attention (left) and sliding window attention (right).</figcaption></figure></div><p></p><p></p><p>Concretely, gpt-oss alternates between GQA layers that attend to the full context and GQA layers with a sliding window limited to 128 tokens.</p><p><span>As I discussed in my </span><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" rel="">previous article</a><span>, </span><a href="https://arxiv.org/abs/2408.00118" rel="">Gemma 2 (2024)</a><span> used a similar 1:1 ratio. </span><a href="https://arxiv.org/abs/2503.19786" rel="">Gemma 3</a><span> earlier this year went much further and shifted to a 5:1 ratio, which means only one full-attention layer for every five sliding-window (local) attention layers.</span></p><p>According to the Gemma ablation studies, sliding-window attention has minimal impact on modeling performance, as shown in the figure below. Note that the window size in Gemma 2 was 4096 tokens, which Gemma 3 reduced to 1024. In gpt-oss, the window is just 128 tokens, which is remarkably small.</p><p><span>And as a fun fact, the </span><a href="https://openai.com/index/introducing-gpt-oss/" rel="">official announcement article</a><span> notes that sliding-window attention was apparently already used in GPT-3:</span></p><blockquote><p>The models use alternating dense and locally banded sparse attention patterns, similar to GPT-3</p></blockquote><p><span>Who knew!? I went back to the original </span><a href="https://arxiv.org/abs/2005.14165" rel="">GPT-3 paper</a><span>, and it was indeed mentioned there:</span></p><blockquote><p>We use the same model and architecture as GPT-2 [ RWC+19 ], including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer [ CGRS19 ]. </p></blockquote><h3 class="header-anchor-post"><strong>2.7 RMSNorm Replaces LayerNorm</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§rmsnorm-replaces-layernorm" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/rmsnorm-replaces-layernorm" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p><span>Finally, the last small tweak, coming from GPT-2, is replacing </span><a href="https://arxiv.org/abs/1607.06450" rel="">LayerNorm (2016)</a><span> by </span><a href="https://arxiv.org/abs/1910.07467" rel="">RMSNorm (2019)</a><span>, which has been a common trend in recent years.</span></p><p>Akin to swapping GELU with Swish and SwiGLU, RMSNorm is one of these smaller but sensible efficiency improvements. RMSNorm is similar to LayerNorm in its purpose to normalize layer activations, as shown in Figure 11 below.</p><p>You might recall that not too long ago, BatchNorm was the go-to choice for this task. It has since fallen out of favor, largely because it is harder to parallelize efficiently (due to the mean and variance batch statistics) and performs poorly with small batch sizes.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H32R!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H32R!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 424w, https://substackcdn.com/image/fetch/$s_!H32R!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 848w, https://substackcdn.com/image/fetch/$s_!H32R!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 1272w, https://substackcdn.com/image/fetch/$s_!H32R!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.jpg" width="1367" height="599" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:599,&quot;width&quot;:1367,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:274255,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!H32R!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 424w, https://substackcdn.com/image/fetch/$s_!H32R!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 848w, https://substackcdn.com/image/fetch/$s_!H32R!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 1272w, https://substackcdn.com/image/fetch/$s_!H32R!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ac713f9-4f15-4104-9b67-eff1c4f29f95_1367x599.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 11: A comparison between LayerNorm (left) and RMSNorm (right) for a small linear layer.</figcaption></figure></div><p></p><p></p><p>As we can see in Figure 11 above, both LayerNorm and RMSNorm scale the layer outputs to be in a reasonable range.</p><p>LayerNorm subtracts the mean and divides by the standard deviation such that the layer outputs have a zero mean and unit variance (variance of 1 and standard deviation of one).</p><p>RMSNorm divides the inputs by the root-mean-square. This scales activations to a comparable magnitude without enforcing zero mean or unit variance. In this particular example shown in Figure 11, the mean is 0.77 and the variance is 0.41.</p><p>Both LayerNorm and RMSNorm stabilize activation scales and improve optimization, but RMSNorm is often preferred in large-scale LLMs because it is cheaper to compute. Unlike LayerNorm, RMSNorm has no bias (shift) term and reduces the expensive mean and variance computations to a single root-mean-square operation. This reduces the number of cross-feature reductions from two to one, which lowers communication overhead on GPUs and improving training efficiency.</p><p>Figure 12 shows what this looks like in code:</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!m5aM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!m5aM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 424w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 848w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 1272w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/de968991-5068-40d9-87bb-98b887f5f384_919x690.jpg" width="589" height="442.23068552774754" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de968991-5068-40d9-87bb-98b887f5f384_919x690.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:690,&quot;width&quot;:919,&quot;resizeWidth&quot;:589,&quot;bytes&quot;:259430,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!m5aM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 424w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 848w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 1272w, https://substackcdn.com/image/fetch/$s_!m5aM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde968991-5068-40d9-87bb-98b887f5f384_919x690.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 12: Code implementations of LayerNorm and RMSNorm showing that RMSNorm is computationally simpler.</figcaption></figure></div><p></p><p></p><h3 class="header-anchor-post"><strong>2.8 The GPT-2 Legacy</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§the-gpt-legacy" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/the-gpt-legacy" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>I still think that GPT-2 is an excellent beginner architecture when learning about LLMs. It's simple enough to understand without getting lost in layers of optimization tricks, but still complex enough to give you a solid grasp of how modern transformer models work.</p><p>By starting with GPT-2, you can focus on the fundamentals (attention mechanisms, positional embeddings, normalization, and the overall training pipeline) without being overwhelmed by the extra features and tweaks found in newer architectures.</p><p>In fact, I think it's worth the time to learn about and even implement GPT-2 first before trying to stack newer changes on top. You will not only have an easier time understanding those changes, but you will likely also appreciate them more, because you will get a better understanding of what limitations or problems they try to solve.</p><p><span>For instance, starting with my GPT-2 code I recently implemented the </span><a href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/11_qwen3" rel="">Qwen3 architecture from scratch</a><span>, which is super similar to gpt-oss, which brings us to the next topic: Comparing gpt-oss to a more recent architecture.</span></p><div class="subscription-widget-wrap"><div class="subscription-widget show-subscribe"><div class="preamble"><p>Ahead of AI is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><div data-component-name="SubscribeWidget" class="subscribe-widget is-signed-up"><div class="pencraft pc-reset button-wrapper"><div class="pencraft pc-display-flex pc-justifyContent-center pc-reset"><button tabindex="0" type="button" data-href="https://magazine.sebastianraschka.com/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=170506328&amp;next=https%3A%2F%2Fmagazine.sebastianraschka.com%2Fp%2Ffrom-gpt-2-to-gpt-oss-analyzing-the" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_primary-RfbeYt size_md-gCDS3o"><span>Upgrade to paid</span></button></div></div></div></div></div><p></p><h2 class="header-anchor-post"><strong>3. Comparing gpt-oss To A Recent Architecture (Qwen3)</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§comparing-gpt-oss-to-a-recent-architecture-qwen" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/comparing-gpt-oss-to-a-recent-architecture-qwen" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><p>Now that we have walked through the evolution from GPT-2 to GPT OSS, we can take the next step and compare GPT OSS to a more recent architecture, Qwen3, which was released three months earlier in May 2025.</p><p>The reason I am selecting Qwen3 here is that it is among the top open-weight models as of the time of writing. Additionally, one of the Qwen3 MoE models is more or less directly comparable to GPT OSS due to its relatively similar overall size in terms of trainable parameters.</p><p>Figure 13 below compares gpt-oss-20b to a Qwen3 model of comparable size.</p><p></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rzWN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rzWN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 424w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 848w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 1272w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/99d31b61-7268-4eed-985a-fafe7166db72_1543x779.jpg" width="1456" height="735" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:735,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:265440,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!rzWN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 424w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 848w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 1272w, https://substackcdn.com/image/fetch/$s_!rzWN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99d31b61-7268-4eed-985a-fafe7166db72_1543x779.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 13: A gpt-oss and Qwen3 model of comparable size side by side.</figcaption></figure></div><p></p><p>As we can see, gpt-oss 20B and Qwen3 30B-A3B are very similar in their architecture components. The primary difference here, aside from the dimensions, is that gpt-oss employs sliding window attention, as discussed earlier in section 1.6 (not shown in this figure), whereas Qwen3 does not.</p><p>Let's walk through the noteworthy details one by one in the following subsections.</p><h3 class="header-anchor-post"><strong>3.1 Width Versus Depth</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§width-versus-depth" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/width-versus-depth" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>If we look at the two models closely, we see that Qwen3 is a much deeper architecture with its 48 transformer blocks instead of 24 (Figure 14).</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!1jSR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!1jSR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 424w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 848w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 1272w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/ed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.jpg" width="1456" height="721" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:721,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:275433,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!1jSR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 424w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 848w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 1272w, https://substackcdn.com/image/fetch/$s_!1jSR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed149602-1ff5-4c23-a4bf-c449b26915da_1613x799.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 14: Qwen3 has twice as many transformer blocks as gpt-oss-20b.</figcaption></figure></div><p></p><p></p><p></p><p>On the other hand, gpt-oss is a much wider architecture:</p><ul><li><p>An embedding dimension of 2880 instead of 2048</p></li><li><p>An intermediate expert (feed forward) projection dimension of also 2880 instead of 768</p></li></ul><p>It's also worth noting that gpt-oss uses twice as many attention heads, but this doesn't directly increase the model's width. The width is determined by the embedding dimension.</p><p>Does one approach offer advantages over the other given a fixed number of parameters? As a rule of thumb, deeper models have more flexibility but can be harder to train due to instability issues, due to exploding and vanishing gradients (which RMSNorm and shortcut connections aim to mitigate).</p><p>Wider architectures have the advantage of being faster during inference (with a higher tokens/second throughput) due to better parallelization at a higher memory cost.</p><p><span>When it comes to modeling performance, there's unfortunately no good apples-to-apples comparison I am aware of (where parameter size and datasets are kept constant) except for an ablation study in the </span><a href="https://arxiv.org/abs/2408.00118" rel="">Gemma 2 paper (Table 9)</a><span>, which found that for a 9B parameter architecture, a wider setup is slightly better than a deeper setup. Across 4 benchmarks, the wider model achieved a 52.0 average score, and the deeper model achieved a 50.8 average score.</span></p><h3 class="header-anchor-post"><strong>3.2 Few Large Versus Many Small Experts</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§few-large-versus-many-small-experts" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/few-large-versus-many-small-experts" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>As shown in Figure 14 above, it's also noteworthy that gpt-oss has a surprisingly small number of experts (32 instead of 128), and only uses 4 instead of 8 active experts per token. However, each expert is much larger than the experts in Qwen3.</p><p>This is interesting because the recent trends and developments point towards more, smaller models as being beneficial. This change, at a constant total parameter size, is nicely illustrated in Figure 15 below from the DeepSeekMoE paper.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qYc3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qYc3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 424w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 848w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 1272w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.jpg" width="1131" height="609" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:609,&quot;width&quot;:1131,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:219481,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qYc3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 424w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 848w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 1272w, https://substackcdn.com/image/fetch/$s_!qYc3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5941e19e-ead5-47be-9c41-8afee9124c6d_1131x609.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 15: An annotated figure from "DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models", </span><a href="https://arxiv.org/abs/2401.06066" rel="">https://arxiv.org/abs/2401.06066</a></figcaption></figure></div><p></p><p></p><p>Notably, unlike DeepSeek's models, neither gpt-oss nor Qwen3 uses shared experts, though.</p><p>To be fair, the small number of experts in gpt-oss could be a side effect of the 20B size. Looking at the 120B mode below, they indeed increased the number of experts (and transformer blocks) while keeping everything else fixed, as shown in Figure 16 below.</p><p></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!VPar!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!VPar!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 424w, https://substackcdn.com/image/fetch/$s_!VPar!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 848w, https://substackcdn.com/image/fetch/$s_!VPar!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 1272w, https://substackcdn.com/image/fetch/$s_!VPar!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.jpg" width="1456" height="687" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:687,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:246229,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!VPar!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 424w, https://substackcdn.com/image/fetch/$s_!VPar!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 848w, https://substackcdn.com/image/fetch/$s_!VPar!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 1272w, https://substackcdn.com/image/fetch/$s_!VPar!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48d8c956-fdf6-4a0e-8b67-9e40303e0815_1596x753.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 16: The two gpt-oss architectures side by side, where the larger 120B model only scales the number of transformer blocks and number of experts.</figcaption></figure></div><p></p><p>The boring explanation for the fact that the 20B and 120B models are so similar is probably that the 120B model was the main focus. And the easiest way to create a smaller model was to make it a bit shorter (fewer transformer blocks) and to reduce the number of experts, because that's where most of the parameters are. However, one might speculate whether they started training the 120B model, and then chopped some of the transformer blocks and experts for continued pre-training (instead of starting from random weights).</p><p>In any case, it's because it's quite unusual to only scale those two (transformer blocks and number of experts). For instance, when looking at Qwen3 MoE models of multiple sizes (Figure 17 below), they were scaled more proportionally to each other over many more aspects..</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!0h6T!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!0h6T!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 424w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 848w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 1272w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.jpg" width="1120" height="903" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:903,&quot;width&quot;:1120,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:210100,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!0h6T!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 424w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 848w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 1272w, https://substackcdn.com/image/fetch/$s_!0h6T!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9faf6dc8-5876-47c2-8965-212195773ed9_1120x903.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Figure 17: Architecture differences in the various Qwen3 models.</figcaption></figure></div><p></p><p></p><h3 class="header-anchor-post"><strong>3.3 Attention Bias and Attention Sinks</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§attention-bias-and-attention-sinks" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/attention-bias-and-attention-sinks" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>Both gpt-oss and Qwen3 use grouped query attention. The main difference is that gpt-oss restricts the context size via sliding window attention in each second layer, as mentioned earlier.</p><p>However, there's one interesting detail that caught my eye. It seems that gpt-oss uses bias units for the attention weights, as shown in the figure below.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!U3bl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!U3bl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 424w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 848w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 1272w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.jpg" width="1456" height="441" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:441,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:176606,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!U3bl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 424w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 848w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 1272w, https://substackcdn.com/image/fetch/$s_!U3bl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f1c450c-a6ad-4bc7-9e0e-6596c75fadda_1606x486.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 18: gpt-oss models use bias units in the attention layers. See code example </span><a href="https://github.com/huggingface/transformers/blob/369c99d0cea403b77bd0aef818527106453fd9fc/src/transformers/models/gpt_oss/modular_gpt_oss.py#L228-L243" rel="">here</a><span>.</span></figcaption></figure></div><p></p><p></p><p><span>I haven't seen these bias units being used since the GPT-2 days, and they are commonly regarded as redundant. Indeed, I found a </span><a href="https://arxiv.org/abs/2302.08626" rel="">recent paper</a><span> that shows mathematically that this is at least true for the key transformation (k_proj). Furthermore, the empirical results show that there is little difference between with and without bias units (see Figure 19 below).</span></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!FT2j!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png" data-component-name="Image2ToDOM" rel="" class="image-link image2"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!FT2j!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 424w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 848w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 1272w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/73888178-f1d1-4490-a310-d61ae113b0a9_397x182.jpg" width="279" height="127.90428211586902" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:182,&quot;width&quot;:397,&quot;resizeWidth&quot;:279,&quot;bytes&quot;:20470,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!FT2j!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 424w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 848w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 1272w, https://substackcdn.com/image/fetch/$s_!FT2j!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73888178-f1d1-4490-a310-d61ae113b0a9_397x182.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div></div></div></a><figcaption class="image-caption"><span>Figure 19: Table from </span><a href="https://arxiv.org/pdf/2302.08626" rel="">https://arxiv.org/pdf/2302.08626</a><span> showing the average test loss when the models were trained from scratch with and without bias units.</span></figcaption></figure></div><p></p><p></p><p><span>Another detail you may have noticed is the definition of </span><code>sinks</code><span> in the code screenshot in Figure 18. In general models, attention sinks are special "always-attended" tokens placed at the start of the sequence to stabilize attention, which is especially useful in long-context scenarios. I.e., if the context gets very long, this special attended token at the beginning is still attended to, and it can learn to store some generally useful information about the entire sequence. (I think it was originally proposed in the </span><a href="https://arxiv.org/abs/2309.17453" rel="">Efficient Streaming Language Models with Attention Sinks</a><span> paper.)</span></p><p><span>In the gpt-oss implementation, </span><em>attention sinks</em><span> are not actual tokens in the input sequence. Instead, they are learned per-head bias logits that are appended to the attention scores (Figure 20). The goal is the same as with the above-mentioned attention sinks, but without modifying the tokenized inputs.</span></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Qwo6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Qwo6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 424w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 848w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 1272w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.jpg" width="988" height="684" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:684,&quot;width&quot;:988,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:202184,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Qwo6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 424w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 848w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 1272w, https://substackcdn.com/image/fetch/$s_!Qwo6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F542cfc4c-ccfb-48b9-b285-ecbe8d2c0e4e_988x684.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 20: The use of attention sinks in gpt-oss; based on the Hugging Face code </span><a href="https://github.com/huggingface/transformers/blame/369c99d0cea403b77bd0aef818527106453fd9fc/src/transformers/models/gpt_oss/modular_gpt_oss.py" rel="">here</a><span>.</span></figcaption></figure></div><p></p><p></p><h3 class="header-anchor-post"><strong>3.4 License</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§license" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/license" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>Lastly, and similar to Qwen3, the gpt-oss models are Apache 2.0 open-source license, which is great (it's the same license that I prefer for my own open-source projects). This means that the models can be distilled into other models or used in commercial products without restriction.</p><p><strong>Open-weight vs. open-source LLMs.</strong><span> This distinction has been debated for years, but it is worth clarifying to avoid confusion about this release and its artifacts. Some model developers release only the model weights and inference code (for example, Llama, Gemma, gpt-oss), while others (for example, OLMo) release everything including training code, datasets, and weights as true open source.</span></p><p><span>By that stricter definition, gpt-oss is an </span><em>open-weight</em><span> model (just like Qwen3) because it includes the weights and inference code but not the training code or datasets. However, the terminology is used inconsistently across the industry.</span></p><p><span>I assume the "oss" in "gpt-oss" stands for </span><em>open source software</em><span>; however, I am positively surprised that OpenAI itself clearly describes gpt-oss as an open-weight model in their official </span><a href="https://openai.com/index/introducing-gpt-oss/" rel="">announcement article</a><span>.</span></p><h2 class="header-anchor-post"><strong>4 Other Interesting Tidbits</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§other-interesting-tidbits" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/other-interesting-tidbits" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><p>While the previous sections described how the architecture has evolved since GPT-2 and discussed its similarities to Qwen3 (and most other recent models), there are still a few additional but noteworthy details I have not mentioned, yet. These are points that did not fit neatly into the earlier sections but are still worth mentioning.</p><h3 class="header-anchor-post"><strong>4.1 Training Overview</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§training-overview" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/training-overview" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p><span>Unfortunately, there is not much information about the training set sizes and algorithms available. I added the most interesting puzzle pieces from the </span><a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf" rel="">model card report</a><span> (1) and </span><a href="https://openai.com/index/introducing-gpt-oss/" rel="">announcement post</a><span> (2) below:</span></p><blockquote><p>The gpt-oss models were trained using our most advanced pre-training and post-training techniques [...] (1)</p><p>[...] required 2.1million H100-hours to complete, with gpt-oss-20b needing almost 10x fewer. (1)</p><p>[...] including a supervised fine-tuning stage and a high-compute RL stage [...] (2)</p><p>We trained the models on a mostly English, text-only dataset, with a focus on STEM, coding, and general knowledge. (2)</p></blockquote><p><span>So, we know that the gpt-oss models are reasoning models. The training compute of 2.1 million H100 GPU hours is roughly on par with the 2.788 million H800 GPU hours that the ~5.6x larger </span><a href="https://arxiv.org/abs/2412.19437" rel="">DeepSeek V3</a><span> model was trained for. Unfortunately, there is no information about the Qwen3 training time available yet.</span></p><p>Interestingly, the GPT-oss training hour estimate includes both the supervised learning for instruction following and the reinforcement learning for reasoning, whereas DeepSeek V3 is just a pre-trained base model on top of which DeepSeek R1 was trained separately.</p><h3 class="header-anchor-post"><strong>4.2 Reasoning Efforts</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§reasoning-efforts" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/reasoning-efforts" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>As mentioned in the previous section, the gpt-oss models are reasoning models. However, what's particularly interesting is that they were trained so that users can easily control the degree of reasoning via inference time scaling.</p><p>Concretely, gpt-oss models can receive "Reasoning effort: low/medium/high" instructions as part of their system prompt, which directly affects the response length and accuracy, as shown in Figure 21.</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!LsLL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LsLL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 424w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 848w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 1272w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.jpg" width="1219" height="548" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:548,&quot;width&quot;:1219,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:175317,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!LsLL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 424w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 848w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 1272w, https://substackcdn.com/image/fetch/$s_!LsLL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a51339c-49a4-48c6-b60f-ce841b604692_1219x548.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 21: Response length and quality of gpt-oss models under different reasoning efforts (annotated figure from the </span><a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf" rel="">model card</a><span>)</span></figcaption></figure></div><p></p><p></p><p>This level of adjustability is useful because it lets us balance cost, compute, and accuracy. For example, if the task is simple, such as answering a straightforward knowledge question or fixing a small typo, we can skip extended reasoning. This saves time and resources while avoiding unnecessarily long responses and verbose reasoning traces.</p><p>It is somewhat unfortunate that OpenAI did not release the base models prior to reinforcement learning-based reasoning training, unlike Qwen3 or OLMo. Base models are particularly valuable starting points for researchers working on reasoning methods (which is one reason I currently like working with Qwen3 Base). My guess is that OpenAI's decision was driven more by industry and production use cases than by research considerations.</p><p><span>Note that the original Qwen3 models also have a toggle for enabling/disabling thinking (reasoning) modes (via a </span><code>enable_thinking=True/False</code><span> setting in the tokenizer that simply adds &lt;think&gt;&lt;/think&gt; tags to disable the reasoning behavior). However, the Qwen3 team updated their models in the last few weeks and moved away from the hybrid model towards dedicated Instruct/Thinking/Coder variants.</span></p><p>The reason was that the hybrid mode resulted in lower performance compared to the individual models:</p><blockquote><p><span>After discussing with the community and reflecting on the matter, we have decided to abandon the hybrid thinking mode. We will now train the Instruct and Thinking models separately to achieve the best possible quality. </span><a href="https://www.actuia.com/en/news/alibaba-launches-qwen3-235b-a22b-instruct-2507-and-breaks-away-from-hybrid-reasoning/?utm_source=chatgpt.com" rel="">Source</a></p></blockquote><h3 class="header-anchor-post"><strong>4.3 MXFP4 Optimization: A Small But Important Detail</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§mxfp-optimization-a-small-but-important-detail" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/mxfp-optimization-a-small-but-important-detail" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p>One interesting surprise is that OpenAI released the gpt-oss models with an MXFP4 quantization scheme for the MoE experts.</p><p>Quantization formats used to be a niche topic, mostly relevant to mobile or embedded AI, but that's changed with the push toward bigger models. In this case, the MXFP4 optimization allows the model to run on single GPU devices.</p><p>Here’s what that looks like in practice:</p><ul><li><p>The large model (think 120B) fits on a single 80GB H100 or newer GPU. Not consumer hardware, but hey, it's much cheaper to rent a 1-H100 machine than a multi-H100 machine. Plus, we don't have to worry about distributing the model across GPUs and adding communication overhead. It's really nice that AMD MI300X cards are supported from day 1 as well!</p></li><li><p><span>The smaller 20B model even fits into 16 GB of VRAM; the caveat is that it has to be a RTX 50-series GPU or newer to support MXFP4. (Edit: support for older cards, such as RTX 4090, was recently added via a </span><a href="https://github.com/huggingface/transformers/pull/39940" rel="">patch</a><span>.)</span></p></li></ul><p>Note that the models will also run on older hardware but without MXFP4 support and will thus consume more RAM. Without MXFP4 optimization, the models in bfloat16 will consume more like 48 GB (gpt-oss-20b) and 240 GB (gpt-oss-120b).</p><p>By the way, I can run the gpt-oss-20b model comfortably on my Mac Mini using ollama. It uses about 13.5 Gb or memory, which is really reasonable.</p><h3 class="header-anchor-post"><strong>4.4 Benchmarks</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§benchmarks" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/benchmarks" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h3><p><span>The models are still a bit too new for independent benchmarks. Checking the </span><a href="https://lmarena.ai/leaderboard" rel="">LM Arena leaderboard</a><span>, I found that gpt-oss is not listed, yet. So, Qwen3-Instruct remains the top open-weight model, according to users on the LM Arena, for now (Figure 22).</span></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!u2e3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!u2e3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 424w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 848w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 1272w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png" width="1246" height="928" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:928,&quot;width&quot;:1246,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:199404,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!u2e3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 424w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 848w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 1272w, https://substackcdn.com/image/fetch/$s_!u2e3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a8d9a1-db1c-4a8c-bcef-e2b61fd99893_1246x928.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 22: Current view of the </span><a href="https://lmarena.ai/leaderboard" rel="">LM Arena Leaderboard</a><span> (as of 8 Aug 2025)</span></figcaption></figure></div><p></p><p></p><p>Looking at a reasoning benchmarks provide in the gpt-oss announcement post, we can see that the gpt-ossmodels are on par with OpenAI's proprietary models as well as Qwen3 (Figure 23).</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ueCy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ueCy!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 424w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 848w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 1272w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/e665447b-5092-4e88-b27a-768998945b02_978x588.png" width="669" height="402.22085889570553" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e665447b-5092-4e88-b27a-768998945b02_978x588.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:588,&quot;width&quot;:978,&quot;resizeWidth&quot;:669,&quot;bytes&quot;:100836,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ueCy!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 424w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 848w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 1272w, https://substackcdn.com/image/fetch/$s_!ueCy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe665447b-5092-4e88-b27a-768998945b02_978x588.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 23: The main benchmark charts are from the official gpt-oss </span><a href="https://openai.com/index/gpt-oss-model-card/" rel="">announcement post</a><span>. The "no tools" gpt-oss-120b data is taken from the official </span><a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf" rel="">model card paper</a><span>, and the Qwen3 numbers are taken from the official </span><a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507" rel="">Qwen3 repository</a><span>.</span></figcaption></figure></div><p></p><p></p><p>However, this should be caveated by the fact that gpt-oss-120b is almost half the size of the Qwen3 A235B-A22B-Thinking-2507 model and can run on a single GPU.</p><p>Benchmark performance, however, does not always reflect real-world usability. In my limited use over the past few days, I have found gpt-oss to be quite capable. That said, as others have observed, it does seem to have a relatively high tendency to hallucinate (a point also mentioned in its model card).</p><p>This may stem from its heavy training focus on reasoning tasks such as math, puzzles, and code, which could have led to some "general knowledge forgetting." Still, because gpt-oss was designed with tool use in mind, this limitation may become less relevant over time. Tool integration in open-source LLMs is still in its early stages, but as it matures, I expect that we increasingly let models consult external sources (like search engines) when answering factual or knowledge-based queries.</p><p>If that happens, it could be sensible to prioritize reasoning capacity over memorization. This is much like in human learning in school (or in life in general), where problem-solving skills often matter more than memorizing facts.</p><h2 class="header-anchor-post"><strong>5 gpt-oss and GPT-5</strong><div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div id="§gpt-oss-and-gpt" class="pencraft pc-reset header-anchor offset-top"></div><button tabindex="0" type="button" aria-label="Link" data-href="https://magazine.sebastianraschka.com/i/170506328/gpt-oss-and-gpt" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_secondary-S63h9o"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></button></div></div></h2><p>OpenAI had a busy week and released the long-awaited GPT-5 model shortly after gpt-oss. The GPT-5 release was interesting. And if there's one thing I have to say here, it's that I am really surprised by how good their open-source models really are compared to their best product offering in terms of benchmark performance (Figure 24).</p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!IDPE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!IDPE!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 424w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 848w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 1272w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.jpg" width="1456" height="1144" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1144,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2040548,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://magazine.sebastianraschka.com/i/170506328?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!IDPE!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 424w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 848w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 1272w, https://substackcdn.com/image/fetch/$s_!IDPE!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5552d62b-4c0b-4b19-adcb-59a0a162ad72_5923x4653.png 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><span>Figure 24: The main benchmark charts are from the official GPT-5 </span><a href="https://openai.com/index/introducing-gpt-5/" rel="">announcement post</a><span>. The gpt-oss data is taken from the official </span><a href="https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf" rel="">model card paper</a><span> and </span><a href="https://openai.com/index/introducing-gpt-oss/" rel="">announcement post</a><span>, and the Qwen3 numbers are taken from the official </span><a href="https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct" rel="">Qwen3-Coder repository</a><span>.</span></figcaption></figure></div><p></p><p>All in all, even though some people called the release overhyped, I am glad that we have a new set of really strong open weight models that are not too far behind the best proprietary ones. Of course, benchmarks often do not accurately reflect real-world use, and it is still too early to tell based on the limited usage. But I think these are good times for people who like to work with open-weight and local (or privately hosted) models.</p><p></p><div><hr></div><p><em>This magazine is a personal passion project, and your support helps keep it alive. If you would like to contribute, there are a few great ways:</em></p><ul><li><p><em><strong><a href="https://amzn.to/4fqvn0D" rel="">Grab a copy of my book</a></strong><span>. Build a Large Language Model (From Scratch) walks you through building an LLM step by step, from tokenizer to training.</span></em></p></li></ul><ul><li><p><em><strong><a href="https://www.manning.com/livevideo/master-and-build-large-language-models" rel="">Check out the video course</a></strong><span>. There’s now a 17-hour video course based on the book, available from Manning. It follows the book closely, section by section, and works well both as a standalone or as a code-along resource. The video course is ad-free (unlike the YouTube version) and has a cleaner, more structured format. It also contains 5 additional hours of pre-requisite video material created by Abhinav Kimothi.</span></em></p></li></ul><ul><li><p><em><strong><a href="https://magazine.sebastianraschka.com/subscribe" rel="">Subscribe</a></strong><span>. A paid subscription helps to make my writing sustainable and gives you access to additional contents.</span></em></p></li></ul><p><em>Thanks for reading, and for helping support independent research!</em></p><div class="captioned-image-container"><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wVLk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg" data-component-name="Image2ToDOM" rel="" class="image-link image2 is-viewable-img"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wVLk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 1456w" sizes="100vw"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/fde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpg" width="1456" height="878" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:878,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!wVLk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wVLk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffde977ef-c20a-487b-8f1d-5fdbada6585c_1468x885.jpeg 1456w" sizes="100vw" loading="lazy" class="sizing-normal"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2 lucide-maximize-2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><div class="subscription-widget-wrap"><div class="subscription-widget show-subscribe"><div class="preamble"><p>Ahead of AI is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber.</p></div><div data-component-name="SubscribeWidget" class="subscribe-widget is-signed-up"><div class="pencraft pc-reset button-wrapper"><div class="pencraft pc-display-flex pc-justifyContent-center pc-reset"><button tabindex="0" type="button" data-href="https://magazine.sebastianraschka.com/subscribe?utm_medium=web&amp;utm_source=subscribe-widget-preamble&amp;utm_content=170506328&amp;next=https%3A%2F%2Fmagazine.sebastianraschka.com%2Fp%2Ffrom-gpt-2-to-gpt-oss-analyzing-the" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_primary-RfbeYt size_md-gCDS3o"><span>Upgrade to paid</span></button></div></div></div></div></div></div></div><div class="visibility-check"></div><div class="pencraft pc-display-flex pc-paddingTop-16 pc-paddingBottom-16 pc-reset border-top-detail-themed-k9TZAY"><div class="pencraft pc-display-flex pc-gap-16 pc-alignItems-center pc-reset color-secondary-ls1g8s"><div class="pencraft pc-display-flex pc-flexDirection-row pc-gap-8 pc-alignItems-center pc-justifyContent-flex-start pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-row pc-alignItems-center pc-justifyContent-flex-start pc-reset rtl-zsi3Q8" style="--scale: 32px; --offset: 8px; --border-width: 4px;"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/135212089-enio-fernandes" aria-label="View Enio Fernandes&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB" style="--scale: 32px;"><div title="Enio Fernandes" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Vd6d!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 32w, https://substackcdn.com/image/fetch/$s_!Vd6d!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 64w, https://substackcdn.com/image/fetch/$s_!Vd6d!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png" sizes="32px" alt="Enio Fernandes&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!Vd6d!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 32w, https://substackcdn.com/image/fetch/$s_!Vd6d!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 64w, https://substackcdn.com/image/fetch/$s_!Vd6d!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5aedd3b2-c2f1-4511-ae76-19e03b77c13e_96x96.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/95866185-tim" aria-label="View Tim&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB overlap-q75iOo" style="--scale: 32px;"><div title="Tim" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ksBe!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!ksBe!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!ksBe!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/924b8234-87e8-4d09-864a-16eff29a3546_144x144.jpg" sizes="32px" alt="Tim&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!ksBe!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!ksBe!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!ksBe!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F924b8234-87e8-4d09-864a-16eff29a3546_144x144.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/54970662-scott-smith" aria-label="View scott smith&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB overlap-q75iOo" style="--scale: 32px;"><div title="scott smith" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!YiAI!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!YiAI!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!YiAI!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/66d41826-d9cf-486f-816c-81e50f090873_144x144.png" sizes="32px" alt="scott smith&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!YiAI!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!YiAI!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!YiAI!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F66d41826-d9cf-486f-816c-81e50f090873_144x144.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/88011838-jk" aria-label="View JK&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB overlap-q75iOo" style="--scale: 32px;"><div title="JK" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wllM!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!wllM!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!wllM!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png" sizes="32px" alt="JK&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!wllM!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!wllM!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!wllM!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9a4004ff-ab88-4ef1-b601-27a43b074030_144x144.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/258935901-jack" aria-label="View Jack&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6 avatar-u8q6xB overlap-q75iOo last-JfNEJ_" style="--scale: 32px;"><div title="Jack" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oWbC!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!oWbC!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!oWbC!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png" sizes="32px" alt="Jack&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!oWbC!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!oWbC!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!oWbC!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53b4dc46-28aa-48bb-8c9e-b7a4086fbb4f_144x144.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div></div></div><div class="pencraft pc-reset color-secondary-ls1g8s line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ"><div class="pencraft pc-display-flex pc-gap-4 pc-alignItems-center pc-reset"><a class="pencraft pc-reset cursor-pointer-LYORKw color-secondary-ls1g8s decoration-hover-underline-ClDVRM reset-IxiVJZ">564 Likes</a>∙<div class="pencraft pc-reset color-secondary-ls1g8s line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ"><a href="https://substack.com/note/p-170506328/restacks?utm_source=substack&amp;utm_content=facepile-restacks" class="pencraft pc-reset color-secondary-ls1g8s decoration-hover-underline-ClDVRM reset-IxiVJZ">52 Restacks</a></div></div></div></div></div><div class="post-footer"><div class="pencraft pc-display-flex pc-gap-16 pc-paddingTop-16 pc-paddingBottom-16 pc-justifyContent-space-between pc-alignItems-center pc-reset flex-grow-rzmknG border-top-detail-themed-k9TZAY border-bottom-detail-themed-Ua9186 post-ufi"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="like-button-container post-ufi-button style-button state-liked"><a role="button" aria-label="Like (564)" aria-pressed="true" class="post-ufi-button style-button state-liked has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><div class="label">564</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><a role="button" href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comments" aria-label="View comments (45)" class="post-ufi-button style-button post-ufi-comment-button has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></g></svg><div class="label">45</div></a><a role="button" class="post-ufi-button style-button has-label with-border"><svg role="img" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 20px; width: 20px;"><g><title></title><path d="M21 3V8M21 8H16M21 8L18 5.29962C16.7056 4.14183 15.1038 3.38328 13.3879 3.11547C11.6719 2.84766 9.9152 3.08203 8.32951 3.79031C6.74382 4.49858 5.39691 5.65051 4.45125 7.10715C3.5056 8.5638 3.00158 10.2629 3 11.9996M3 21V16M3 16H8M3 16L6 18.7C7.29445 19.8578 8.89623 20.6163 10.6121 20.8841C12.3281 21.152 14.0848 20.9176 15.6705 20.2093C17.2562 19.501 18.6031 18.3491 19.5487 16.8925C20.4944 15.4358 20.9984 13.7367 21 12" stroke-linecap="round" stroke-linejoin="round"></path></g></svg><div class="label">52</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><a role="button" href="javascript:void(0)" aria-label="View share options" class="post-ufi-button style-button no-icon has-label with-border"><div class="label">Share</div></a></div></div></div></div></article></div></div></div><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div class="visibility-check"></div><div id="discussion" class="pencraft pc-display-flex pc-flexDirection-column pc-gap-16 pc-paddingTop-32 pc-paddingBottom-32 pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-32 pc-reset container"><h4 class="pencraft pc-reset line-height-24-jnGwiv font-display-nhmvtD size-20-P_cSRT weight-bold-DmI9lw reset-IxiVJZ">Discussion about this post</h4><div class="pencraft pc-alignSelf-flex-start pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-position-relative pc-minWidth-0 pc-reset bg-primary-zk6FDl pc-borderRadius-sm overflow-hidden-WdpwT6"><div aria-label="Select discussion type" role="tablist" aria-orientation="horizontal" class="pencraft pc-display-flex pc-gap-4 pc-padding-4 pc-position-relative pc-reset cursor-default-flE2S1 outline-detail-vcQLyr pc-borderRadius-sm overflow-auto-7WTsTi scrollBar-hidden-HcAIpI"><button tabindex="0" type="button" id="headlessui-tabs-tab-P0-38" role="tab" aria-selected="true" data-headlessui-state="selected" class="pencraft pc-reset pencraft segment-LBFzmC buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_tertiary-rlke8z size_sm-G3LciD">Comments</button><button tabindex="-1" type="button" id="headlessui-tabs-tab-P0-39" role="tab" aria-selected="false" data-headlessui-state="" class="pencraft pc-reset pencraft segment-LBFzmC buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_quaternary-kpMibu size_sm-G3LciD">Restacks</button><div class="pencraft pc-position-absolute pc-height-32 pc-reset bg-secondary-UUD3_J pc-borderRadius-xs sizing-border-box-DggLA4 highlight-U002IP" style="--highlight-width: 81.26250457763672px; --highlight-x: 0px;"></div></div><div class="pencraft pc-display-flex pc-alignItems-center pc-reset arrowButtonContainer-O4uSiH arrowButtonOverlaidContainer-t10AyH left-Tg8vqp"><div class="overlay-zrMCxn primary-lv_sOW"></div></div><div class="pencraft pc-display-flex pc-alignItems-center pc-reset arrowButtonContainer-O4uSiH arrowButtonOverlaidContainer-t10AyH right-i3oWGi"><div class="overlay-zrMCxn primary-lv_sOW"></div></div></div></div></div><div class="single-post-section comments-section"><div class="container"><div class="visibility-check"></div><div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"><div data-test-id="comment-input" class="pencraft pc-display-flex pc-reset flex-grow-rzmknG"><form class="form-CkZ7Kt"><div class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><div title="User" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!owWd!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 32w, https://substackcdn.com/image/fetch/$s_!owWd!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 64w, https://substackcdn.com/image/fetch/$s_!owWd!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/default-dark.jpg" sizes="32px" alt="User&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!owWd!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 32w, https://substackcdn.com/image/fetch/$s_!owWd!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 64w, https://substackcdn.com/image/fetch/$s_!owWd!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-dark.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-8 pc-reset flex-grow-rzmknG"><textarea name="body" placeholder="Write a comment..." aria-label="Write a comment..." rows="4" class="pencraft input-qHk4bN autogrowing-_ipn9Y textarea-GbEjRX inputText-pV_yWb" style="height: 96px;"></textarea><div style="height: 0px; transition: height 250ms var(--animation-smooth), opacity 250ms var(--animation-smooth); display: block; flex-direction: column; opacity: 0;"><div style="padding-top: 0.05px; padding-bottom: 0.05px; display: block; flex: 0 0 auto; flex-direction: column; transition: transform 250ms var(--animation-smooth);"></div></div></div></form></div></div><div class="comment-list post-page-root-comment-list"><div class="comment-list-items"><div class="comment"><div id="comment-143691105" class="comment-anchor"></div><div id="comment-143691105-reply" class="comment-anchor"></div><div role="article" aria-label="Comment by Dr. Ashish Bamania" class="pencraft pc-display-flex pc-gap-12 pc-paddingBottom-12 pc-reset comment-content"><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/155457308-dr-ashish-bamania?utm_source=comment" aria-label="View Dr. Ashish Bamania&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6" style="--scale: 32px;"><div title="Dr. Ashish Bamania" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!1rS7!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 32w, https://substackcdn.com/image/fetch/$s_!1rS7!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 64w, https://substackcdn.com/image/fetch/$s_!1rS7!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/f41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.jpg" sizes="32px" alt="Dr. Ashish Bamania&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!1rS7!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 32w, https://substackcdn.com/image/fetch/$s_!1rS7!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 64w, https://substackcdn.com/image/fetch/$s_!1rS7!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff41b7f65-55d7-4099-969a-931c2ddd2f5f_612x612.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-4 pc-reset"><div class="pencraft pc-display-flex pc-minWidth-0 pc-gap-8 pc-alignItems-center pc-height-20 pc-reset line-height-20-t4M0El font-text-qe4AeH size-15-Psle70 weight-regular-mUq6Gb"><div class="pencraft pc-display-flex pc-minWidth-0 pc-gap-6 pc-alignItems-center pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-gap-6 pc-reset line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ"><span class="pencraft pc-reset weight-medium-fw81nC reset-IxiVJZ"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm inline-lJXy8b"><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a href="https://substack.com/profile/155457308-dr-ashish-bamania?utm_source=substack-feed-item" showback="true" class="link-LIBpto">Dr. Ashish Bamania</a></span></div></span></div><div class="publicationHoverCardTarget-sPJ4jb"></div><a href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comment/143691105" rel="nofollow" native="true" title="Aug 9, 2025, 6:24 PM" class="pencraft pc-reset color-secondary-ls1g8s decoration-hover-underline-ClDVRM reset-IxiVJZ"><span class="pencraft pc-reset color-secondary-ls1g8s line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ">Aug 9</span></a></div></div><div class="pencraft pc-display-flex pc-gap-4 pc-reset"><button tabindex="-1" type="button" class="pencraft pc-display-flex pc-gap-4 pc-height-20 pc-paddingLeft-6 pc-paddingRight-6 pc-paddingTop-2 pc-paddingBottom-2 pc-alignItems-center pc-reset cursor-inherit-LxLBJ6 pc-borderRadius-xs size-11-NuY2Zx weight-medium-fw81nC pencraft tag-XbOVLt theme_accent-Y2sqZY priority_secondary-outline-RpooJS"><div class="pencraft pc-display-flex pc-alignItems-center pc-reset leading-mI5Ihl fillIcon-dQ0mii"><svg role="img" width="14" height="14" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="2.5" stroke="#000" xmlns="http://www.w3.org/2000/svg" style="height: 14px; width: 14px;"><g><title></title><path stroke="none" d="M9.99915 16.7256C9.90515 16.7256 9.79102 16.692 9.65674 16.6249C9.52246 16.5622 9.3949 16.4906 9.27405 16.41C8.02974 15.6044 6.94657 14.7584 6.02454 13.8722C5.10697 12.9815 4.3953 12.0662 3.88953 11.1262C3.38375 10.1818 3.13086 9.23067 3.13086 8.27283C3.13086 7.63725 3.23157 7.05762 3.43298 6.53394C3.63888 6.01025 3.92086 5.55819 4.27893 5.17773C4.64148 4.79728 5.05774 4.50635 5.52771 4.30493C6.00216 4.09904 6.51241 3.99609 7.05847 3.99609C7.73433 3.99609 8.31844 4.16618 8.81079 4.50635C9.30762 4.84652 9.70374 5.28963 9.99915 5.83569C10.299 5.28516 10.6951 4.84204 11.1875 4.50635C11.6843 4.16618 12.2707 3.99609 12.9465 3.99609C13.4836 3.99609 13.9894 4.09904 14.4639 4.30493C14.9428 4.50635 15.3613 4.79728 15.7194 5.17773C16.0774 5.55819 16.3572 6.01025 16.5586 6.53394C16.7645 7.05762 16.8674 7.63725 16.8674 8.27283C16.8674 9.23067 16.6145 10.1818 16.1088 11.1262C15.603 12.0662 14.8891 12.9815 13.967 13.8722C13.0495 14.7584 11.9708 15.6044 10.731 16.41C10.6056 16.4906 10.4758 16.5622 10.3416 16.6249C10.2118 16.692 10.0976 16.7256 9.99915 16.7256Z"></path></g></svg></div>Liked by Sebastian Raschka, PhD</button></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset flex-grow-rzmknG"></div><div id="trigger43" aria-expanded="false" aria-haspopup="dialog" aria-controls="dialog44" aria-label="View more" class="pencraft pc-display-flex pc-reset triggerContainer-eX588u"><button tabindex="0" type="button" aria-label="Ellipsis" class="pencraft pc-reset pencraft trigger-j08Uop iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_quaternary-kpMibu"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-ellipsis"><circle cx="12" cy="12" r="1"></circle><circle cx="19" cy="12" r="1"></circle><circle cx="5" cy="12" r="1"></circle></svg></button></div></div><div class="comment-body"><p><span>Love this article! Quite helpful as always!</span></p><div role="button" class="show-all-toggle"><div class="show-all-toggle-label">Expand full comment</div></div></div><div class="pencraft pc-display-flex pc-gap-16 pc-paddingTop-8 pc-justifyContent-flex-start pc-alignItems-center pc-reset comment-actions withShareButton-hQzuEn"><span class="pencraft pc-reset color-pub-secondary-text-hGQ02T decoration-hover-underline-ClDVRM reset-IxiVJZ"><a href="javascript:void(0)" class="like-button"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><div class="pencraft pc-display-flex pc-reset reaction-container"><svg role="img" width="24" height="24" viewBox="0 0 24 24" fill="#000000" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="animation"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><svg role="img" width="16" height="16" viewBox="0 0 24 24" fill="transparent" stroke-width="2" stroke="var(--color-fg-secondary-themed)" xmlns="http://www.w3.org/2000/svg" style="height: 16px; width: 16px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="transparent" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg></div><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA like-count">Like (3)</div></div></a></span><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a class="pencraft pc-reset link-_X6et2 link-LIBpto"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Reply</div></div></a></span><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a class="pencraft pc-reset link-_X6et2 link-LIBpto"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Share</div></div></a></span></div><div style="height: 0px; transition: height 250ms var(--animation-smooth), opacity 250ms var(--animation-smooth); display: block; flex-direction: column; opacity: 0;"><div style="padding-top: 0.05px; padding-bottom: 0.05px; display: block; flex: 0 0 auto; flex-direction: column; transition: transform 250ms var(--animation-smooth);"></div></div></div></div></div><div class="comment"><div id="comment-143681212" class="comment-anchor"></div><div id="comment-143681212-reply" class="comment-anchor"></div><div role="article" aria-label="Comment by Zupo Llask" class="pencraft pc-display-flex pc-gap-12 pc-paddingBottom-12 pc-reset comment-content"><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/profile/108040817-zupo-llask?utm_source=comment" aria-label="View Zupo Llask&#39;s profile" class="pencraft pc-display-contents pc-reset"><div tabindex="0" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA animate-XFJxE4 outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 pressable-sm-YIJFKJ showFocus-sk_vEm container-TAtrWj interactive-UkK0V6" style="--scale: 32px;"><div title="Zupo Llask" class="pencraft pc-display-flex pc-width-32 pc-height-32 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 32px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rRGT!,w_32,h_32,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!rRGT!,w_64,h_64,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!rRGT!,w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 96w" sizes="32px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png" sizes="32px" alt="Zupo Llask&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!rRGT!,w_32,h_32,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 32w, https://substackcdn.com/image/fetch/$s_!rRGT!,w_64,h_64,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 64w, https://substackcdn.com/image/fetch/$s_!rRGT!,w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F265d57f5-46e2-4944-9273-3a742ffda70a_144x144.png 96w" width="32" height="32" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></a></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-4 pc-reset"><div class="pencraft pc-display-flex pc-minWidth-0 pc-gap-8 pc-alignItems-center pc-height-20 pc-reset line-height-20-t4M0El font-text-qe4AeH size-15-Psle70 weight-regular-mUq6Gb"><div class="pencraft pc-display-flex pc-minWidth-0 pc-gap-6 pc-alignItems-center pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-gap-6 pc-reset line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ"><span class="pencraft pc-reset weight-medium-fw81nC reset-IxiVJZ"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm inline-lJXy8b"><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a href="https://substack.com/profile/108040817-zupo-llask?utm_source=substack-feed-item" showback="true" class="link-LIBpto">Zupo Llask</a></span></div></span></div><div class="publicationHoverCardTarget-sPJ4jb"></div><a href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comment/143681212" rel="nofollow" native="true" title="Aug 9, 2025, 5:38 PM" class="pencraft pc-reset color-secondary-ls1g8s decoration-hover-underline-ClDVRM reset-IxiVJZ"><span class="pencraft pc-reset color-secondary-ls1g8s line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ">Aug 9</span></a></div></div><div class="pencraft pc-display-flex pc-gap-4 pc-reset"><button tabindex="-1" type="button" class="pencraft pc-display-flex pc-gap-4 pc-height-20 pc-paddingLeft-6 pc-paddingRight-6 pc-paddingTop-2 pc-paddingBottom-2 pc-alignItems-center pc-reset cursor-inherit-LxLBJ6 pc-borderRadius-xs size-11-NuY2Zx weight-medium-fw81nC pencraft tag-XbOVLt theme_accent-Y2sqZY priority_secondary-outline-RpooJS"><div class="pencraft pc-display-flex pc-alignItems-center pc-reset leading-mI5Ihl fillIcon-dQ0mii"><svg role="img" width="14" height="14" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="2.5" stroke="#000" xmlns="http://www.w3.org/2000/svg" style="height: 14px; width: 14px;"><g><title></title><path stroke="none" d="M9.99915 16.7256C9.90515 16.7256 9.79102 16.692 9.65674 16.6249C9.52246 16.5622 9.3949 16.4906 9.27405 16.41C8.02974 15.6044 6.94657 14.7584 6.02454 13.8722C5.10697 12.9815 4.3953 12.0662 3.88953 11.1262C3.38375 10.1818 3.13086 9.23067 3.13086 8.27283C3.13086 7.63725 3.23157 7.05762 3.43298 6.53394C3.63888 6.01025 3.92086 5.55819 4.27893 5.17773C4.64148 4.79728 5.05774 4.50635 5.52771 4.30493C6.00216 4.09904 6.51241 3.99609 7.05847 3.99609C7.73433 3.99609 8.31844 4.16618 8.81079 4.50635C9.30762 4.84652 9.70374 5.28963 9.99915 5.83569C10.299 5.28516 10.6951 4.84204 11.1875 4.50635C11.6843 4.16618 12.2707 3.99609 12.9465 3.99609C13.4836 3.99609 13.9894 4.09904 14.4639 4.30493C14.9428 4.50635 15.3613 4.79728 15.7194 5.17773C16.0774 5.55819 16.3572 6.01025 16.5586 6.53394C16.7645 7.05762 16.8674 7.63725 16.8674 8.27283C16.8674 9.23067 16.6145 10.1818 16.1088 11.1262C15.603 12.0662 14.8891 12.9815 13.967 13.8722C13.0495 14.7584 11.9708 15.6044 10.731 16.41C10.6056 16.4906 10.4758 16.5622 10.3416 16.6249C10.2118 16.692 10.0976 16.7256 9.99915 16.7256Z"></path></g></svg></div>Liked by Sebastian Raschka, PhD</button></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset flex-grow-rzmknG"></div><div id="trigger45" aria-expanded="false" aria-haspopup="dialog" aria-controls="dialog46" aria-label="View more" class="pencraft pc-display-flex pc-reset triggerContainer-eX588u"><button tabindex="0" type="button" aria-label="Ellipsis" class="pencraft pc-reset pencraft trigger-j08Uop iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_sm-G3LciD priority_quaternary-kpMibu"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-ellipsis"><circle cx="12" cy="12" r="1"></circle><circle cx="19" cy="12" r="1"></circle><circle cx="5" cy="12" r="1"></circle></svg></button></div></div><div class="comment-body"><p><span>Dear Sebastian,</span></p><p><span>What about HRM?</span></p><p><span><a href="https://github.com/sapientinc/HRM" target="_blank" rel="nofollow ugc noopener" class="linkified">https://github.com/sapientinc/HRM</a></span></p><p><span><a href="https://arxiv.org/abs/2506.21734" target="_blank" rel="nofollow ugc noopener" class="linkified">https://arxiv.org/abs/2506.21734</a> </span></p><p><span>Do you already have a say about it?</span></p><p><span>TY for all your work! 🙏</span></p><div role="button" class="show-all-toggle"><div class="show-all-toggle-label">Expand full comment</div></div></div><div class="pencraft pc-display-flex pc-gap-16 pc-paddingTop-8 pc-justifyContent-flex-start pc-alignItems-center pc-reset comment-actions withShareButton-hQzuEn"><span class="pencraft pc-reset color-pub-secondary-text-hGQ02T decoration-hover-underline-ClDVRM reset-IxiVJZ"><a href="javascript:void(0)" class="like-button"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><div class="pencraft pc-display-flex pc-reset reaction-container"><svg role="img" width="24" height="24" viewBox="0 0 24 24" fill="#000000" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="animation"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><svg role="img" width="16" height="16" viewBox="0 0 24 24" fill="transparent" stroke-width="2" stroke="var(--color-fg-secondary-themed)" xmlns="http://www.w3.org/2000/svg" style="height: 16px; width: 16px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="transparent" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg></div><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA like-count">Like (3)</div></div></a></span><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a class="pencraft pc-reset link-_X6et2 link-LIBpto"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Reply</div></div></a></span><span class="pencraft pc-reset decoration-hover-underline-ClDVRM reset-IxiVJZ"><a class="pencraft pc-reset link-_X6et2 link-LIBpto"><div class="pencraft pc-display-flex pc-gap-6 pc-alignItems-center pc-reset"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-fg-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><div class="pencraft pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA">Share</div></div></a></span></div><div style="height: 0px; transition: height 250ms var(--animation-smooth), opacity 250ms var(--animation-smooth); display: block; flex-direction: column; opacity: 0;"><div style="padding-top: 0.05px; padding-bottom: 0.05px; display: block; flex: 0 0 auto; flex-direction: column; transition: transform 250ms var(--animation-smooth);"></div></div></div></div><div class="more-replies-container"><a href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comment/143681212" class="more-replies">1 reply by Sebastian Raschka, PhD</a></div></div></div></div><a href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the/comments" class="more-comments">43 more comments...</a></div></div></div><div class="single-post-section"><div class="container"><div class="visibility-check"></div><div aria-label="Top Posts Footer" role="region" class="pencraft pc-paddingTop-24 pc-paddingBottom-24 pc-reset" style="margin-left: -8px; margin-right: -8px;"><div class="portable-archive"><div aria-label="Archive sort tabs" role="navigation" class="pencraft pc-display-flex pc-gap-12 pc-paddingLeft-8 pc-paddingRight-8 pc-paddingBottom-16 pc-justifyContent-space-between pc-alignItems-center pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-position-relative pc-minWidth-0 pc-reset bg-primary-zk6FDl pc-borderRadius-sm overflow-hidden-WdpwT6"><div aria-label="Tabs" role="tablist" aria-orientation="horizontal" class="pencraft pc-display-flex pc-gap-4 pc-padding-4 pc-position-relative pc-reset cursor-default-flE2S1 outline-detail-vcQLyr pc-borderRadius-sm overflow-auto-7WTsTi scrollBar-hidden-HcAIpI"><button tabindex="0" type="button" id="headlessui-tabs-tab-P0-40" role="tab" aria-selected="true" data-headlessui-state="selected" class="pencraft pc-reset pencraft segment-LBFzmC buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_tertiary-rlke8z size_sm-G3LciD">Top</button><button tabindex="-1" type="button" id="headlessui-tabs-tab-P0-41" role="tab" aria-selected="false" data-headlessui-state="" class="pencraft pc-reset pencraft segment-LBFzmC buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_quaternary-kpMibu size_sm-G3LciD">Latest</button><button tabindex="-1" type="button" id="headlessui-tabs-tab-P0-42" role="tab" aria-selected="false" data-headlessui-state="" class="pencraft pc-reset pencraft segment-LBFzmC buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_quaternary-kpMibu size_sm-G3LciD">Discussions</button><div class="pencraft pc-position-absolute pc-height-32 pc-reset bg-secondary-UUD3_J pc-borderRadius-xs sizing-border-box-DggLA4 highlight-U002IP" style="--highlight-width: 39.11249923706055px; --highlight-x: 0px;"></div></div><div class="pencraft pc-display-flex pc-alignItems-center pc-reset arrowButtonContainer-O4uSiH arrowButtonOverlaidContainer-t10AyH left-Tg8vqp"><div class="overlay-zrMCxn primary-lv_sOW"></div></div><div class="pencraft pc-display-flex pc-alignItems-center pc-reset arrowButtonContainer-O4uSiH arrowButtonOverlaidContainer-t10AyH right-i3oWGi"><div class="overlay-zrMCxn primary-lv_sOW"></div></div></div><button tabindex="0" type="button" aria-label="Search" class="pencraft pc-reset pencraft iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></button></div><div class="portable-archive-list"><div><div class="container-O1YsI6 two-column-list-BLHtzo two-column-list--with-dividers-cHfR0M"><div aria-label="Post preview for The Big LLM Architecture Comparison" role="article" class="pencraft pc-display-flex pc-flexDirection-column pc-padding-8 pc-position-relative pc-reset pc-borderRadius-sm container-H2dyKk"><div class="container-Qnseki"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-4 pc-position-relative pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" data-testid="post-preview-title" class="pencraft pc-reset color-pub-primary-text-NyXPlw font-pub-headings-FE5byy clamp-y7pNm8 clamp-3-lxFDfR reset-IxiVJZ" style="font-size: 19px; line-height: 26px;">The Big LLM Architecture Comparison</a></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison" class="pencraft pc-reset color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-15-Psle70 clamp-y7pNm8 clamp-2-kM02pu reset-IxiVJZ">From DeepSeek-V3 to Kimi K2: A Look At Modern LLM Architecture Design</a></div><div class="pencraft pc-display-inline pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA"><time datetime="2025-07-19T11:11:10.901Z" class="date-rtYe1v">Jul 19</time>&nbsp;<span class="dividerChar-SbAJEi">•</span>&nbsp;<span class="pencraft pc-reset reset-IxiVJZ"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/@rasbt" class="link-HFGLqU">Sebastian Raschka, PhD</a></div></span></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset actions-YFg47u"><div class="post-ufi style-compressed justified themed"><div class="like-button-container post-ufi-button style-compressed"><a role="button" aria-label="Like (1,181)" aria-pressed="false" class="post-ufi-button style-compressed has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><div class="label">1,181</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><a role="button" href="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison/comments" aria-label="View comments (60)" class="post-ufi-button style-compressed post-ufi-comment-button has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></g></svg><div class="label">60</div></a><a role="button" class="post-ufi-button style-compressed no-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><path d="M21 3V8M21 8H16M21 8L18 5.29962C16.7056 4.14183 15.1038 3.38328 13.3879 3.11547C11.6719 2.84766 9.9152 3.08203 8.32951 3.79031C6.74382 4.49858 5.39691 5.65051 4.45125 7.10715C3.5056 8.5638 3.00158 10.2629 3 11.9996M3 21V16M3 16H8M3 16L6 18.7C7.29445 19.8578 8.89623 20.6163 10.6121 20.8841C12.3281 21.152 14.0848 20.9176 15.6705 20.2093C17.2562 19.501 18.6031 18.3491 19.5487 16.8925C20.4944 15.4358 20.9984 13.7367 21 12" stroke-linecap="round" stroke-linejoin="round"></path></g></svg></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div><a role="button" href="javascript:void(0)" aria-label="View share options" class="post-ufi-button style-compressed no-label with-border"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share icon"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg></a></div></div></div><div><div class="image-tkPTAj container-XxSyR3" style="aspect-ratio: 1.5 / 1;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LmVE!,w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.png"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.jpg" sizes="(min-width:768px) 50vw, 100vw" alt="" width="320" height="213" loading="lazy" class="img-OACg1c image-nBNbRY pencraft pc-reset" style="aspect-ratio: 1.5 / 1;"></picture></div></div></div></div><div class="pencraft pc-display-flex pc-reset border-bottom-detail-themed-Ua9186 divider-QOeHtM"></div><div aria-label="Post preview for Understanding Reasoning LLMs" role="article" class="pencraft pc-display-flex pc-flexDirection-column pc-padding-8 pc-position-relative pc-reset pc-borderRadius-sm container-H2dyKk"><div class="container-Qnseki"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-4 pc-position-relative pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/understanding-reasoning-llms" data-testid="post-preview-title" class="pencraft pc-reset color-pub-primary-text-NyXPlw font-pub-headings-FE5byy clamp-y7pNm8 clamp-3-lxFDfR reset-IxiVJZ" style="font-size: 19px; line-height: 26px;">Understanding Reasoning LLMs</a></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/understanding-reasoning-llms" class="pencraft pc-reset color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-15-Psle70 clamp-y7pNm8 clamp-2-kM02pu reset-IxiVJZ">Methods and Strategies for Building and Refining Reasoning Models</a></div><div class="pencraft pc-display-inline pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA"><time datetime="2025-02-05T12:11:39.216Z" class="date-rtYe1v">Feb 5</time>&nbsp;<span class="dividerChar-SbAJEi">•</span>&nbsp;<span class="pencraft pc-reset reset-IxiVJZ"><div class="profile-hover-card-target profileHoverCardTarget-PBxvGm"><a href="https://substack.com/@rasbt" class="link-HFGLqU">Sebastian Raschka, PhD</a></div></span></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset actions-YFg47u"><div class="post-ufi style-compressed justified themed"><div class="like-button-container post-ufi-button style-compressed"><a role="button" aria-label="Like (1,098)" aria-pressed="false" class="post-ufi-button style-compressed has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><div class="label">1,098</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><a role="button" href="https://magazine.sebastianraschka.com/p/understanding-reasoning-llms/comments" aria-label="View comments (40)" class="post-ufi-button style-compressed post-ufi-comment-button has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></g></svg><div class="label">40</div></a><a role="button" class="post-ufi-button style-compressed no-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><path d="M21 3V8M21 8H16M21 8L18 5.29962C16.7056 4.14183 15.1038 3.38328 13.3879 3.11547C11.6719 2.84766 9.9152 3.08203 8.32951 3.79031C6.74382 4.49858 5.39691 5.65051 4.45125 7.10715C3.5056 8.5638 3.00158 10.2629 3 11.9996M3 21V16M3 16H8M3 16L6 18.7C7.29445 19.8578 8.89623 20.6163 10.6121 20.8841C12.3281 21.152 14.0848 20.9176 15.6705 20.2093C17.2562 19.501 18.6031 18.3491 19.5487 16.8925C20.4944 15.4358 20.9984 13.7367 21 12" stroke-linecap="round" stroke-linejoin="round"></path></g></svg></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div><a role="button" href="javascript:void(0)" aria-label="View share options" class="post-ufi-button style-compressed no-label with-border"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share icon"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg></a></div></div></div><div><div class="image-tkPTAj container-XxSyR3" style="aspect-ratio: 1.5 / 1;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!QwUc!,w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6ebc5c9-461f-4d3a-889b-b8ea4e14e5ba_1600x830.png"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/d6ebc5c9-461f-4d3a-889b-b8ea4e14e5ba_1600x830.jpg" sizes="(min-width:768px) 50vw, 100vw" alt="" width="320" height="213" loading="lazy" class="img-OACg1c image-nBNbRY pencraft pc-reset" style="aspect-ratio: 1.5 / 1;"></picture></div></div></div></div><div class="pencraft pc-display-flex pc-reset border-bottom-detail-themed-Ua9186 divider-QOeHtM"></div><div aria-label="Post preview for Understanding and Coding Self-Attention, Multi-Head Attention, Causal-Attention, and Cross-Attention in LLMs" role="article" class="pencraft pc-display-flex pc-flexDirection-column pc-padding-8 pc-position-relative pc-reset pc-borderRadius-sm container-H2dyKk"><div class="container-Qnseki"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-4 pc-position-relative pc-reset flex-grow-rzmknG"><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention" data-testid="post-preview-title" class="pencraft pc-reset color-pub-primary-text-NyXPlw font-pub-headings-FE5byy clamp-y7pNm8 clamp-3-lxFDfR reset-IxiVJZ" style="font-size: 19px; line-height: 26px;">Understanding and Coding Self-Attention, Multi-Head Attention, Causal-Attention, and Cross-Attention in LLMs</a></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset"><a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention" class="pencraft pc-reset color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-15-Psle70 clamp-y7pNm8 clamp-2-kM02pu reset-IxiVJZ">This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama.</a></div><div class="pencraft pc-display-inline pc-reset color-pub-secondary-text-hGQ02T line-height-20-t4M0El font-meta-MWBumP size-11-NuY2Zx weight-medium-fw81nC transform-uppercase-yKDgcq reset-IxiVJZ meta-EgzBVA"><div class="icon-cvHqCn"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-lock"><rect width="18" height="11" x="3" y="11" rx="2" ry="2"></rect><path d="M7 11V7a5 5 0 0 1 10 0v4"></path></svg></div><time datetime="2024-01-14T11:55:06.449Z" class="date-rtYe1v">Jan 14, 2024</time></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-reset actions-YFg47u"><div class="post-ufi style-compressed justified themed"><div class="like-button-container post-ufi-button style-compressed"><a role="button" aria-label="Like (386)" aria-pressed="false" class="post-ufi-button style-compressed has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-heart"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5 0 0 0 16.5 3c-1.76 0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5 0 0 0 2 8.5c0 2.3 1.5 4.05 3 5.5l7 7Z"></path></svg></g></svg><div class="label">386</div></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><a role="button" href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention/comments" aria-label="View comments (41)" class="post-ufi-button style-compressed post-ufi-comment-button has-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="#000000" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-message-circle"><path d="M7.9 20A9 9 0 1 0 4 16.1L2 22Z"></path></svg></g></svg><div class="label">41</div></a><a role="button" class="post-ufi-button style-compressed no-label with-border"><svg role="img" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke-width="2" stroke="#000" xmlns="http://www.w3.org/2000/svg" class="icon" style="height: 14px; width: 14px;"><g><title></title><path d="M21 3V8M21 8H16M21 8L18 5.29962C16.7056 4.14183 15.1038 3.38328 13.3879 3.11547C11.6719 2.84766 9.9152 3.08203 8.32951 3.79031C6.74382 4.49858 5.39691 5.65051 4.45125 7.10715C3.5056 8.5638 3.00158 10.2629 3 11.9996M3 21V16M3 16H8M3 16L6 18.7C7.29445 19.8578 8.89623 20.6163 10.6121 20.8841C12.3281 21.152 14.0848 20.9176 15.6705 20.2093C17.2562 19.501 18.6031 18.3491 19.5487 16.8925C20.4944 15.4358 20.9984 13.7367 21 12" stroke-linecap="round" stroke-linejoin="round"></path></g></svg></a><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div><a role="button" href="javascript:void(0)" aria-label="View share options" class="post-ufi-button style-compressed no-label with-border"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-share icon"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg></a></div></div></div><div><div class="image-tkPTAj container-XxSyR3" style="aspect-ratio: 1.5 / 1;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!3NS4!,w_320,h_213,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.jpg" sizes="(min-width:768px) 50vw, 100vw" alt="" width="320" height="213" loading="lazy" class="img-OACg1c image-nBNbRY pencraft pc-reset" style="aspect-ratio: 1.5 / 1;"></picture></div></div></div></div></div></div><div class="pencraft pc-display-flex pc-paddingLeft-8 pc-paddingRight-8 pc-paddingTop-16 pc-reset"><button tabindex="0" type="button" data-testid="archive-view-all" data-href="/archive?sort=top" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_secondary-S63h9o size_md-gCDS3o">See all<svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right"><path d="m9 18 6-6-6-6"></path></svg></button></div></div></div></div></div></div><div class="visibility-check"></div><div class="subscribe-footer"><div class="container"><p>Ready for more?</p><div><a href="https://magazine.sebastianraschka.com/subscribe?utm_source=ready-for-more" native="true" class="cta paid-cta"><button tabindex="0" type="button" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_primary-RfbeYt size_md-gCDS3o"><b>Upgrade to paid</b></button></a></div></div></div></div></div></div><div class="footer-wrap publication-footer"><div class="visibility-check"></div><div class="footer themed-background"><div class="container"><div class="footer-blurbs"><div class="footer-copyright-blurb">© 2025 Raschka AI Research (RAIR) Lab LLC</div><div class="footer-terms-blurb"><a href="https://substack.com/privacy" target="_blank" rel="noopener" class="pencraft pc-reset decoration-underline-ClTkYc">Privacy</a><span> ∙ </span><a href="https://substack.com/tos" target="_blank" rel="noopener" class="pencraft pc-reset decoration-underline-ClTkYc">Terms</a><span> ∙ </span><a href="https://substack.com/ccpa#personal-data-collected" target="_blank" rel="noopener" class="pencraft pc-reset decoration-underline-ClTkYc">Collection notice</a></div></div><div class="footer-buttons"><a native="true" href="https://substack.com/signup?utm_source=substack&amp;utm_medium=web&amp;utm_content=footer" class="footer-substack-cta start-publishing"><svg role="img" width="1000" height="1000" viewBox="0 0 1000 1000" fill="#ff6719" stroke-width="1.8" stroke="none" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M764.166 348.371H236.319V419.402H764.166V348.371Z"></path><path d="M236.319 483.752V813.999L500.231 666.512L764.19 813.999V483.752H236.319Z"></path><path d="M764.166 213H236.319V284.019H764.166V213Z"></path></g></svg> Start writing</a><a native="true" href="https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&amp;utm_content=web-footer-button" class="footer-substack-cta get-the-app no-icon">Get the app</a></div><div translated="true" class="pencraft pc-reset reset-IxiVJZ footer-slogan-blurb"><a href="https://substack.com/" native="true">Substack</a> is the home for great culture</div></div></div></div><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup" style="z-index: 1001;"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div></div><div class="pencraft pc-display-contents pc-reset pubAccentTheme-rgl9Hv"></div><div inert="" role="dialog" class="modal typography out gone reader-onboarding-modal wide popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="reader-onboarding-modal-container"></div></div></div></div></div></div><div style="left: auto; right: 16px; bottom: 16px; z-index: 1001; transform: translateY(0px);" role="region" aria-label="Notification" class="pencraft pc-position-fixed pc-reset sizing-border-box-DggLA4"></div><div><div inert="" role="dialog" class="modal typography out gone popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div class="profile-updater-modal"><div class="profile-updater"><h4 class="pencraft pc-paddingBottom-20 pc-reset align-left-PENAI6 line-height-24-jnGwiv font-display-nhmvtD size-20-P_cSRT weight-bold-DmI9lw reset-IxiVJZ">Create your profile</h4><div class="pencraft pc-display-flex pc-justifyContent-center pc-alignItems-center pc-reset flex-grow-rzmknG"><div class="pencraft pc-alignSelf-flex-start pc-reset"><button tabindex="0" type="button" aria-label="Edit profile photo" class="pencraft pc-reset pencraft buttonBase-GK1x3M"><div class="pencraft pc-display-flex pc-width-120 pc-height-120 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-primary-zk6FDl border-detail-EGrm7T pc-borderRadius-full overflow-hidden-WdpwT6"><div class="pencraft pc-display-flex pc-width-120 pc-height-120 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 120px;"><div title="User" class="pencraft pc-display-flex pc-width-120 pc-height-120 pc-justifyContent-center pc-alignItems-center pc-position-relative pc-reset bg-secondary-UUD3_J flex-auto-j3S2WA outline-detail-vcQLyr pc-borderRadius-full overflow-hidden-WdpwT6 sizing-border-box-DggLA4 container-TAtrWj" style="--scale: 120px;"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_240,h_240,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 240w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_360,h_360,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 360w" sizes="120px"><img src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/default-light.jpg" sizes="120px" alt="User&#39;s avatar" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_240,h_240,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 240w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_360,h_360,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 360w" width="120" height="120" draggable="false" class="img-OACg1c object-fit-cover-u4ReeV pencraft pc-reset"></picture></div></div></div><input type="file" accept="image/*" aria-label="Upload file" tabindex="-1" class="sr-only"></button></div></div><form action="https://magazine.sebastianraschka.com/api/v1/user/profile" method="post" novalidate="" class="form "><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-20 pc-reset"><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-8 pc-reset"><label for="name" class="pencraft pc-reset cursor-inherit-LxLBJ6 color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ pencraft pencraft"><div class="pencraft pc-display-flex pc-gap-4 pc-alignItems-center pc-reset">Name<span class="pencraft pc-reset color-error-lkpu58 reset-IxiVJZ">*</span></div></label><div class="pencraft pc-display-flex pc-minWidth-0 pc-position-relative pc-reset flex-auto-j3S2WA"><input autofocus="true" placeholder="Type your name..." name="name" id="name" type="text" class="profile-name input-y4v6N4 inputText-pV_yWb"></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-8 pc-reset"><label for="handle" class="pencraft pc-reset cursor-inherit-LxLBJ6 color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ pencraft">Handle</label><div class="pencraft pc-display-flex pc-minWidth-0 pc-position-relative pc-reset flex-auto-j3S2WA"><input placeholder="Type your handle..." name="handle" id="handle" type="text" class="profile-name input-y4v6N4 inputText-pV_yWb"></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-8 pc-reset"><label for="bio" class="pencraft pc-reset cursor-inherit-LxLBJ6 color-primary-zABazT line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-medium-fw81nC reset-IxiVJZ pencraft">Bio</label><textarea placeholder="Say something about yourself..." name="bio" id="bio" rows="4" class="pencraft textarea-GbEjRX inputText-pV_yWb"></textarea></div><input type="hidden" name="confirmation_redirect_pathname" value="/p/from-gpt-2-to-gpt-oss-analyzing-the"><input type="hidden" name="photo_url"><input type="hidden" name="user_id"><input type="hidden" name="needs_photo" value="false"><input type="hidden" name="token"><div id="error-container"></div></div><div class="pencraft pc-display-flex pc-flexDirection-column pc-gap-8 pc-paddingTop-20 pc-reset"><div class="pencraft pc-paddingBottom-12 pc-reset tosCheckboxContainer-vfMi_Y"><div class="visibility-check"></div><label class="pencraft pc-display-flex pc-gap-8 pc-justifyContent-center pc-alignItems-center pc-reset tosCheckbox-XbLWCT" style="display: flex;"><div class="tosCheckboxBox-KXqPaU"><div class="pencraft pc-reset pencraft"><div tabindex="-1" class="pencraft pc-display-flex pc-justifyContent-center pc-alignItems-center pc-boxShadow-xs pc-position-relative pc-reset flex-auto-j3S2WA animate-XFJxE4 cursor-pointer-LYORKw outline-detail-vcQLyr pc-borderRadius-xs sizing-border-box-DggLA4 pencraft checkbox-h4aRbX sm-rkc_jb enabled-BlbymI unchecked-ixpycg theme_accent-BLPCPx"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-check icon-JVHTJb"><path d="M20 6 9 17l-5-5"></path></svg><input type="checkbox" role="checkbox" data-state="unselected" aria-checked="false" tabindex="0" class="pencraft"></div></div></div><div class="pencraft pc-reset color-primary-zABazT align-left-PENAI6 line-height-20-t4M0El font-text-qe4AeH size-13-hZTUKr weight-regular-mUq6Gb reset-IxiVJZ"> I agree to Substack's <a href="https://substack.com/tos" target="_blank" class="pencraft pc-reset reset-IxiVJZ" style="text-decoration: underline;">Terms of Use</a>, and acknowledge its <a href="https://substack.com/ccpa#personal-data-collected" target="_blank" class="pencraft pc-reset reset-IxiVJZ" style="text-decoration: underline;">Information Collection Notice</a> and <a href="https://substack.com/privacy" target="_blank" class="pencraft pc-reset reset-IxiVJZ" style="text-decoration: underline;">Privacy Policy</a>.</div></label></div><button tabindex="0" type="submit" disabled="" class="pencraft pc-reset pencraft buttonBase-GK1x3M buttonText-X0uSmG buttonStyle-r7yGCK priority_primary-RfbeYt size_lg-A_bUNK">Save and post comment</button></div></form></div></div></div></div></div></div></div><div inert="" role="dialog" class="modal typography out gone popup"><div class="modal-table"><div class="modal-row"><div class="modal-cell modal-content"><div class="container"><button tabindex="0" type="button" aria-label="X" data-testid="close-modal" class="pencraft pc-reset pencraft modal-btn modal-exit-btn no-margin iconButton-mq_Et5 iconButtonBase-dJGHgN buttonBase-GK1x3M buttonStyle-r7yGCK size_md-gCDS3o priority_tertiary-rlke8z"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="secondary" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-x"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></button><div data-testid="paywall" data-component-name="Paywall" role="region" aria-label="Paywall" class="paywall modal-paywall"><div translated="true" class="pencraft pc-paddingBottom-0 pc-reset reset-IxiVJZ paywall-intro">Hi <b>ajaychaudhary8104@gmail.com</b></div><h2 class="paywall-title">Only paid subscribers can comment on this post</h2><div class="paywall-cta"><a href="https://magazine.sebastianraschka.com/subscribe?simple=true&amp;next=https%3A%2F%2Fmagazine.sebastianraschka.com%2Fp%2Ffrom-gpt-2-to-gpt-oss-analyzing-the&amp;utm_source=paywall&amp;utm_medium=web&amp;utm_content=170506328" native="true"><button tabindex="0" type="button" class="pencraft pc-reset pencraft subscribe-btn subscribeButton-LcKYi7 buttonBase-GK1x3M">Subscribe</button></a></div><div class="paywall-login"><a href="https://substack.com/sign-in?redirect=%2Fp%2Ffrom-gpt-2-to-gpt-oss-analyzing-the&amp;for_pub=sebastianraschka&amp;change_user=true" native="true">Already a paid subscriber? <b>Switch accounts</b></a></div></div></div></div></div></div></div></div>
            
        </div>

        
            <script src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6c2ff3e3828e4017b7faf7b63e24cdf8.min.js.download" crossorigin="anonymous"></script>
            <script>
                window.Sentry && window.Sentry.onLoad(function() {
                    window.Sentry.init({
                        environment: window._preloads.sentry_environment,
                        dsn: window._preloads.sentry_dsn,
                    })
                })
            </script>
        


        
        
        
        <script>window._preloads        = JSON.parse("{\"isEU\":false,\"language\":\"en\",\"country\":\"IN\",\"userLocale\":{\"language\":\"en\",\"region\":\"US\",\"source\":\"accept-language\"},\"base_url\":\"https://magazine.sebastianraschka.com\",\"stripe_publishable_key\":\"pk_live_51QfnARLDSWi1i85FBpvw6YxfQHljOpWXw8IKi5qFWEzvW8HvoD8cqTulR9UWguYbYweLvA16P7LN6WZsGdZKrNkE00uGbFaOE3\",\"captcha_site_key\":\"6LdYbsYZAAAAAIFIRh8X_16GoFRLIReh-e-q6qSa\",\"pub\":{\"apple_pay_disabled\":false,\"apex_domain\":null,\"author_id\":27393275,\"byline_images_enabled\":true,\"bylines_enabled\":true,\"chartable_token\":null,\"community_enabled\":true,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"cover_photo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/a845e33e-b40d-46af-bd79-df96459df6b7_917x450.png\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"custom_domain_optional\":false,\"custom_domain\":\"magazine.sebastianraschka.com\",\"default_comment_sort\":\"best_first\",\"default_coupon\":null,\"default_group_coupon\":\"278f5ac1\",\"default_show_guest_bios\":true,\"email_banner_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/4d4190ba-b99c-4c4c-a70b-3ff514dd086b_1100x238.png\",\"email_from_name\":null,\"email_from\":null,\"embed_tracking_disabled\":false,\"explicit\":false,\"expose_paywall_content_to_search_engines\":true,\"fb_pixel_id\":null,\"fb_site_verification_token\":null,\"flagged_as_spam\":false,\"founding_subscription_benefits\":[\"Deep appreciation for your extraordinarily generous support.\"],\"free_subscription_benefits\":[\"Receive new articles\"],\"ga_pixel_id\":null,\"google_site_verification_token\":null,\"google_tag_manager_token\":null,\"hero_image\":null,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"hide_intro_subtitle\":null,\"hide_intro_title\":null,\"hide_podcast_feed_link\":false,\"homepage_type\":\"newspaper\",\"id\":1174659,\"image_thumbnails_always_enabled\":false,\"invite_only\":false,\"language\":\"en\",\"logo_url_wide\":\"https://substackcdn.com/image/fetch/$s_!xQ0c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5083e6d3-fbc9-4870-95b9-6e85d02f62a6_9366x2023.png\",\"logo_url\":\"https://substackcdn.com/image/fetch/$s_!96vs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"minimum_group_size\":2,\"moderation_enabled\":true,\"name\":\"Ahead of AI\",\"paid_subscription_benefits\":[\"Receive new articles and support the Ahead of AI magazine\",\"Earlier access to certain articles and occasional bonus articles\",\"Support independent research, writing, and compute costs\"],\"parsely_pixel_id\":null,\"payments_state\":\"enabled\",\"paywall_free_trial_enabled\":false,\"podcast_art_url\":null,\"paid_podcast_episode_art_url\":null,\"podcast_byline\":null,\"podcast_description\":null,\"podcast_enabled\":false,\"podcast_feed_url\":null,\"podcast_title\":null,\"post_preview_limit\":1000,\"primary_user_id\":27393275,\"require_clickthrough\":false,\"show_pub_podcast_tab\":false,\"show_recs_on_homepage\":true,\"subdomain\":\"sebastianraschka\",\"subscriber_invites\":0,\"support_email\":null,\"theme_var_background_pop\":\"#2096FF\",\"theme_var_color_links\":false,\"theme_var_cover_bg_color\":null,\"trial_end_override\":null,\"twitter_pixel_id\":null,\"type\":\"newsletter\",\"post_reaction_faces_enabled\":true,\"is_personal_mode\":false,\"plans\":[{\"id\":\"yearly60usd\",\"object\":\"plan\",\"active\":true,\"aggregate_usage\":null,\"amount\":6000,\"amount_decimal\":\"6000\",\"billing_scheme\":\"per_unit\",\"created\":1734874989,\"currency\":\"usd\",\"interval\":\"year\",\"interval_count\":1,\"livemode\":true,\"metadata\":{\"substack\":\"yes\"},\"meter\":null,\"nickname\":\"$60 a year\",\"product\":\"prod_RRis9CUfE0gdys\",\"tiers\":null,\"tiers_mode\":null,\"transform_usage\":null,\"trial_period_days\":null,\"usage_type\":\"licensed\",\"currency_options\":{\"aud\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":9500,\"unit_amount_decimal\":\"9500\"},\"brl\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":33000,\"unit_amount_decimal\":\"33000\"},\"cad\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":8500,\"unit_amount_decimal\":\"8500\"},\"chf\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":4800,\"unit_amount_decimal\":\"4800\"},\"dkk\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":38000,\"unit_amount_decimal\":\"38000\"},\"eur\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":5500,\"unit_amount_decimal\":\"5500\"},\"gbp\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":4400,\"unit_amount_decimal\":\"4400\"},\"mxn\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":112500,\"unit_amount_decimal\":\"112500\"},\"nok\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":60500,\"unit_amount_decimal\":\"60500\"},\"nzd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":10000,\"unit_amount_decimal\":\"10000\"},\"pln\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":22000,\"unit_amount_decimal\":\"22000\"},\"sek\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":57000,\"unit_amount_decimal\":\"57000\"},\"usd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6000,\"unit_amount_decimal\":\"6000\"}}},{\"id\":\"monthly6usd\",\"object\":\"plan\",\"active\":true,\"aggregate_usage\":null,\"amount\":600,\"amount_decimal\":\"600\",\"billing_scheme\":\"per_unit\",\"created\":1734874989,\"currency\":\"usd\",\"interval\":\"month\",\"interval_count\":1,\"livemode\":true,\"metadata\":{\"substack\":\"yes\"},\"meter\":null,\"nickname\":\"$6 a month\",\"product\":\"prod_RRisuF7bHBIY1t\",\"tiers\":null,\"tiers_mode\":null,\"transform_usage\":null,\"trial_period_days\":null,\"usage_type\":\"licensed\",\"currency_options\":{\"aud\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":1000,\"unit_amount_decimal\":\"1000\"},\"brl\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":3300,\"unit_amount_decimal\":\"3300\"},\"cad\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":900,\"unit_amount_decimal\":\"900\"},\"chf\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":500,\"unit_amount_decimal\":\"500\"},\"dkk\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":3800,\"unit_amount_decimal\":\"3800\"},\"eur\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":600,\"unit_amount_decimal\":\"600\"},\"gbp\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":500,\"unit_amount_decimal\":\"500\"},\"mxn\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":11500,\"unit_amount_decimal\":\"11500\"},\"nok\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6500,\"unit_amount_decimal\":\"6500\"},\"nzd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":1000,\"unit_amount_decimal\":\"1000\"},\"pln\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":2200,\"unit_amount_decimal\":\"2200\"},\"sek\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6000,\"unit_amount_decimal\":\"6000\"},\"usd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":600,\"unit_amount_decimal\":\"600\"}}},{\"id\":\"founding10000usd\",\"name\":\"founding10000usd\",\"nickname\":\"founding10000usd\",\"active\":true,\"amount\":10000,\"currency\":\"usd\",\"interval\":\"year\",\"interval_count\":1,\"metadata\":{\"substack\":\"yes\",\"founding\":\"yes\",\"no_coupons\":\"yes\",\"short_description\":\"Founding plan\",\"short_description_english\":\"Founding plan\",\"minimum\":\"10000\",\"minimum_local\":{\"aud\":15500,\"brl\":53500,\"cad\":14000,\"chf\":8000,\"dkk\":63500,\"eur\":8500,\"gbp\":7500,\"mxn\":184000,\"nok\":99000,\"nzd\":17000,\"pln\":36500,\"sek\":93500,\"usd\":10000}},\"currency_options\":{\"aud\":{\"unit_amount\":15500,\"tax_behavior\":\"unspecified\"},\"brl\":{\"unit_amount\":53500,\"tax_behavior\":\"unspecified\"},\"cad\":{\"unit_amount\":14000,\"tax_behavior\":\"unspecified\"},\"chf\":{\"unit_amount\":8000,\"tax_behavior\":\"unspecified\"},\"dkk\":{\"unit_amount\":63500,\"tax_behavior\":\"unspecified\"},\"eur\":{\"unit_amount\":8500,\"tax_behavior\":\"unspecified\"},\"gbp\":{\"unit_amount\":7500,\"tax_behavior\":\"unspecified\"},\"mxn\":{\"unit_amount\":184000,\"tax_behavior\":\"unspecified\"},\"nok\":{\"unit_amount\":99000,\"tax_behavior\":\"unspecified\"},\"nzd\":{\"unit_amount\":17000,\"tax_behavior\":\"unspecified\"},\"pln\":{\"unit_amount\":36500,\"tax_behavior\":\"unspecified\"},\"sek\":{\"unit_amount\":93500,\"tax_behavior\":\"unspecified\"},\"usd\":{\"unit_amount\":10000,\"tax_behavior\":\"unspecified\"}}}],\"stripe_user_id\":\"acct_1Lu1X9C70OBNvDYI\",\"stripe_country\":\"US\",\"stripe_publishable_key\":\"pk_live_51Lu1X9C70OBNvDYItYBM7APq6Q7Fz9vANfiT7y1sPUHBShLA13s7wfHqcNbk7gFH9Tzi60lZUexbZf5DHiy6fvpe00q673wHzg\",\"stripe_platform_account\":\"US\",\"automatic_tax_enabled\":false,\"author_name\":\"Sebastian Raschka, PhD\",\"author_handle\":\"rasbt\",\"author_photo_url\":\"https://substackcdn.com/image/fetch/$s_!CfW_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"author_bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"twitter_screen_name\":\"rasbt\",\"has_custom_tos\":false,\"has_custom_privacy\":false,\"theme\":{\"background_pop_color\":\"#c5030c\",\"web_bg_color\":\"#ffffff\",\"cover_bg_color\":null,\"publication_id\":1174659,\"color_links\":null,\"font_preset_heading\":null,\"font_preset_body\":\"sans\",\"font_family_headings\":null,\"font_family_body\":null,\"font_family_ui\":null,\"font_size_body_desktop\":null,\"print_secondary\":null,\"custom_css_web\":null,\"custom_css_email\":null,\"home_hero\":\"newspaper\",\"home_posts\":\"custom\",\"home_show_top_posts\":true,\"hide_images_from_list\":false,\"home_hero_alignment\":\"left\",\"home_hero_show_podcast_links\":true,\"default_post_header_variant\":null},\"threads_v2_settings\":{\"photo_replies_enabled\":true,\"first_thread_email_sent_at\":null,\"create_thread_minimum_role\":\"paid\",\"activated_at\":null,\"reader_thread_notifications_enabled\":true,\"boost_free_subscriber_chat_preview_enabled\":true,\"push_suppression_enabled\":false},\"default_group_coupon_percent_off\":\"30.00\",\"pause_return_date\":null,\"has_posts\":true,\"has_recommendations\":true,\"first_post_date\":\"2022-11-04T19:43:47.949Z\",\"has_podcast\":false,\"has_free_podcast\":false,\"has_subscriber_only_podcast\":false,\"has_community_content\":true,\"rankingDetail\":\"Hundreds of paid subscribers\",\"rankingDetailFreeIncluded\":\"Hundreds of thousands of subscribers\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Over 132,000 subscribers\",\"rankingDetailByLanguage\":{\"de\":{\"rankingDetail\":\"Hunderte von Paid-Abonnenten\",\"rankingDetailFreeIncluded\":\"Hunderttausende von Abonnenten\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"\u00DCber 132,000 Abonnenten\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"es\":{\"rankingDetail\":\"Cientos de suscriptores de pago\",\"rankingDetailFreeIncluded\":\"Cientos de miles de suscriptores\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"M\u00E1s de 132,000 suscriptores\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"fr\":{\"rankingDetail\":\"Des centaines d'abonn\u00E9s payants\",\"rankingDetailFreeIncluded\":\"Des centaines de milliers d'abonn\u00E9s\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Plus de 132,000 abonn\u00E9s\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"pt\":{\"rankingDetail\":\"Centenas de subscritores pagos\",\"rankingDetailFreeIncluded\":\"Centenas de milhares de subscritores\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Mais de 132,000 subscritores\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"pt-br\":{\"rankingDetail\":\"Centenas de assinantes pagantes\",\"rankingDetailFreeIncluded\":\"Centenas de milhares de assinantes\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Mais de 132,000 assinantes\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"it\":{\"rankingDetail\":\"Centinaia di abbonati a pagamento\",\"rankingDetailFreeIncluded\":\"Centinaia di migliaia di abbonati\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Oltre 132,000 abbonati\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"},\"en\":{\"rankingDetail\":\"Hundreds of paid subscribers\",\"rankingDetailFreeIncluded\":\"Hundreds of thousands of subscribers\",\"rankingDetailOrderOfMagnitude\":100,\"rankingDetailFreeIncludedOrderOfMagnitude\":100000,\"rankingDetailFreeSubscriberCount\":\"Over 132,000 subscribers\",\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\"}},\"freeSubscriberCount\":\"132,000\",\"freeSubscriberCountOrderOfMagnitude\":\"132K+\",\"author_bestseller_tier\":100,\"disable_monthly_subscriptions\":false,\"disable_annual_subscriptions\":false,\"hide_post_restacks\":false,\"notes_feed_enabled\":true,\"last_chat_post_at\":null,\"primary_profile_name\":\"Sebastian Raschka, PhD\",\"primary_profile_photo_url\":\"https://substackcdn.com/image/fetch/$s_!CfW_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"no_follow\":false,\"paywall_chat\":\"free\",\"sections\":[],\"multipub_migration\":null,\"navigationBarItems\":[{\"id\":\"2564b0cc-f5ae-4cd3-8459-425ead1af79b\",\"publication_id\":1174659,\"sibling_rank\":0,\"link_title\":null,\"link_url\":null,\"section_id\":null,\"post_id\":null,\"is_hidden\":false,\"standard_key\":\"about\",\"post_tag_id\":null,\"section\":null,\"postTag\":null,\"post\":null},{\"id\":\"8973f8de-0b4a-43d3-ada7-b259e60f4eb1\",\"publication_id\":1174659,\"sibling_rank\":0,\"link_title\":\"Support\",\"link_url\":\"\",\"section_id\":null,\"post_id\":141448215,\"is_hidden\":null,\"standard_key\":null,\"post_tag_id\":null,\"section\":null,\"postTag\":null,\"post\":{\"id\":141448215,\"publication_id\":1174659,\"is_published\":true,\"title\":\"Support Independent AI Research\",\"body\":\"s3://substack-content/post/141448215/2025-08-29T00-46-24-124Z/27393275/faf0948552c9754e74c54763c646673727a15683\",\"slug\":\"supporting-ahead-of-ai\",\"post_date\":\"2024-02-07T01:47:55.040Z\",\"draft_title\":\"Support Independent AI Research\",\"draft_body\":\"s3://substack-content/post/141448215/2025-08-29T00-46-24-124Z/27393275/faf0948552c9754e74c54763c646673727a15683\",\"draft_updated_at\":\"2025-08-29T00:46:24.197Z\",\"subtitle\":\"\",\"draft_subtitle\":\"\",\"email_sent_at\":null,\"audience\":\"everyone\",\"type\":\"page\",\"podcast_url\":\"\",\"draft_podcast_url\":\"\",\"podcast_duration\":null,\"draft_podcast_duration\":null,\"podcast_art_url\":null,\"podcast_description\":null,\"podcast_subtitle\":null,\"explicit\":null,\"podcast_content\":null,\"podcast_guid\":null,\"social_title\":null,\"description\":null,\"cover_image\":null,\"imported_podcast_url\":null,\"imported_podcast_art_url\":null,\"uuid\":\"1b287a40-f5d3-402d-a231-ae1f487a5ba0\",\"write_comment_permissions\":\"everyone\",\"should_send_email\":false,\"default_comment_sort\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"updated_at\":\"2025-08-29T00:46:31.261Z\",\"canonical_url\":null,\"subscriber_set_id\":null,\"section_id\":null,\"section_chosen\":false,\"draft_section_id\":null,\"show_guest_bios\":true,\"reply_to_post_id\":null,\"should_send_free_preview\":false,\"word_count\":1255,\"video_upload_id\":null,\"draft_video_upload_id\":null,\"draft_created_at\":\"2024-02-07T01:30:32.546Z\",\"podcast_upload_id\":null,\"draft_podcast_upload_id\":null,\"voiceover_upload_id\":null,\"draft_voiceover_upload_id\":null,\"free_unlock_required\":false,\"podcast_preview_upload_id\":null,\"draft_podcast_preview_upload_id\":null,\"legacy_podcast_file_size\":null,\"syndicate_voiceover_to_rss\":false,\"audience_before_archived\":null,\"should_send_stats_email\":true,\"exempt_from_archive_paywall\":false,\"has_explicit_paywall\":false,\"inbox_sent_at\":null,\"editor_v2\":false,\"teaser_post_eligible\":true,\"has_dismissed_tk_warning\":false,\"live_stream_id\":null,\"is_draft_hidden\":false,\"meter_type\":\"none\"}},{\"id\":\"0a3636ba-c018-452f-ad43-d429671380dd\",\"publication_id\":1174659,\"sibling_rank\":2,\"link_title\":\"LLMs From Scratch Book\",\"link_url\":\"https://amzn.to/4fqvn0D\",\"section_id\":null,\"post_id\":null,\"is_hidden\":null,\"standard_key\":null,\"post_tag_id\":null,\"section\":null,\"postTag\":null,\"post\":null},{\"id\":\"af81fc3a-7ffc-46da-bc8a-8bedc3c5b31d\",\"publication_id\":1174659,\"sibling_rank\":3,\"link_title\":\"Reasoning From Scratch Book\",\"link_url\":\"https://mng.bz/Ewrj\",\"section_id\":null,\"post_id\":null,\"is_hidden\":null,\"standard_key\":null,\"post_tag_id\":null,\"section\":null,\"postTag\":null,\"post\":null}],\"contributors\":[{\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"role\":\"admin\",\"owner\":true,\"user_id\":27393275,\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\"}],\"threads_v2_enabled\":true,\"viralGiftsConfig\":{\"id\":\"2490f013-78b6-4c3a-8f8f-fad76b54c918\",\"publication_id\":1174659,\"enabled\":true,\"gifts_per_user\":5,\"gift_length_months\":1,\"send_extra_gifts\":true,\"message\":\"Machine Learning & AI trends, discussions, and educational contents to stay ahead of the field!\",\"created_at\":\"2022-11-22T16:45:58.850743+00:00\",\"updated_at\":\"2022-11-22T16:45:58.850743+00:00\",\"days_til_invite\":14,\"send_emails\":true,\"show_link\":null,\"grant_email_body\":null,\"grant_email_subject\":null},\"tier\":2,\"no_index\":false,\"can_set_google_site_verification\":true,\"can_have_sitemap\":true,\"draft_iap_advanced_plans\":[{\"sku\":\"rkFp9Ivlejn3FqgFkE\",\"publication_id\":\"1174659\",\"is_active\":true,\"price_base_units\":800,\"currency_alpha3\":\"usd\",\"period\":\"month\",\"created_at\":\"2025-04-05T02:15:57.295Z\",\"updated_at\":\"2025-04-05T02:15:57.295Z\",\"id\":\"4711\",\"payout_amount_base_units\":60,\"alternate_currencies\":{\"aud\":1300,\"brl\":4600,\"cad\":1200,\"chf\":700,\"dkk\":5500,\"eur\":800,\"gbp\":700,\"mxn\":16000,\"nok\":8500,\"nzd\":1400,\"pln\":3100,\"sek\":8000},\"display_name\":\"Ahead of AI (Monthly)\",\"display_price\":\"$8\"},{\"sku\":\"GVXZP2sSCQTJI0cybm\",\"publication_id\":\"1174659\",\"is_active\":true,\"price_base_units\":8000,\"currency_alpha3\":\"usd\",\"period\":\"year\",\"created_at\":\"2025-04-05T02:15:57.316Z\",\"updated_at\":\"2025-04-05T02:15:57.316Z\",\"id\":\"4712\",\"payout_amount_base_units\":600,\"alternate_currencies\":{\"aud\":13000,\"brl\":45500,\"cad\":11500,\"chf\":7000,\"dkk\":54500,\"eur\":7500,\"gbp\":6500,\"mxn\":160000,\"nok\":83000,\"nzd\":14000,\"pln\":31000,\"sek\":78500},\"display_name\":\"Ahead of AI (Yearly)\",\"display_price\":\"$80\"}],\"iap_advanced_plans\":[{\"sku\":\"rkFp9Ivlejn3FqgFkE\",\"publication_id\":\"1174659\",\"is_active\":true,\"price_base_units\":800,\"currency_alpha3\":\"usd\",\"period\":\"month\",\"created_at\":\"2025-04-05T02:15:57.295Z\",\"updated_at\":\"2025-04-05T02:15:57.295Z\",\"id\":\"4711\",\"payout_amount_base_units\":60,\"alternate_currencies\":{\"aud\":1300,\"brl\":4600,\"cad\":1200,\"chf\":700,\"dkk\":5500,\"eur\":800,\"gbp\":700,\"mxn\":16000,\"nok\":8500,\"nzd\":1400,\"pln\":3100,\"sek\":8000},\"display_name\":\"Ahead of AI (Monthly)\",\"display_price\":\"$8\"},{\"sku\":\"GVXZP2sSCQTJI0cybm\",\"publication_id\":\"1174659\",\"is_active\":true,\"price_base_units\":8000,\"currency_alpha3\":\"usd\",\"period\":\"year\",\"created_at\":\"2025-04-05T02:15:57.316Z\",\"updated_at\":\"2025-04-05T02:15:57.316Z\",\"id\":\"4712\",\"payout_amount_base_units\":600,\"alternate_currencies\":{\"aud\":13000,\"brl\":45500,\"cad\":11500,\"chf\":7000,\"dkk\":54500,\"eur\":7500,\"gbp\":6500,\"mxn\":160000,\"nok\":83000,\"nzd\":14000,\"pln\":31000,\"sek\":78500},\"display_name\":\"Ahead of AI (Yearly)\",\"display_price\":\"$80\"}],\"founding_plan_name_english\":\"Founding plan\",\"draft_plans\":[{\"id\":\"yearly60usd\",\"object\":\"plan\",\"active\":true,\"aggregate_usage\":null,\"amount\":6000,\"amount_decimal\":\"6000\",\"billing_scheme\":\"per_unit\",\"created\":1734874989,\"currency\":\"usd\",\"interval\":\"year\",\"interval_count\":1,\"livemode\":true,\"metadata\":{\"substack\":\"yes\"},\"meter\":null,\"nickname\":\"$60 a year\",\"product\":\"prod_RRis9CUfE0gdys\",\"tiers\":null,\"tiers_mode\":null,\"transform_usage\":null,\"trial_period_days\":null,\"usage_type\":\"licensed\",\"currency_options\":{\"aud\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":9500,\"unit_amount_decimal\":\"9500\"},\"brl\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":33000,\"unit_amount_decimal\":\"33000\"},\"cad\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":8500,\"unit_amount_decimal\":\"8500\"},\"chf\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":4800,\"unit_amount_decimal\":\"4800\"},\"dkk\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":38000,\"unit_amount_decimal\":\"38000\"},\"eur\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":5500,\"unit_amount_decimal\":\"5500\"},\"gbp\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":4400,\"unit_amount_decimal\":\"4400\"},\"mxn\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":112500,\"unit_amount_decimal\":\"112500\"},\"nok\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":60500,\"unit_amount_decimal\":\"60500\"},\"nzd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":10000,\"unit_amount_decimal\":\"10000\"},\"pln\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":22000,\"unit_amount_decimal\":\"22000\"},\"sek\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":57000,\"unit_amount_decimal\":\"57000\"},\"usd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6000,\"unit_amount_decimal\":\"6000\"}}},{\"id\":\"monthly6usd\",\"object\":\"plan\",\"active\":true,\"aggregate_usage\":null,\"amount\":600,\"amount_decimal\":\"600\",\"billing_scheme\":\"per_unit\",\"created\":1734874989,\"currency\":\"usd\",\"interval\":\"month\",\"interval_count\":1,\"livemode\":true,\"metadata\":{\"substack\":\"yes\"},\"meter\":null,\"nickname\":\"$6 a month\",\"product\":\"prod_RRisuF7bHBIY1t\",\"tiers\":null,\"tiers_mode\":null,\"transform_usage\":null,\"trial_period_days\":null,\"usage_type\":\"licensed\",\"currency_options\":{\"aud\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":1000,\"unit_amount_decimal\":\"1000\"},\"brl\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":3300,\"unit_amount_decimal\":\"3300\"},\"cad\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":900,\"unit_amount_decimal\":\"900\"},\"chf\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":500,\"unit_amount_decimal\":\"500\"},\"dkk\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":3800,\"unit_amount_decimal\":\"3800\"},\"eur\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":600,\"unit_amount_decimal\":\"600\"},\"gbp\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":500,\"unit_amount_decimal\":\"500\"},\"mxn\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":11500,\"unit_amount_decimal\":\"11500\"},\"nok\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6500,\"unit_amount_decimal\":\"6500\"},\"nzd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":1000,\"unit_amount_decimal\":\"1000\"},\"pln\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":2200,\"unit_amount_decimal\":\"2200\"},\"sek\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":6000,\"unit_amount_decimal\":\"6000\"},\"usd\":{\"custom_unit_amount\":null,\"tax_behavior\":\"unspecified\",\"unit_amount\":600,\"unit_amount_decimal\":\"600\"}}},{\"id\":\"founding10000usd\",\"name\":\"founding10000usd\",\"nickname\":\"founding10000usd\",\"active\":true,\"amount\":10000,\"currency\":\"usd\",\"interval\":\"year\",\"interval_count\":1,\"metadata\":{\"substack\":\"yes\",\"founding\":\"yes\",\"no_coupons\":\"yes\",\"short_description\":\"Founding plan\",\"short_description_english\":\"Founding plan\",\"minimum\":\"10000\",\"minimum_local\":{\"aud\":15500,\"brl\":53500,\"cad\":14000,\"chf\":8000,\"dkk\":63500,\"eur\":8500,\"gbp\":7500,\"mxn\":184000,\"nok\":99000,\"nzd\":17000,\"pln\":36500,\"sek\":93500,\"usd\":10000}},\"currency_options\":{\"aud\":{\"unit_amount\":15500,\"tax_behavior\":\"unspecified\"},\"brl\":{\"unit_amount\":53500,\"tax_behavior\":\"unspecified\"},\"cad\":{\"unit_amount\":14000,\"tax_behavior\":\"unspecified\"},\"chf\":{\"unit_amount\":8000,\"tax_behavior\":\"unspecified\"},\"dkk\":{\"unit_amount\":63500,\"tax_behavior\":\"unspecified\"},\"eur\":{\"unit_amount\":8500,\"tax_behavior\":\"unspecified\"},\"gbp\":{\"unit_amount\":7500,\"tax_behavior\":\"unspecified\"},\"mxn\":{\"unit_amount\":184000,\"tax_behavior\":\"unspecified\"},\"nok\":{\"unit_amount\":99000,\"tax_behavior\":\"unspecified\"},\"nzd\":{\"unit_amount\":17000,\"tax_behavior\":\"unspecified\"},\"pln\":{\"unit_amount\":36500,\"tax_behavior\":\"unspecified\"},\"sek\":{\"unit_amount\":93500,\"tax_behavior\":\"unspecified\"},\"usd\":{\"unit_amount\":10000,\"tax_behavior\":\"unspecified\"}}}],\"base_url\":\"https://magazine.sebastianraschka.com\",\"hostname\":\"magazine.sebastianraschka.com\",\"is_on_substack\":false,\"spotify_podcast_settings\":null,\"podcastPalette\":{\"DarkMuted\":{\"population\":72,\"rgb\":[73,153,137]},\"DarkVibrant\":{\"population\":6013,\"rgb\":[4,100,84]},\"LightMuted\":{\"population\":7,\"rgb\":[142,198,186]},\"LightVibrant\":{\"population\":3,\"rgb\":[166,214,206]},\"Muted\":{\"population\":6,\"rgb\":[92,164,156]},\"Vibrant\":{\"population\":5,\"rgb\":[76,164,146]}},\"pageThemes\":{\"podcast\":null},\"appTheme\":{\"colors\":{\"accent\":{\"name\":\"#c5030c\",\"primary\":{\"r\":197,\"g\":3,\"b\":12,\"a\":1},\"primary_hover\":{\"r\":174,\"g\":0,\"b\":0,\"a\":1},\"primary_elevated\":{\"r\":174,\"g\":0,\"b\":0,\"a\":1},\"secondary\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.2},\"contrast\":{\"r\":255,\"g\":255,\"b\":255,\"a\":1},\"bg\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.2},\"bg_hover\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.3},\"dark\":{\"primary\":{\"r\":197,\"g\":3,\"b\":12,\"a\":1},\"primary_hover\":{\"r\":219,\"g\":43,\"b\":29,\"a\":1},\"primary_elevated\":{\"r\":219,\"g\":43,\"b\":29,\"a\":1},\"secondary\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.2},\"contrast\":{\"r\":255,\"g\":255,\"b\":255,\"a\":1},\"bg\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.2},\"bg_hover\":{\"r\":197,\"g\":3,\"b\":12,\"a\":0.3}}},\"fg\":{\"primary\":{\"r\":0,\"g\":0,\"b\":0,\"a\":0.8},\"secondary\":{\"r\":0,\"g\":0,\"b\":0,\"a\":0.6},\"tertiary\":{\"r\":0,\"g\":0,\"b\":0,\"a\":0.4},\"accent\":{\"r\":197,\"g\":3,\"b\":12,\"a\":1},\"dark\":{\"primary\":{\"r\":255,\"g\":255,\"b\":255,\"a\":0.9},\"secondary\":{\"r\":255,\"g\":255,\"b\":255,\"a\":0.6},\"tertiary\":{\"r\":255,\"g\":255,\"b\":255,\"a\":0.4},\"accent\":{\"r\":239,\"g\":64,\"b\":43,\"a\":1}}},\"bg\":{\"name\":\"#ffffff\",\"hue\":{\"r\":255,\"g\":255,\"b\":255,\"a\":0},\"tint\":{\"r\":255,\"g\":255,\"b\":255,\"a\":0},\"primary\":{\"r\":255,\"g\":255,\"b\":255,\"a\":1},\"primary_hover\":{\"r\":250,\"g\":250,\"b\":250,\"a\":1},\"primary_elevated\":{\"r\":250,\"g\":250,\"b\":250,\"a\":1},\"secondary\":{\"r\":238,\"g\":238,\"b\":238,\"a\":1},\"secondary_elevated\":{\"r\":206.90096477355226,\"g\":206.90096477355175,\"b\":206.9009647735519,\"a\":1},\"tertiary\":{\"r\":219,\"g\":219,\"b\":219,\"a\":1},\"quaternary\":{\"r\":182,\"g\":182,\"b\":182,\"a\":1},\"dark\":{\"primary\":{\"r\":22,\"g\":23,\"b\":24,\"a\":1},\"primary_hover\":{\"r\":27,\"g\":28,\"b\":29,\"a\":1},\"primary_elevated\":{\"r\":27,\"g\":28,\"b\":29,\"a\":1},\"secondary\":{\"r\":35,\"g\":37,\"b\":37,\"a\":1},\"secondary_elevated\":{\"r\":41.35899397549579,\"g\":43.405356429195315,\"b\":43.40489285041963,\"a\":1},\"tertiary\":{\"r\":54,\"g\":55,\"b\":55,\"a\":1},\"quaternary\":{\"r\":90,\"g\":91,\"b\":91,\"a\":1}}}},\"cover_image\":{\"url\":\"https://substackcdn.com/image/fetch/$s_!LheM!,w_1200,h_400,c_crop,f_auto,q_auto:best,fl_progressive:steep,g_auto,b_rgb:FFFFFF/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa845e33e-b40d-46af-bd79-df96459df6b7_917x450.png\",\"height\":450,\"width\":917}},\"live_subscriber_counts\":false,\"logoPalette\":{\"Vibrant\":{\"rgb\":[236,44,52],\"population\":630},\"DarkVibrant\":{\"rgb\":[121.64608695652176,10.95391304347825,15.566086956521787],\"population\":0},\"LightVibrant\":{\"rgb\":[232,148,148],\"population\":49},\"Muted\":{\"rgb\":[140.36086956521737,12.639130434782615,17.96086956521746],\"population\":0},\"DarkMuted\":{\"rgb\":[140.36086956521737,12.639130434782615,17.96086956521746],\"population\":0},\"LightMuted\":{\"rgb\":[246,237,238],\"population\":412}}},\"confirmedLogin\":false,\"freeSignupUserId\":391278817,\"freeSignupEmail\":\"ajaychaudhary8104@gmail.com\",\"freeSignup\":true,\"hide_intro_popup\":true,\"block_auto_login\":false,\"domainInfo\":{\"isSubstack\":false,\"customDomain\":\"magazine.sebastianraschka.com\"},\"experimentFeatures\":{\"notes_ranking_v86\":\"treatment\",\"android_vertical_post_player_2\":\"control\",\"publication_ranking_v16\":\"control\",\"dpn_user_picture_instead_of_comment\":\"treatment\",\"related_notes_variations\":\"treatment_explore_button\",\"publication_search_replatform\":\"treatment\",\"search_retrieval_v2\":\"treatment\"},\"experimentExposures\":{},\"siteConfigs\":{\"score_upsell_email\":\"experiment\",\"first_chat_email_enabled\":true,\"notes_video_max_duration_minutes\":5,\"reader-onboarding-promoted-pub\":737237,\"new_commenter_approval\":false,\"pub_update_opennode_api_key\":false,\"enable_user_report_review\":true,\"zendesk_automation_cancellations\":false,\"hide_book_a_meeting_button\":false,\"mfa_action_box_enabled\":false,\"publication_max_bylines\":35,\"no_contest_charge_disputes\":false,\"feed_posts_previously_seen_weight\":0.1,\"publication_tabs_reorder\":false,\"comp_expiry_email_new_copy\":\"NONE\",\"free_unlock_required\":false,\"traffic_rule_check_enabled\":false,\"amp_emails_enabled\":false,\"enable_post_summarization\":false,\"live_stream_host_warning_message\":\"\",\"bitcoin_enabled\":false,\"minimum_ios_os_version\":\"17.0.0\",\"show_entire_square_image\":false,\"hide_subscriber_count\":false,\"publication_author_display_override\":\"\",\"ios_webview_payments_enabled\":\"control\",\"generate_pdf_tax_report\":false,\"dpn_weight_disable\":5,\"show_generic_post_importer\":false,\"enable_pledges_modal\":true,\"include_pdf_invoice\":false,\"app_upsell_after_posting_notes\":\"experiment\",\"notes_weight_watch_video\":5,\"use_post_podcast_import_batching\":true,\"meetings_v1\":false,\"exempt_from_gtm_filter\":false,\"group_sections_and_podcasts_in_menu\":false,\"boost_optin_modal_enabled\":true,\"standards_and_enforcement_features_enabled\":false,\"pub_creation_captcha_behavior\":\"risky_pubs_or_rate_limit\",\"post_blogspot_importer\":false,\"suggested_search_metadata_web_ui\":false,\"notes_weight_short_item_boost\":0.15,\"pub_tts_override\":\"default\",\"disable_monthly_subscriptions\":false,\"skip_welcome_email\":false,\"chat_reader_thread_notification_default\":false,\"scheduled_pinned_posts\":false,\"disable_redirect_outbound_utm_params\":false,\"reader_gift_referrals_enabled\":true,\"enable_bestseller_survey_modal\":false,\"dont_show_guest_byline\":false,\"like_comments_enabled\":true,\"subscription_bar_all_debug_enabled\":false,\"temporal_livestream_ended_draft\":true,\"enable_author_note_email_toggle\":false,\"meetings_embed_publication_name\":false,\"fallback_to_archive_search_on_section_pages\":false,\"livekit_track_egress_custom_base_url\":\"http://livekit-egress-custom-recorder-participant-test.s3-website-us-east-1.amazonaws.com\",\"people_you_may_know_algorithm\":\"experiment\",\"welcome_screen_blurb_override\":\"\",\"live_stream_guest_overlay\":\"control\",\"like_posts_enabled\":true,\"apply_crm_overlay_updates\":true,\"twitter_player_card_enabled\":true,\"feed_promoted_user\":false,\"writer_beta_android_enable_post_editor_v2\":false,\"show_note_stats_for_all_notes\":false,\"section_specific_csv_imports_enabled\":false,\"disable_podcast_feed_description_cta\":false,\"bypass_profile_substack_logo_detection\":false,\"use_preloaded_player_sources\":false,\"list_pruning_enabled\":false,\"facebook_connect\":false,\"opt_in_to_sections_during_subscribe\":false,\"dpn_weight_share\":2,\"underlined_colored_links\":false,\"modal_rec_variant_user\":\"control\",\"extract_stripe_receipt_url\":false,\"enable_aligned_images\":false,\"max_image_upload_mb\":64,\"enable_android_dms_writer_beta\":false,\"threads_suggested_ios_version\":null,\"pledges_disabled\":false,\"threads_minimum_ios_version\":812,\"hide_podcast_email_setup_link\":false,\"subscribe_captcha_behavior\":\"default\",\"publication_ban_sample_rate\":0,\"grant_viral_gifts_to_gift_recipients\":\"experiment\",\"ios_enable_publication_activity_tab\":false,\"custom_themes_substack_subscribe_modal\":false,\"share_viral_gift_as_link\":\"experiment\",\"opt_in_to_sections_during_subscribe_include_main_pub_newsletter\":false,\"continue_support_cta_in_newsletter_emails\":false,\"bloomberg_syndication_enabled\":false,\"lists_enabled\":false,\"ios_feed_media_content_mode\":\"fit\",\"generated_database_maintenance_mode\":false,\"allow_document_freeze\":false,\"subscription_bar_all_debug_subdomains\":null,\"podcast_main_feed_is_firehose\":false,\"pub_app_incentive_gift\":\"\",\"no_embed_redirect\":false,\"translate_mobile_app\":false,\"customized_email_from_name_for_new_follow_emails\":\"treatment\",\"spotify_open_access_sandbox_mode\":false,\"partner_data_api_enabled\":false,\"fullstory_enabled\":false,\"chat_reply_poll_interval\":3,\"dpn_weight_follow_or_subscribe\":3,\"enable_reader_marketing_page\":false,\"force_pub_links_to_use_subdomain\":false,\"always_show_cookie_banner\":false,\"hide_media_download_option\":false,\"hide_post_restacks\":false,\"feed_item_source_debug_mode\":false,\"writer_beta_android_enable_post_editor\":false,\"thefp_enable_account_menu\":false,\"enable_user_status_ui\":false,\"publication_homepage_title_display_override\":\"\",\"pub_banned_word_list\":\"\",\"post_preview_highlight_byline\":false,\"4k_video\":false,\"enable_islands_section_intent_screen\":false,\"tfp_free_week_reg_wall\":false,\"post_metering_enabled\":false,\"notifications_disabled\":\"\",\"cross_post_notification_threshold\":1000,\"facebook_connect_prod_app\":true,\"feed_enable_live_streams\":false,\"force_into_pymk_ranking\":false,\"minimum_android_version\":756,\"live_stream_krisp_noise_suppression_enabled\":false,\"enable_transcription_translations\":false,\"ios_post_video_pager_alpha_enabled\":false,\"use_og_image_as_twitter_image_for_post_previews\":false,\"always_use_podcast_channel_art_as_episode_art_in_rss\":false,\"cookie_preference_middleware_enabled\":false,\"seo_tier_override\":\"NONE\",\"no_follow_links\":false,\"publisher_api_enabled\":false,\"zendesk_support_priority\":\"default\",\"enable_post_clips_stats\":false,\"enable_subscriber_referrals_awards\":true,\"ios_profile_themes_feed_permalink_enabled\":false,\"use_publication_language_for_transcription\":false,\"show_substack_funded_gifts_tooltip\":true,\"disable_ai_transcription\":false,\"thread_permalink_preview_min_ios_version\":4192,\"android_toggle_on_website_enabled\":false,\"internal_android_enable_post_editor\":false,\"edit_profile_feed_item\":false,\"updated_inbox_ui\":false,\"web_reader_podcasts_tab\":false,\"use_temporal_thumbnail_selection_workflow\":false,\"live_stream_creation_enabled\":false,\"disable_card_element_in_europe\":false,\"enable_web_typing_indicators\":false,\"web_vitals_sample_rate\":10,\"allow_live_stream_auto_takedown\":\"true\",\"search_ranker_variant\":\"control\",\"post_advanced_search\":\"control\",\"ai_image_generation_enabled\":true,\"disable_personal_substack_initialization\":false,\"section_specific_welcome_pages\":false,\"local_payment_methods\":\"control\",\"activity_items_reads_rollout\":0,\"posts_in_rss_feed\":20,\"post_rec_endpoint\":\"\",\"publisher_dashboard_section_selector\":false,\"reader_surveys_platform_question_order\":\"36,1,4,2,3,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35\",\"ios_toggle_on_website_enabled\":false,\"login_guard_app_link_in_email\":true,\"modal_rec_variant_content\":\"control\",\"monthly_sub_is_one_off\":false,\"unread_notes_activity_digest\":\"control\",\"display_cookie_settings\":false,\"welcome_page_query_params\":false,\"enable_free_podcast_urls\":false,\"enable_linkedin_oauth\":false,\"comp_expiry_emails_disabled\":false,\"enable_description_on_polls\":false,\"use_microlink_for_instagram_embeds\":false,\"post_notification_batch_delay_ms\":30000,\"free_signup_confirmation_behavior\":\"with_email_validation\",\"ios_post_stats_for_admins\":false,\"live_stream_concurrent_viewer_count_drawer\":false,\"use_livestream_post_media_composition\":true,\"section_specific_preambles\":false,\"android_live_stream_multihost_enabled\":false,\"show_menu_on_posts\":false,\"app_upsell_follow_prompt\":\"control\",\"ios_post_subscribe_web_routing\":true,\"opt_into_all_trending_topics\":false,\"ios_writer_stats_public_launch_v2\":false,\"min_size_for_phishing_check\":1,\"enable_android_post_stats\":false,\"ios_chat_revamp_enabled\":false,\"app_onboarding_survey_email\":false,\"post_notification_batch_chunk_size\":100,\"thefp_enable_pullquote_alignment\":false,\"thefp_enable_pullquote_color\":false,\"republishing_enabled\":false,\"app_mode\":false,\"show_phone_banner\":false,\"live_stream_video_enhancer\":\"internal\",\"enable_author_pages\":false,\"enable_decagon_chat\":true,\"first_month_upsell\":\"experiment\",\"enable_fedcm\":false,\"new_user_checklist_enabled\":\"use_follower_count\",\"ios_trending_topic_note_badge\":\"experiment\",\"enable_updated_webview_checkout\":false,\"show_attached_profile_for_pub_setting\":false,\"welcome_page_update_desktop_visuals_limited\":\"experiment\",\"rss_verification_code\":\"\",\"notification_post_emails\":\"experiment\",\"ios_profile_subdomain_chips\":true,\"chat_suppress_contributor_push_option_enabled\":false,\"live_stream_invite_ttl_seconds\":600,\"feed_ranking_per_post_clip_cap\":2,\"export_hooks_enabled\":false,\"audio_encoding_bitrate\":null,\"bestseller_pub_override\":false,\"extra_seats_coupon_type\":false,\"post_subdomain_universal_links\":false,\"post_import_max_file_size\":26214400,\"notes_weight_follow\":4,\"livekit_reconnect_slate_url\":\"https://mux-livestream-assets.s3.us-east-1.amazonaws.com/custom-disconnect-slate-tall.png\",\"exclude_from_pymk_suggestions\":false,\"minimum_ios_version\":2200,\"disable_annual_subscriptions\":false,\"enable_bestseller_survey_modal_override\":false,\"enable_livestream_rtmp_invites\":false,\"enable_android_dms\":false,\"feed_ranker_use_user_comment_reaction_cache\":true,\"pub_auto_moderation_enabled\":false,\"disable_live_stream_ai_trimming_by_default\":false,\"recipes_enabled\":false,\"disable_deletion\":false,\"ios_default_coupon_enabled\":false,\"notes_weight_read_post\":5,\"notes_weight_reply\":3,\"livekit_egress_custom_base_url\":\"http://livekit-egress-custom-recorder.s3-website-us-east-1.amazonaws.com\",\"clip_focused_video_upload_flow\":false,\"live_stream_max_guest_users\":2,\"enable_video_seo_data\":false,\"can_reimport_unsubscribed_users_with_2x_optin\":false,\"feed_posts_weight_subscribed\":0,\"included_in_demo_feed\":false,\"live_event_mixin\":\"\",\"review_incoming_email\":\"default\",\"app_install_prompts\":\"native_banner_if_supported\",\"enable_founding_gifts\":false,\"ios_chat_uikit\":false,\"enable_sponsorship_campaigns\":false,\"thread_permalink_preview_min_android_version\":2037,\"tabbed_notes_search\":\"control\",\"default_thumbnail_time\":10,\"pub_ranking_weight_immediate_engagement\":1,\"pub_ranking_weight_retained_engagement\":1,\"load_test_unichat\":false,\"notes_read_post_baseline\":0,\"live_stream_head_alignment_guide\":false,\"show_open_post_as_pdf_button\":false,\"free_press_combo_subscribe_flow_enabled\":false,\"restack_with_image\":false,\"free_press_tabbed_subscribe_flow\":\"control\",\"gift_from_substack_modal\":\"experiment\",\"gifts_from_substack_feature_available\":true,\"disable_ai_clips\":false,\"thefp_enable_web_livestream_kicking\":false,\"enable_elevenlabs_voiceovers\":false,\"use_snowflake_crm_bool\":true,\"android_upgrade_alert_dialog\":true,\"headline_testing_enabled\":true,\"translated_notifications_enabled\":false,\"show_simple_post_editor\":false,\"enable_live_stream_auto_publish_flow\":true,\"search_ranker_query_augmentation\":\"enabled\",\"enable_publication_podcasts_page\":false,\"ios_payment_connection_enabled\":true,\"app_install_reminder_email\":\"experiment\",\"use_landscape_livestream_for_post_draft\":false,\"thefp_enable_dynamic_toaster\":false,\"live_stream_install_app_reminders_enabled\":true,\"use_unified_livestream_workflow\":true,\"thefp_enable_america_250\":true,\"ios_note_composer_settings_enabled\":false,\"android_v2_post_video_player_enabled\":false,\"enable_direct_message_request_bypass\":false,\"enable_apple_news_sync\":false,\"postsById_batch_size\":20,\"free_press_newsletter_promo_enabled\":false,\"enable_ios_livestream_stats\":false,\"disable_live_stream_reactions\":false,\"enable_high_follower_dm\":true,\"ios_welcome_video_profile_prompt\":false,\"clip_generation_3rd_party_vendor\":\"internal\",\"ios_notification_settings_enabled\":false,\"notes_weight_negative\":1,\"ios_discover_tab_min_installed_date\":\"2025-06-09T16:56:58+0000\",\"notes_weight_click_see_more\":2,\"activity_items_writes_rollout\":0,\"edit_profile_theme_colors\":false,\"backend_enable_subscription_bar\":true,\"disable_clipping_for_readers\":false,\"android_enable_subscription_bar\":false,\"apple_fee_percent\":15,\"allow_anonymous_personal_pub_creation\":false,\"feed_posts_weight_reply\":3,\"feed_posts_weight_negative\":5,\"feed_posts_weight_like\":1.5,\"feed_posts_weight_share\":3,\"feed_posts_weight_save\":3,\"enable_press_kit_preview_modal\":false,\"use_snowflake_crm_rollout_percentage\":1,\"feed_posts_weight_sign_up\":4,\"live_stream_video_degradation_preference\":\"maintainFramerate\",\"render_high_quality_clips\":false,\"pause_app_badges\":false,\"android_enable_publication_activity_tab\":false,\"notes_weight_like\":2,\"profile_feed_expanded_inventory\":false,\"phone_verification_fallback_to_twilio\":false,\"livekit_mux_latency_mode\":\"low\",\"feed_posts_weight_long_click\":1,\"feed_juiced_user\":0,\"vertical_video_player_in_feed_1\":\"experiment\",\"show_branded_intro_setting\":true,\"free_press_single_screen_subscribe_flow_enabled\":false,\"notes_click_see_more_baseline\":0.35,\"android_edit_user_links\":true,\"android_move_feed_tabs\":false,\"android_enable_user_status_ui\":false,\"use_advanced_commerce_api_for_iap\":false,\"skip_free_preview_language_in_podcast_notes\":false,\"larger_wordmark_on_publication_homepage\":false,\"video_editor_full_screen\":false,\"enable_mobile_stats_for_admins\":false,\"ios_profile_themes_note_composer_enabled\":false,\"reduce_post_search_fuzziness\":\"treatment\",\"related_posts_web\":\"experiment\",\"notes_weight_click_item\":3,\"enable_milestone_notifications\":true,\"notes_weight_long_visit\":1,\"bypass_single_unlock_token_limit\":false,\"notes_watch_video_baseline\":0.08,\"add_section_and_tag_metadata\":false,\"daily_promoted_notes_enabled\":true,\"feed_ranker_use_user_feed_restack_comment_cache\":true,\"enable_islands_cms\":false,\"enable_livestream_combined_stats\":false,\"search_retrieval_variant\":\"experiment\",\"enable_web_explore\":false,\"enable_drip_campaigns\":false,\"ios_offline_mode_enabled\":false,\"post_management_search_engine\":\"elasticsearch\",\"new_bestseller_leaderboard_feed_item_enabled\":false,\"feed_main_disabled\":false,\"enable_account_settings_revamp\":false,\"allowed_email_domains\":\"one\",\"thefp_enable_fp_recirc_block\":false,\"ios_web_subscription_payments\":\"experiment\",\"publication_search_replatform\":\"experiment\",\"ios_full_search_results\":\"control\",\"enable_debug_logs_ios\":false,\"show_pub_content_on_profile_for_pub_id\":0,\"show_pub_content_on_profile\":false,\"livekit_track_egress\":true,\"video_tab_mixture_pattern\":\"npnnnn\",\"enable_theme_contexts\":false,\"onboarding_suggestions_search\":\"experiment\",\"feed_tuner_enabled\":false,\"enable_arr_milestone_notifications\":true,\"enable_pledges_milestone_notifications\":true,\"livekit_mux_latency_mode_rtmp\":\"low\",\"notes_weight_follow_boost\":3,\"web_notes_trending_topics_enabled\":\"control\",\"ios_trending_topics_feed_item\":\"control\",\"direct_device_push_notifications_ios\":\"control\",\"fcm_high_priority\":false,\"suggested_search_instead_of_dpn\":\"control\",\"unfinished_post_push_notification\":\"treatment\",\"subscription_bar_top_selection_strategy_v2\":\"destination_wau_pub_score\",\"enable_live_stream_audio_enhancements_flow\":false,\"iap_announcement_blog_url\":\"\",\"android_onboarding_progress_persistence\":\"control\",\"related_notes_variations\":\"experiment\",\"dpn_weight_tap_bonus_subscribed\":3,\"ios_custom_buttons_enabled\":true,\"ios_livestream_feedback\":false,\"reader_sharing_flow\":\"control\",\"ios_iap_opt_out_enabled\":false,\"android_view_post_share_assets_employees_only\":false,\"android_trending_topics_feed_item\":\"control\",\"thefp_show_fixed_footer_paywall\":false,\"android_subscription_queue_experiment\":\"experiment\",\"ios_viral_gift_entry_points\":\"treatment\",\"ios_subscription_pogs\":\"experiment\",\"dpn_weight_like\":3,\"use_elasticsearch_for_category_tabs\":\"control\",\"enable_subscribers_milestone_notifications\":true,\"android_enable_edit_profile_theme\":false,\"android_enable_view_profile_theme\":false,\"enable_refresh_token_deduplication\":true,\"dpn_weight_follow\":3,\"live_stream_audio_enhancer_v2\":\"auphonic\",\"dpn_weight_reply\":2.5,\"enable_speaker_focus_clips\":true,\"speaker_focus_variant_generation_enabled\":true,\"search_ranker_load_test_ranking_window\":2000,\"ios_new_post_sharing_flow_enabled\":false,\"search_ranker_load_test_pct\":0,\"profile_feed_expanded_inventory_experiment_driven\":\"control\",\"ignore_video_in_notes_length_limit\":false,\"web_show_scores_on_sports_tab\":false,\"notes_weight_click_share\":3,\"direct_device_push_notifications\":false,\"allow_long_videos\":true,\"dpn_user_picture_instead_of_comment\":\"experiment\",\"ios_post_video_pager_enabled\":\"control\",\"dpn_score_threshold\":0,\"thefp_enable_follow_module\":false,\"dpn_weight_follow_bonus\":0.5,\"ios_post_subscribe_follow_related\":\"control\",\"use_intro_clip_and_branded_intro_by_default\":false,\"publisher_banner\":\"\",\"new_user_subscribe_follow_prompt_override\":\"none\",\"iap_broad_launch_enabled\":true,\"dpn_weight_open\":2.5,\"ios_subscription_pogs_new_users\":\"experiment\",\"ios_subscription_pogs_old_users\":\"experiment\",\"android_subscription_queue_experiment_2\":\"experiment\",\"enable_viewing_all_livestream_viewers\":false,\"serve_suggested_searches_table\":false,\"enable_clip_prompt_variant_filtering\":true,\"dpn_ranking_enabled\":true,\"sequential_retrieval_model_pct\":100,\"dpn_model_variant\":\"experiment\",\"skip_default_welcome_email_for_app_users\":\"control\",\"dpn_weight_long_session\":2.5,\"dpn_weight_tap\":3,\"android_vertical_post_player\":\"control\",\"new_note_communication_notification_experiment\":\"control\",\"enable_notes_admins\":false,\"suggested_search_notifications\":\"control\",\"enable_suggested_searches\":true,\"maximum_affinity_index_for_trending_topic_notification\":5,\"android_synchronous_push_notif_handling\":\"control\",\"animate_all_explore_video_suggestions\":true,\"android_vertical_post_player_2\":\"experiment\",\"suggested_search_metadata_web_market_ui\":false,\"dpn_weight_restack\":2,\"use_new_snowflake_user_rollout_percentage\":1,\"session_version_invalidation_enabled\":false,\"dpn_weight_negative\":1},\"publicationSettings\":{\"block_ai_crawlers\":false,\"credit_token_enabled\":true,\"custom_tos_and_privacy\":false,\"did_identity\":null,\"disable_optimistic_bank_payments\":false,\"display_welcome_page_details\":true,\"enable_meetings\":false,\"payment_pledges_enabled\":false,\"enable_post_page_conversion\":true,\"enable_prev_next_nav\":false,\"enable_restacking\":true,\"gifts_from_substack_disabled\":false,\"google_analytics_4_token\":\"G-Z4BJTTV5MZ\",\"group_sections_and_podcasts_in_menu_enabled\":false,\"live_stream_homepage_visibility\":\"contributorsAndAdmins\",\"live_stream_homepage_style\":\"autoPlay\",\"medium_length_description\":\"Artificial intelligence is a fast-moving field. Ahead of AI helps you keep up with the latest developments and research trends in the fields of machine learning, deep learning, and artificial intelligence.\",\"notes_feed_enabled\":true,\"paywall_unlock_tokens\":true,\"post_preview_crop_gravity\":\"center\",\"reader_referrals_enabled\":false,\"reader_referrals_leaderboard_enabled\":false,\"seen_coming_soon_explainer\":false,\"seen_google_analytics_migration_modal\":false,\"local_currency_modal_seen\":true,\"local_payment_methods_modal_seen\":true,\"twitter_pixel_signup_event_id\":null,\"twitter_pixel_subscribe_event_id\":null,\"use_local_currency\":true,\"welcome_page_opt_out_text\":\"No thanks\",\"cookie_settings\":\"\",\"show_restacks_below_posts\":true,\"holiday_gifting_post_header\":false,\"homepage_message_text\":\"\",\"homepage_message_link\":\"\",\"about_us_author_ids\":\"\",\"archived_section_ids\":\"\",\"column_section_ids\":\"\",\"fp_primary_column_section_ids\":\"\",\"event_section_ids\":\"\",\"podcasts_metadata\":\"\",\"video_section_ids\":\"\",\"post_metering_enabled\":false},\"publicationUserSettings\":null,\"userSettings\":{\"user_id\":null,\"activity_likes_enabled\":true,\"artist_mode_enabled\":false,\"dashboard_nav_refresh_enabled\":false,\"hasDismissedSectionToNewsletterRename\":false,\"is_guest_post_enabled\":true,\"feed_web_nux_seen_at\":null,\"has_seen_select_to_restack_tooltip_nux\":false,\"invite_friends_nux_dismissed_at\":null,\"suggestions_feed_item_last_shown_at\":null,\"has_seen_select_to_restack_modal\":false,\"last_home_tab\":null,\"last_notification_alert_shown_at\":null,\"disable_reply_hiding\":false,\"newest_seen_chat_item_published_at\":null,\"explicitContentEnabled\":false,\"contactMatchingEnabled\":false,\"messageRequestLevel\":\"everyone\",\"liveStreamAcceptableInviteLevel\":\"everyone\",\"liveStreamAcceptableChatLevel\":\"everyone\",\"creditTokensTreatmentExposed\":false,\"appBadgeIncludesChat\":false,\"autoPlayVideo\":true,\"smart_delivery_enabled\":false,\"chatbotTermsLastAcceptedAt\":null,\"has_seen_notes_post_app_upsell\":false,\"substack_summer_nux_dismissed_at\":null,\"first_note_id\":null,\"show_concurrent_live_stream_viewers\":false,\"has_dismissed_fp_download_pdf_nux\":false,\"edit_profile_feed_item_dismissed_at\":null,\"mobile_permalink_app_upsell_seen_at\":null,\"new_user_checklist_enabled\":false,\"new_user_follow_subscribe_prompt_dismissed_at\":null,\"has_seen_youtube_shorts_auto_publish_announcement\":false,\"notificationQualityFilterEnabled\":true,\"hasSeenOnboardingNewslettersScreen\":false},\"subscriberCountDetails\":\"hundreds of thousands of subscribers\",\"mux_env_key\":\"u42pci814i6011qg3segrcpp9\",\"sentry_environment\":\"production\",\"launchWelcomePage\":false,\"pendingInviteForActiveLiveStream\":null,\"blurbs\":[{\"id\":431753,\"recommended_publication_id\":1174659,\"recommending_publication_id\":265424,\"created_at\":\"2022-11-16T00:01:06.468Z\",\"updated_at\":\"2022-11-16T00:01:06.468Z\",\"blurb_active\":true,\"description\":\"Sebastian is an incredible educator and always has invaluable insights--do keep up with his work!\",\"email_sent_at\":\"2022-11-16T00:34:49.184Z\",\"recommendingPublication\":{\"id\":265424,\"name\":\"The Gradient\",\"subdomain\":\"thegradientpub\",\"custom_domain\":null,\"custom_domain_optional\":false,\"hero_text\":\"Articles, interviews, and news coverage about AI brought to you by a team of AI researchers and builders.\",\"logo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/33e22926-7401-4e09-8c7c-1e6b0f179f76_1196x1196.png\",\"author_id\":25322056,\"primary_user_id\":3550791,\"theme_var_background_pop\":\"#786CFF\",\"created_at\":\"2021-01-18T22:35:25.588Z\",\"email_from_name\":\"The Gradient\",\"copyright\":\"The Gradient\",\"founding_plan_name\":\"Founding Member\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"magaziney\",\"is_personal_mode\":false,\"author\":{\"id\":25322056,\"name\":\"The Gradient\",\"handle\":\"thegradientpub\",\"previous_name\":null,\"photo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/1ab6eeb8-808d-4094-b09a-42a3980ca045_400x400.jpeg\",\"bio\":\"The Gradient is a digital magazine that aims to be a place for discussion about research and trends in artificial intelligence and machine learning. We provide \",\"profile_set_up_at\":\"2021-04-30T00:51:15.962Z\",\"reader_installed_at\":null}},\"author_name\":\"The Gradient\",\"author\":{\"id\":25322056,\"photo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/1ab6eeb8-808d-4094-b09a-42a3980ca045_400x400.jpeg\"}},{\"id\":466622,\"recommended_publication_id\":1174659,\"recommending_publication_id\":1199871,\"created_at\":\"2022-11-28T19:26:18.920Z\",\"updated_at\":\"2022-12-16T23:31:15.215Z\",\"blurb_active\":true,\"description\":\"All the latest scoop on AI from one of the best educators out there!\",\"email_sent_at\":null,\"recommendingPublication\":{\"id\":1199871,\"name\":\"Gradient Ascent\",\"subdomain\":\"artofsaience\",\"custom_domain\":\"newsletter.artofsaience.com\",\"custom_domain_optional\":false,\"hero_text\":\"Gradient Ascent is your weekly guide to AI, trusted by Silicon Valley's top tech firms and the best academic labs worldwide. \",\"logo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/01dfb858-3107-4656-b289-cf13de969a17_800x800.png\",\"author_id\":85853406,\"primary_user_id\":85853406,\"theme_var_background_pop\":\"#FD5353\",\"created_at\":\"2022-11-18T15:58:31.925Z\",\"email_from_name\":\"Sairam from The Art of Saience\",\"copyright\":\"Sairam Sundaresan\",\"founding_plan_name\":\"\\\"I can expense it\\\" \",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"paused\",\"language\":null,\"explicit\":false,\"homepage_type\":\"magaziney\",\"is_personal_mode\":false,\"author\":{\"id\":85853406,\"name\":\"Sairam Sundaresan\",\"handle\":\"sairamsundaresan\",\"previous_name\":\"Sairam\",\"photo_url\":\"https://substackcdn.com/image/fetch/$s_!3vud!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cc4b2d-3161-4743-85d8-97910007711b_1463x1463.jpeg\",\"bio\":\"I'm an AI engineering leader with 14+ years of industry experience across different sectors including mobile devices, data centers, and autonomous vehicles. I'll help you understand AI and break into the field.\",\"profile_set_up_at\":\"2022-04-28T18:19:37.215Z\",\"reader_installed_at\":\"2022-11-03T19:27:08.434Z\"}},\"author_name\":\"Sairam Sundaresan\",\"author\":{\"id\":85853406,\"photo_url\":\"https://substackcdn.com/image/fetch/$s_!3vud!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F79cc4b2d-3161-4743-85d8-97910007711b_1463x1463.jpeg\"}}],\"homepageData\":{\"contentBlockData\":{\"contentBlocks\":[{\"id\":\"2fb7e752-6e5c-4eb4-ae81-38e8bcd756fb\",\"publication_id\":1174659,\"post_source\":\"latest\",\"section_id\":null,\"post_tag_id\":null,\"block_type\":\"grid\",\"primary_sidebar_modules\":[],\"secondary_sidebar_modules\":[],\"order\":1,\"num_posts\":null,\"num_rows\":3,\"attrs\":{},\"section\":null,\"postTag\":null,\"contentBlockPins\":[]},{\"id\":\"4b6e2495-df31-4a11-8b5a-87f55f039485\",\"publication_id\":1174659,\"post_source\":\"none\",\"section_id\":null,\"post_tag_id\":null,\"block_type\":\"subscribe\",\"primary_sidebar_modules\":[],\"secondary_sidebar_modules\":[],\"order\":2,\"num_posts\":null,\"num_rows\":null,\"attrs\":{\"non_subscriber_message\":\"Subscribe to receive new in-depth research insights on AI and machine learning.\",\"free_subscriber_message\":\"Support independent AI research with a paid upgrade and access additional, in-depth content.\",\"paid_subscriber_message\":\"Your support as a paid subscriber makes independent AI research possible\u2014thank you!\"},\"section\":null,\"postTag\":null,\"contentBlockPins\":[]}],\"contributors\":[],\"latestPodcastPosts\":null,\"latestPostByContributorId\":{},\"latestPostFromSections\":{},\"postsBySectionId\":{},\"postsByTagId\":{},\"postsForContentBlockPins\":{}},\"homepageLinks\":[],\"newPosts\":[{\"id\":172832845,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding and Implementing Qwen3 From Scratch\",\"social_title\":\"Understanding and Implementing Qwen3 From Scratch\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"qwen3-from-scratch\",\"post_date\":\"2025-09-06T11:10:21.239Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"only_paid\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/qwen3-from-scratch\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":60},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"A Detailed Look at One of the Leading Open-Source LLMs\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/00515b82-fd01-4c5b-b1b9-2d4b38100be0_1236x775.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":172832845,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A Detailed Look at One of the Leading Open-Source LLMs\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"Previously, I compared the most notable open-weight architectures of 2025 in The Big LLM Architecture Comparison. Then, I zoomed in and discussed the various architecture components in From GPT-2 to gpt-oss: Analyzing the Architectural Advances on a conceptual level.\",\"wordcount\":7156,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5cf0ea83-392e-495a-9745-dc0aaa7f7d4f\",\"publication_id\":1174659,\"name\":\"Reasoning Models\",\"slug\":\"reasoning-models\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[61,183,252],\"population\":18},\"DarkVibrant\":{\"rgb\":[180,140,44],\"population\":1},\"LightVibrant\":{\"rgb\":[140,210,252],\"population\":28},\"Muted\":{\"rgb\":[108,140,156],\"population\":1},\"DarkMuted\":{\"rgb\":[42,52,62],\"population\":23},\"LightMuted\":{\"rgb\":[174,199,212],\"population\":91}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":60,\"comment_count\":4,\"child_comment_count\":3,\"audio_items\":[{\"post_id\":172832845,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":170506328,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"From GPT-2 to gpt-oss: Analyzing the Architectural Advances\",\"social_title\":\"From GPT-2 to gpt-oss: Analyzing the Architectural Advances\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"from-gpt-2-to-gpt-oss-analyzing-the\",\"post_date\":\"2025-08-09T11:23:07.237Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":563},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"And How They Stack Up Against Qwen3\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/529c4cc7-161c-4d7c-b186-06e68c771776_1564x926.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":170506328,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"And How They Stack Up Against Qwen3\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"OpenAI just released their new open-weight LLMs this week: gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019. And yes, thanks to some clever optimizations, they can run locally (but more about this later).\",\"wordcount\":5221,\"postTags\":[{\"id\":\"5cf0ea83-392e-495a-9745-dc0aaa7f7d4f\",\"publication_id\":1174659,\"name\":\"Reasoning Models\",\"slug\":\"reasoning-models\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[92,199,180],\"population\":16},\"DarkVibrant\":{\"rgb\":[33.90684931506849,98.69315068493151,87.18904109589042],\"population\":0},\"LightVibrant\":{\"rgb\":[135,164,235],\"population\":14},\"Muted\":{\"rgb\":[100,116,148],\"population\":1},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":5},\"LightMuted\":{\"rgb\":[135,188,181],\"population\":318}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":563,\"comment_count\":45,\"child_comment_count\":23,\"audio_items\":[{\"post_id\":170506328,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/170506328/tts/d2f3c50e-08e5-4c36-a942-d3a52acf3214/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":168650848,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The Big LLM Architecture Comparison\",\"social_title\":\"The Big LLM Architecture Comparison\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"the-big-llm-architecture-comparison\",\"post_date\":\"2025-07-19T11:11:10.901Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[1174659],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1181},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"From DeepSeek-V3 to gpt-oss: A Look At Modern LLM Architecture Design\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":168650848,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"From DeepSeek-V3 to Kimi K2: A Look At Modern LLM Architecture Design\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It has been seven years since the original GPT architecture was developed. At first glance, looking back at GPT-2 (2019) and forward to DeepSeek-V3 and Llama 4 (2024-2025), one might be surprised at how structurally similar these models still are.\",\"wordcount\":7249,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":{\"post_id\":168650848,\"starts_at\":\"2025-07-19T11:11:11.298Z\",\"ended_at\":\"2025-07-19T12:11:11.487Z\",\"planned_duration_ms\":3600000,\"test_cohort_percent\":5,\"test_cohort_emailed\":true,\"main_cohort_emailed\":true,\"created_at\":\"2025-07-18T17:48:26.613Z\",\"updated_at\":\"2025-07-19T12:11:26.309Z\",\"creator_id\":27393275,\"ended_early\":false,\"winner_overridden\":false},\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[89,193,146],\"population\":57},\"DarkVibrant\":{\"rgb\":[28,25,68],\"population\":350},\"LightVibrant\":{\"rgb\":[251,228,197],\"population\":9},\"Muted\":{\"rgb\":[100,116,148],\"population\":2},\"DarkMuted\":{\"rgb\":[94,99,128],\"population\":49},\"LightMuted\":{\"rgb\":[189,168,205],\"population\":245}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1181,\"comment_count\":60,\"child_comment_count\":24,\"audio_items\":[{\"post_id\":168650848,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/168650848/tts/582abd24-ce98-43b6-81ac-1339a0d403d5/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":166943621,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"LLM Research Papers: The 2025 List (January to June)\",\"social_title\":\"LLM Research Papers: The 2025 List (January to June)\",\"search_engine_title\":null,\"search_engine_description\":\"The latest in LLM research with a hand-curated, topic-organized list of over 200 research papers from 2025.\",\"type\":\"newsletter\",\"slug\":\"llm-research-papers-2025-list-one\",\"post_date\":\"2025-07-01T11:11:45.123Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"only_paid\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/llm-research-papers-2025-list-one\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":70},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\" A topic-organized collection of 200+ LLM research papers from 2025\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!cRyQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4e920533-c926-461b-95bb-c7446f3df382_1289x619.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":166943621,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A topic-organized collection of 200+ LLM research papers from 2025\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"As some of you know, I keep a running list of research papers I (want to) read and reference.\",\"wordcount\":3976,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5cf0ea83-392e-495a-9745-dc0aaa7f7d4f\",\"publication_id\":1174659,\"name\":\"Reasoning Models\",\"slug\":\"reasoning-models\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":false,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[74,132,170],\"population\":50},\"DarkVibrant\":{\"rgb\":[40.214754098360665,71.73442622950819,92.38524590163934],\"population\":0},\"LightVibrant\":{\"rgb\":[180,148,212],\"population\":2},\"Muted\":{\"rgb\":[100,159,100],\"population\":13},\"DarkMuted\":{\"rgb\":[68,108,73],\"population\":7},\"LightMuted\":{\"rgb\":[166,186,204],\"population\":4}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":70,\"comment_count\":5,\"child_comment_count\":3,\"audio_items\":[{\"post_id\":166943621,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":166106178,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding and Coding the KV Cache in LLMs from Scratch\",\"social_title\":\"Understanding and Coding the KV Cache in LLMs from Scratch\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"coding-the-kv-cache-in-llms\",\"post_date\":\"2025-06-17T10:55:34.121Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/coding-the-kv-cache-in-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":385},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"\",\"cover_image\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78382a83-f634-4cfa-92b9-bbea30c61a60_841x926.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":166106178,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"KV caches are one of the most critical techniques for efficient inference in LLMs in production.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"KV caches are one of the most critical techniques for efficient inference in LLMs in production. KV caches are an important component for compute-efficient LLM inference in production. This article explains how they work conceptually and in code with a from-scratch, human-readable implementation.\",\"wordcount\":2849,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":{\"post_id\":166106178,\"starts_at\":\"2025-06-17T10:55:34.788Z\",\"ended_at\":\"2025-06-17T11:26:50.707Z\",\"planned_duration_ms\":1800000,\"test_cohort_percent\":5,\"test_cohort_emailed\":true,\"main_cohort_emailed\":true,\"created_at\":\"2025-06-16T21:55:49.523Z\",\"updated_at\":\"2025-06-17T11:26:59.428Z\",\"creator_id\":27393275,\"ended_early\":false,\"winner_overridden\":false},\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[132,188,212],\"population\":1},\"DarkVibrant\":{\"rgb\":[34.34819277108433,79.08072289156628,98.25180722891568],\"population\":0},\"LightVibrant\":{\"rgb\":[140,188,220],\"population\":1},\"Muted\":{\"rgb\":[124,164,188],\"population\":1},\"DarkMuted\":{\"rgb\":[108,108,108],\"population\":8},\"LightMuted\":{\"rgb\":[188,172,204],\"population\":4}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":385,\"comment_count\":27,\"child_comment_count\":16,\"audio_items\":[{\"post_id\":166106178,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/166106178/tts/a4265993-8c0d-4708-b7a7-ea42208e893a/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":162934205,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Coding LLMs from the Ground Up: A Complete Course\",\"social_title\":\"Coding LLMs from the Ground Up: A Complete Course\",\"search_engine_title\":null,\"search_engine_description\":\"Why build an LLM from scratch? It's probably the best and most efficient way to learn how LLMs really work. Plus, many readers have told me they had a lot of fun doing it.\",\"type\":\"newsletter\",\"slug\":\"coding-llms-from-the-ground-up\",\"post_date\":\"2025-05-10T11:03:17.769Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":true,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/coding-llms-from-the-ground-up\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":233},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/752b6486-73db-4293-9465-854d4a005a5c_2406x1350.jpeg\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":162934205,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Why build LLMs from scratch? It's probably the best and most efficient way to learn how LLMs really work. Plus, many readers have told me they had a lot of fun doing it.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"I wrote a lot about reasoning models in recent months (4 articles in a row)! Next to everything \\\"agentic,\\\" reasoning is one of the biggest LLM topics of 2025.\",\"wordcount\":997,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":false,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[57.24489795918357,130.10204081632648,197.75510204081644],\"population\":0},\"DarkVibrant\":{\"rgb\":[29.767346938775457,67.65306122448978,102.83265306122455],\"population\":0},\"LightVibrant\":{\"rgb\":[217,231,244],\"population\":9},\"Muted\":{\"rgb\":[108,116,132],\"population\":2},\"DarkMuted\":{\"rgb\":[52,52,52],\"population\":5},\"LightMuted\":{\"rgb\":[156,180,204],\"population\":110}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":233,\"comment_count\":4,\"child_comment_count\":3,\"audio_items\":[{\"post_id\":162934205,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":161572341,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The State of Reinforcement Learning for LLM Reasoning\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"the-state-of-llm-reasoning-model-training\",\"post_date\":\"2025-04-19T11:02:44.098Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":432},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Understanding GRPO and New Insights from Reasoning Model Papers\",\"cover_image\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c02ecf0-cb1d-4f62-a160-6d07636b99fd_1600x1384.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":161572341,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Understanding GRPO and New Insights from Reasoning Model Papers\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"A lot has happened this month, especially with the releases of new flagship models like GPT-4.5 and Llama 4. But you might have noticed that reactions to these releases were relatively muted. Why? One reason could be that GPT-4.5 and Llama 4 remain conventional models, which means they were trained without explicit reinforcement learning for reasoning.\",\"wordcount\":7371,\"postTags\":[{\"id\":\"5cf0ea83-392e-495a-9745-dc0aaa7f7d4f\",\"publication_id\":1174659,\"name\":\"Reasoning Models\",\"slug\":\"reasoning-models\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[14,122,189],\"population\":536},\"DarkVibrant\":{\"rgb\":[9.144827586206898,79.69064039408869,123.45517241379311],\"population\":0},\"LightVibrant\":{\"rgb\":[133,185,222],\"population\":33},\"Muted\":{\"rgb\":[131,131,132],\"population\":733},\"DarkMuted\":{\"rgb\":[76,76,76],\"population\":4},\"LightMuted\":{\"rgb\":[203,204,220],\"population\":736}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":432,\"comment_count\":31,\"child_comment_count\":23,\"audio_items\":[{\"post_id\":161572341,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/161572341/tts/cd672520-7f7e-451a-b651-e4dc94781b46/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":159880090,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"First Look at Reasoning From Scratch: Chapter 1\",\"social_title\":\"First Look at Reasoning From Scratch: Chapter 1\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"first-look-at-reasoning-from-scratch\",\"post_date\":\"2025-03-29T11:11:41.742Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"only_paid\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/first-look-at-reasoning-from-scratch\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":56},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"An introduction to reasoning in today's LLMs\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/01d8ee9a-933b-4e66-8ad8-28056a0fdd73_1628x1076.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":159880090,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Welcome to the next stage of large language models (LLMs): reasoning. LLMs have transformed how we process and generate text, but their success has been largely driven by statistical pattern recognition. However, new advances in reasoning methodologies now enable LLMs to tackle more complex tasks, such as solving logical puzzles or multi-step arithmetic. Understanding these methodologies is the central focus of this book.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"Hi everyone,\",\"wordcount\":3577,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":false,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[4,172,140],\"population\":485},\"DarkVibrant\":{\"rgb\":[27,178,152],\"population\":41},\"LightVibrant\":{\"rgb\":[147,202,211],\"population\":20},\"Muted\":{\"rgb\":[116,116,116],\"population\":3},\"DarkMuted\":{\"rgb\":[52,52,52],\"population\":2},\"LightMuted\":{\"rgb\":[177,188,188],\"population\":98}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":56,\"comment_count\":15,\"child_comment_count\":7,\"audio_items\":[{\"post_id\":159880090,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":158620387,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The State of LLM Reasoning Model Inference\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"state-of-llm-reasoning-and-inference-scaling\",\"post_date\":\"2025-03-08T12:11:42.532Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":389},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Inference-Time Compute Scaling Methods to Improve Reasoning Models\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!IOSP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf9e2677-652a-4af1-9f57-dc0c253d2198_1448x1260.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":158620387,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Inference-Time Compute Scaling Methods to Improve Reasoning Models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"Improving the reasoning abilities of large language models (LLMs) has become one of the hottest topics in 2025, and for good reason. Stronger reasoning skills allow LLMs to tackle more complex problems, making them more capable across a wide range of tasks users care about.\",\"wordcount\":4291,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[166,28,9],\"population\":48},\"DarkVibrant\":{\"rgb\":[152,80,72],\"population\":2},\"LightVibrant\":{\"rgb\":[252,200,201],\"population\":6},\"Muted\":{\"rgb\":[113,129,131],\"population\":100},\"DarkMuted\":{\"rgb\":[92,95,95],\"population\":17},\"LightMuted\":{\"rgb\":[180,212,211],\"population\":134}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":389,\"comment_count\":10,\"child_comment_count\":8,\"audio_items\":[{\"post_id\":158620387,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/158620387/tts/02a569db-ee04-4fb0-a5d5-4f944a6a09cb/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":156484949,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Reasoning LLMs\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"understanding-reasoning-llms\",\"post_date\":\"2025-02-05T12:11:39.216Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-reasoning-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1098},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!QwUc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6ebc5c9-461f-4d3a-889b-b8ea4e14e5ba_1600x830.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":156484949,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This article describes the four main approaches to building reasoning models, or how we can enhance LLMs with reasoning capabilities. I hope this provides valuable insights and helps you navigate the rapidly evolving literature and hype surrounding this topic.\",\"wordcount\":4028,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[169,25,6],\"population\":87},\"DarkVibrant\":{\"rgb\":[128.0537142857143,18.942857142857143,4.546285714285711],\"population\":0},\"LightVibrant\":{\"rgb\":[252,235,228],\"population\":408},\"Muted\":{\"rgb\":[116,132,148],\"population\":1},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":7},\"LightMuted\":{\"rgb\":[164,188,200],\"population\":2}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1098,\"comment_count\":40,\"child_comment_count\":21,\"audio_items\":[{\"post_id\":156484949,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/156484949/tts/410051a7-e938-4017-8671-68e5f1fae779/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":153692738,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Noteworthy AI Research Papers of 2024 (Part Two)\",\"social_title\":\"Noteworthy AI Research Papers of 2024 (Part Two)\",\"search_engine_title\":null,\"search_engine_description\":\"Six influential AI papers from July to December, from  improving LLMs by scaling inference-time compute to gains from synthetic training data.\",\"type\":\"newsletter\",\"slug\":\"ai-research-papers-2024-part-2\",\"post_date\":\"2025-01-15T12:11:49.791Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-2\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":172},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Six influential AI papers from July to December\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/950f1c27-f0ee-4392-a7f4-906125c58738_1888x1670.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":153692738,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Six influential AI papers from July to December\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"I hope your 2025 is off to a great start! To kick off the year, I've finally been able to complete the draft and second part of this AI Research Highlights of 2024 article. It covers a variety of relevant topics, from mixture-of-experts models to new LLM scaling laws for precision.\",\"wordcount\":5450,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[69,148,202],\"population\":23},\"DarkVibrant\":{\"rgb\":[36,92,140],\"population\":1},\"LightVibrant\":{\"rgb\":[225,194,149],\"population\":15},\"Muted\":{\"rgb\":[100,172,161],\"population\":3},\"DarkMuted\":{\"rgb\":[75,98,105],\"population\":101},\"LightMuted\":{\"rgb\":[191,195,196],\"population\":181}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":172,\"comment_count\":10,\"child_comment_count\":5,\"audio_items\":[{\"post_id\":153692738,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/153692738/tts/4a7d14a6-fd5d-4949-8479-4e7f054324d0/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":153341037,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Noteworthy AI Research Papers of 2024 (Part One)\",\"social_title\":\"Noteworthy AI Research Papers of 2024 (Part One)\",\"search_engine_title\":null,\"search_engine_description\":\"Six influential AI papers from January to June, from mixture-of-experts LLMs to new LoRA variants.\",\"type\":\"newsletter\",\"slug\":\"ai-research-papers-2024-part-1\",\"post_date\":\"2024-12-31T12:21:42.892Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-1\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":361},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Six influential AI papers from January to June\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/cace23cf-5185-4045-a894-bb67b20728c8_1850x1348.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":153341037,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Six influential AI papers from January to June\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"To kick off the year, I've finally been able to complete the draft of this AI Research Highlights of 2024 article. It covers a variety of topics, from mixture-of-experts models to new LLM scaling laws for precision.\",\"wordcount\":3234,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[8,163,249],\"population\":156},\"DarkVibrant\":{\"rgb\":[15,124,188],\"population\":24},\"LightVibrant\":{\"rgb\":[94,196,252],\"population\":8},\"Muted\":{\"rgb\":[135,148,116],\"population\":9},\"DarkMuted\":{\"rgb\":[51,51,51],\"population\":18},\"LightMuted\":{\"rgb\":[186,198,161],\"population\":33}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":361,\"comment_count\":28,\"child_comment_count\":17,\"audio_items\":[{\"post_id\":153341037,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/153341037/tts/0cc251e8-b1cf-46e1-b486-673fac99d065/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":152305086,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"LLM Research Papers: The 2024 List\",\"social_title\":\"LLM Research Papers: The 2024 List\",\"search_engine_title\":null,\"search_engine_description\":\"A curated list of interesting LLM-related research papers from 2024, shared for those looking for something to read over the holidays.\",\"type\":\"newsletter\",\"slug\":\"llm-research-papers-the-2024-list\",\"post_date\":\"2024-12-08T12:11:04.618Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":296},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/7ba1c2ab-7ae7-4f22-86df-f116f2914cd5_1272x1232.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":152305086,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A curated list of interesting LLM-related research papers from 2024, shared for those looking for something to read over the holidays.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It\u2019s been a very eventful and exciting year in AI research. This is especially true if you are interested in LLMs.\",\"wordcount\":6491,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[127.5,127.5,127.5],\"population\":0},\"DarkVibrant\":{\"rgb\":[66.3,66.3,66.3],\"population\":0},\"LightVibrant\":{\"rgb\":[188.7,188.7,188.7],\"population\":0},\"Muted\":{\"rgb\":[144,146,146],\"population\":26},\"DarkMuted\":{\"rgb\":[76.5,76.5,76.5],\"population\":0},\"LightMuted\":{\"rgb\":[188,188,188],\"population\":231}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":296,\"comment_count\":28,\"child_comment_count\":23,\"audio_items\":[{\"post_id\":152305086,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/152305086/tts/69edd8db-4544-4336-819b-9684a0d3bc22/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":151078631,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Multimodal LLMs\",\"social_title\":\"Understanding Multimodal LLMs\",\"search_engine_title\":null,\"search_engine_description\":\"An introduction to the main multimodal LLM techniques and latest models\",\"type\":\"newsletter\",\"slug\":\"understanding-multimodal-llms\",\"post_date\":\"2024-11-03T12:44:00.421Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-multimodal-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":540},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"An introduction to the main techniques and latest models\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/c534f387-f776-41eb-9c65-f0032b91daee_1988x1430.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":151078631,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"An introduction to the main techniques and latest models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It was a wild two months. There have once again been many developments in AI research, with two Nobel Prizes awarded to AI and several interesting research papers published.\",\"wordcount\":4421,\"postTags\":[{\"id\":\"1496f84a-084b-4bf8-9930-a33eca71b372\",\"publication_id\":1174659,\"name\":\"Computer Vision\",\"slug\":\"computer-vision\",\"hidden\":false},{\"id\":\"2e792e1c-c4e1-4a7c-a303-bdac25c1f3a8\",\"publication_id\":1174659,\"name\":\"Vision Transformers\",\"slug\":\"vision-transformers\",\"hidden\":false},{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[180,22,5],\"population\":151},\"DarkVibrant\":{\"rgb\":[4,116,188],\"population\":58},\"LightVibrant\":{\"rgb\":[197,222,239],\"population\":75},\"Muted\":{\"rgb\":[145,103,93],\"population\":24},\"DarkMuted\":{\"rgb\":[98,73,50],\"population\":17},\"LightMuted\":{\"rgb\":[207,178,173],\"population\":41}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":540,\"comment_count\":57,\"child_comment_count\":28,\"audio_items\":[{\"post_id\":151078631,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/151078631/tts/1548c000-1339-4ad7-9834-b5616d93e113/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":148679739,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Building A GPT-Style LLM Classifier From Scratch\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"building-a-gpt-style-llm-classifier\",\"post_date\":\"2024-09-21T12:07:44.166Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/building-a-gpt-style-llm-classifier\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":175},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Finetuning a GPT Model for Spam Classification\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!mmsV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc52e5b0c-836c-4ae4-9b09-02e364004195_1600x858.jpeg\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":148679739,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Finetuning a GPT Model for Spam Classification\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"In this article, I want to show you how to transform pretrained large language models (LLMs) into strong text classifiers.\",\"wordcount\":3937,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[202.50000000000003,127.5,52.499999999999986],\"population\":0},\"DarkVibrant\":{\"rgb\":[105.30000000000001,66.3,27.3],\"population\":0},\"LightVibrant\":{\"rgb\":[248,238,228],\"population\":7},\"Muted\":{\"rgb\":[176,176,176],\"population\":32},\"DarkMuted\":{\"rgb\":[121.50000000000001,76.5,31.499999999999986],\"population\":0},\"LightMuted\":{\"rgb\":[216,185,184],\"population\":30}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":175,\"comment_count\":12,\"child_comment_count\":5,\"audio_items\":[{\"post_id\":148679739,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":148329414,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Building LLMs from the Ground Up: A 3-hour Coding Workshop\",\"social_title\":\"Building LLMs from the Ground Up: A 3-hour Coding Workshop\",\"search_engine_title\":null,\"search_engine_description\":\"A 3-hour coding workshop presentation on implementing, training, and using LLMs.\",\"type\":\"newsletter\",\"slug\":\"building-llms-from-the-ground-up\",\"post_date\":\"2024-08-31T10:39:35.940Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":433},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/367b547c-9d22-4a3d-b466-1d56ccc6b055_1844x1224.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":148329414,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"If your weekend plans include catching up on AI developments and understanding Large Language Models (LLMs), I've prepared a 1-hour presentation on the development cycle of LLMs, covering everything from architectural implementation to the finetuning stages.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"If you\u2019d like to spend a few hours this weekend to dive into Large Language Models (LLMs) and understand how they work, I've prepared a 3-hour coding workshop presentation on implementing, training, and using LLMs.\",\"wordcount\":343,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[204,124,164],\"population\":34},\"DarkVibrant\":{\"rgb\":[64,40,20],\"population\":2},\"LightVibrant\":{\"rgb\":[236,143,189],\"population\":45},\"Muted\":{\"rgb\":[101,130,152],\"population\":17},\"DarkMuted\":{\"rgb\":[84,44,72],\"population\":2},\"LightMuted\":{\"rgb\":[167,178,191],\"population\":23}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":433,\"comment_count\":16,\"child_comment_count\":11,\"audio_items\":[{\"post_id\":148329414,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/148329414/tts/ead5fd00-a385-4a95-a7dc-9ff942b29fb3/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":147749119,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"New LLM Pre-training and Post-training Paradigms\",\"social_title\":\"New LLM Pre-training and Post-training Paradigms\",\"search_engine_title\":null,\"search_engine_description\":\"New LLM Pre-training and Post-training Paradigms: A Look at How Moderns LLMs Are Trained\",\"type\":\"newsletter\",\"slug\":\"new-llm-pre-training-and-post-training\",\"post_date\":\"2024-08-17T11:55:09.678Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":319},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"A Look at How Modern LLMs Are Trained\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/02b82c11-c899-4202-9594-19c0db1e147b_1514x1298.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":147749119,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A Look at How Moderns LLMs Are Trained\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"The development of large language models (LLMs) has come a long way, from the early GPT models to the sophisticated open-weight LLMs we have today. Initially, the LLM training process focused solely on pre-training, but it has since expanded to include both pre-training and post-training. Post-training typically encompasses supervised instruction fine-tuning and alignment, which was popularized by ChatGPT.\",\"wordcount\":4270,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[25,127,192],\"population\":25},\"DarkVibrant\":{\"rgb\":[15.27649769585254,77.6046082949309,117.32350230414747],\"population\":0},\"LightVibrant\":{\"rgb\":[156,198,226],\"population\":12},\"Muted\":{\"rgb\":[127,127,128],\"population\":68},\"DarkMuted\":{\"rgb\":[47,47,47],\"population\":31},\"LightMuted\":{\"rgb\":[164,188,204],\"population\":1}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":319,\"comment_count\":29,\"child_comment_count\":13,\"audio_items\":[{\"post_id\":147749119,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/147749119/tts/e1681903-b00d-4c46-b393-906654656b12/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":146761957,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Instruction Pretraining LLMs\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":\"The Latest Research in LLM Instruction Finetuning\",\"type\":\"newsletter\",\"slug\":\"instruction-pretraining-llms\",\"post_date\":\"2024-07-20T11:11:11.771Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/instruction-pretraining-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":183},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"The Latest Research in Instruction Finetuning\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!0QPB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9aef22-3864-4212-ac39-cf73d569831b_1600x1175.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":146761957,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"The Latest Research in Instruction Finetuning\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"A lot has happened last month: Apple announced the integration of on-device LLMs, Nvidia shared their large Nemotron model, FlashAttention-3 was announced, Google's Gemma 2 came out, and much more.\",\"wordcount\":6406,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[38.73417721518991,142.02531645569613,216.2658227848101],\"population\":0},\"DarkVibrant\":{\"rgb\":[20.14177215189876,73.853164556962,112.45822784810125],\"population\":0},\"LightVibrant\":{\"rgb\":[188,220,243],\"population\":141},\"Muted\":{\"rgb\":[142,120,115],\"population\":10},\"DarkMuted\":{\"rgb\":[76,76,76],\"population\":4},\"LightMuted\":{\"rgb\":[182,195,206],\"population\":195}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":183,\"comment_count\":17,\"child_comment_count\":5,\"audio_items\":[{\"post_id\":146761957,\"voice_id\":\"en-US-JennyNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/146761957/tts/a94d437e-f4e9-4369-832b-cd382555018b/en-US-JennyNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":145442372,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Developing an LLM: Building, Training, Finetuning\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"llms-building-training-finetuning\",\"post_date\":\"2024-06-08T13:04:07.929Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/llms-building-training-finetuning\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":360},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"A Deep Dive into the Lifecycle of LLM Development\",\"cover_image\":\"https://substackcdn.com/image/youtube/w_728,c_limit/kPGTx4wcm_w\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":145442372,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A Deep Dive into the Lifecycle of LLM Development\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"If your weekend plans include catching up on AI developments and understanding Large Language Models (LLMs), I've prepared a 1-hour presentation on the development cycle of LLMs, covering everything from architectural implementation to the finetuning stages.\",\"wordcount\":203,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":null,\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":360,\"comment_count\":18,\"child_comment_count\":13,\"audio_items\":[{\"post_id\":145442372,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/145442372/tts/544e4725-9372-4fe2-8609-cc94c5a8b69c/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":145134347,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"LLM Research Insights: Instruction Masking and New LoRA Finetuning Experiments\",\"social_title\":\"LLM Research Insights: Instruction Masking and New LoRA Finetuning Experiments\",\"search_engine_title\":null,\"search_engine_description\":\"This article covers three new papers related to instruction finetuning and parameter-efficient finetuning with LoRA in large language models (LLMs). I work with these methods on a daily basis, so it's always exciting to see new research that provides practical insights.\",\"type\":\"newsletter\",\"slug\":\"llm-research-insights-instruction\",\"post_date\":\"2024-06-02T11:03:45.456Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/llm-research-insights-instruction\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":80},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Discussing the Latest Model Releases and AI Research in May 2024\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/5bfabe9e-ade8-45e9-974b-1b53452808bb_2046x1370.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":145134347,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Discussing the Latest Model Releases and AI Research in May 2024\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This month, I am covering three new papers related to instruction finetuning and parameter-efficient finetuning with LoRA in large language models (LLMs). I work with these methods on a daily basis, so it's always exciting to see new research that provides practical insights.\",\"wordcount\":4043,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[127.5,127.5,127.5],\"population\":0},\"DarkVibrant\":{\"rgb\":[66.3,66.3,66.3],\"population\":0},\"LightVibrant\":{\"rgb\":[188.7,188.7,188.7],\"population\":0},\"Muted\":{\"rgb\":[124,124,124],\"population\":135},\"DarkMuted\":{\"rgb\":[66,66,66],\"population\":7},\"LightMuted\":{\"rgb\":[188,188,188],\"population\":65}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":80,\"comment_count\":9,\"child_comment_count\":3,\"audio_items\":[{\"post_id\":145134347,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/145134347/tts/b77fa56d-96a2-4f87-b365-df7cd4c39fb1/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":144110727,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?\",\"social_title\":\"How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"how-good-are-the-latest-open-llms\",\"post_date\":\"2024-05-12T11:02:46.703Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":120},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Discussing the Latest Model Releases and AI Research in April 2024\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/399d678a-7dbf-4533-874c-7300fb03830e_1034x610.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":144110727,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Discussing the Latest Model Releases and AI Research in April 2024\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"April 2024, what a month! My birthday, a new book release, spring is finally here, and four major open LLM releases: Mixtral, Meta AI's Llama 3, Microsoft's Phi-3, and Apple's OpenELM.\",\"wordcount\":5326,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[252,137,52],\"population\":3},\"DarkVibrant\":{\"rgb\":[4,76,132],\"population\":8},\"LightVibrant\":{\"rgb\":[246,196,152],\"population\":13},\"Muted\":{\"rgb\":[115,150,176],\"population\":10},\"DarkMuted\":{\"rgb\":[80,76,68],\"population\":2},\"LightMuted\":{\"rgb\":[156,188,204],\"population\":8}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":120,\"comment_count\":4,\"child_comment_count\":2,\"audio_items\":[{\"post_id\":144110727,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/144110727/tts/cbe2afdb-8d4b-4390-9b24-1098e846c012/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":143687732,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Using and Finetuning Pretrained Transformers\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"using-and-finetuning-pretrained-transformers\",\"post_date\":\"2024-04-20T11:02:21.015Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/using-and-finetuning-pretrained-transformers\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":126},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/9a2f144c-3665-4f77-81bb-9bbbbbe756b6_1604x1224.jpeg\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":143687732,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"What are the different ways to use and finetune pretrained large language models (LLMs)?\u00A0The most common ways to use and finetune pretrained LLMs include a feature-based approach, in-context prompting, and updating a subset of the model parameters.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This week has been filled with developments, including exciting new AI research that I\u2019ll be discussing in my usual end-of-month write-ups.\",\"wordcount\":3396,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[16,165,252],\"population\":91},\"DarkVibrant\":{\"rgb\":[10,80,133],\"population\":173},\"LightVibrant\":{\"rgb\":[116,204,252],\"population\":1},\"Muted\":{\"rgb\":[94,139,173],\"population\":81},\"DarkMuted\":{\"rgb\":[60,60,60],\"population\":5},\"LightMuted\":{\"rgb\":[131,164,188],\"population\":17}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":126,\"comment_count\":13,\"child_comment_count\":5,\"audio_items\":[{\"post_id\":143687732,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/143687732/tts/31663b91-3ae8-44b8-8959-332e303e0794/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":142924793,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Tips for LLM Pretraining and Evaluating Reward Models\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":\"Discussing Simple and Scalable Strategies to Continually Pre-train Large Language Models and Evaluating Reward Modeling for Language Modeling.\",\"type\":\"newsletter\",\"slug\":\"tips-for-llm-pretraining-and-evaluating-rms\",\"post_date\":\"2024-03-31T11:02:29.688Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":142},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"subtitle\":\"Discussing AI Research Papers in March 2024\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!stc4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fabd9ec-29f1-4c1c-85fb-8781e7c6ce0b_1600x436.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":142924793,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Discussing AI Research Papers in March 2024\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It's another month in AI research, and it's hard to pick favorites.\",\"wordcount\":5099,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[249,98,75],\"population\":87},\"DarkVibrant\":{\"rgb\":[175,68,53],\"population\":14},\"LightVibrant\":{\"rgb\":[148,212,252],\"population\":355},\"Muted\":{\"rgb\":[95,133,160],\"population\":31},\"DarkMuted\":{\"rgb\":[92,48,45],\"population\":10},\"LightMuted\":{\"rgb\":[195,172,196],\"population\":349}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":142,\"comment_count\":16,\"child_comment_count\":9,\"audio_items\":[{\"post_id\":142924793,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/142924793/tts/98044847-f8b9-4395-911c-fbd39dd0af1e/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false}],\"numRecommendations\":13,\"pinnedPosts\":[{\"id\":168650848,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The Big LLM Architecture Comparison\",\"social_title\":\"The Big LLM Architecture Comparison\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"the-big-llm-architecture-comparison\",\"post_date\":\"2025-07-19T11:11:10.901Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[1174659],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1181},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":1,\"subtitle\":\"From DeepSeek-V3 to gpt-oss: A Look At Modern LLM Architecture Design\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":168650848,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"From DeepSeek-V3 to Kimi K2: A Look At Modern LLM Architecture Design\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It has been seven years since the original GPT architecture was developed. At first glance, looking back at GPT-2 (2019) and forward to DeepSeek-V3 and Llama 4 (2024-2025), one might be surprised at how structurally similar these models still are.\",\"wordcount\":7249,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":{\"post_id\":168650848,\"starts_at\":\"2025-07-19T11:11:11.298Z\",\"ended_at\":\"2025-07-19T12:11:11.487Z\",\"planned_duration_ms\":3600000,\"test_cohort_percent\":5,\"test_cohort_emailed\":true,\"main_cohort_emailed\":true,\"created_at\":\"2025-07-18T17:48:26.613Z\",\"updated_at\":\"2025-07-19T12:11:26.309Z\",\"creator_id\":27393275,\"ended_early\":false,\"winner_overridden\":false},\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[89,193,146],\"population\":57},\"DarkVibrant\":{\"rgb\":[28,25,68],\"population\":350},\"LightVibrant\":{\"rgb\":[251,228,197],\"population\":9},\"Muted\":{\"rgb\":[100,116,148],\"population\":2},\"DarkMuted\":{\"rgb\":[94,99,128],\"population\":49},\"LightMuted\":{\"rgb\":[189,168,205],\"population\":245}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1181,\"comment_count\":60,\"child_comment_count\":24,\"audio_items\":[{\"post_id\":168650848,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/168650848/tts/582abd24-ce98-43b6-81ac-1339a0d403d5/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false}],\"postsByGroupId\":{},\"recommendations\":[{\"id\":1101061,\"recommended_publication_id\":1092659,\"recommending_publication_id\":1174659,\"created_at\":\"2023-05-11T15:25:32.918Z\",\"updated_at\":\"2023-05-11T15:25:32.918Z\",\"blurb_active\":true,\"description\":\"Hands-down my favorite newsletter for technical deep learning content!\",\"email_sent_at\":\"2023-05-11T16:41:31.050Z\",\"recommendedPublication\":{\"id\":1092659,\"name\":\"Deep (Learning) Focus\",\"subdomain\":\"cameronrwolfe\",\"custom_domain\":null,\"custom_domain_optional\":false,\"hero_text\":\"I contextualize and explain important topics in AI research.\",\"logo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ab9b43fb-52d5-40da-995d-5b7cd3f91064_896x896.png\",\"author_id\":29736521,\"primary_user_id\":29736521,\"theme_var_background_pop\":\"#6C0095\",\"created_at\":\"2022-09-17T15:12:33.160Z\",\"email_from_name\":\"Deep (Learning) Focus\",\"copyright\":\"Cameron R. Wolfe\",\"founding_plan_name\":\"Founding Member\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false,\"author\":{\"id\":29736521,\"name\":\"Cameron R. Wolfe, Ph.D.\",\"handle\":\"cwolferesearch\",\"previous_name\":\"Cameron R. Wolfe\",\"photo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/69aba7df-b571-4609-aa47-fc2d031c11b8_1242x1595.jpeg\",\"bio\":\"Research @ Netflix \u2022 Rice University PhD \u2022 I make AI understandable\",\"profile_set_up_at\":\"2022-09-17T15:11:34.083Z\",\"reader_installed_at\":\"2023-01-10T11:25:00.723Z\"}},\"subscribe_auth_token\":\"eyJwdWJJZHMiOlsxMDkyNjU5XSwiaWF0IjoxNzU4NDg1MzAwLCJleHAiOjE3NTg1NzE3MDAsInN1YiI6InN1YnNjcmliZV9hdXRoX3Rva2VuIn0.gyP-EG-IOTuTspz73iSQ66eHdAHGv3y3LGhHt7KFH_o\"},{\"id\":1282159,\"recommended_publication_id\":1084089,\"recommending_publication_id\":1174659,\"created_at\":\"2023-06-28T14:00:45.447Z\",\"updated_at\":\"2023-06-28T14:00:45.447Z\",\"blurb_active\":false,\"description\":null,\"email_sent_at\":\"2023-06-28T16:19:27.364Z\",\"recommendedPublication\":{\"id\":1084089,\"name\":\"Latent.Space\",\"subdomain\":\"swyx\",\"custom_domain\":\"www.latent.space\",\"custom_domain_optional\":false,\"hero_text\":\"The AI Engineer newsletter + Top 10 US Tech podcast. Exploring AI UX, Agents, Devtools, Infra, Open Source Models. See https://latent.space/about for highlights from Chris Lattner, Andrej Karpathy, George Hotz, Simon Willison, Soumith Chintala et al!\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/73b0838a-bd14-46a1-801c-b6a2046e5c1e_1130x1130.png\",\"author_id\":89230629,\"primary_user_id\":89230629,\"theme_var_background_pop\":\"#0068EF\",\"created_at\":\"2022-09-12T05:38:09.694Z\",\"email_from_name\":\"Latent.Space\",\"copyright\":\"Latent.Space\",\"founding_plan_name\":\"Latent Spacenaut\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"magaziney\",\"is_personal_mode\":false,\"author\":{\"id\":89230629,\"name\":\"Latent.Space\",\"handle\":\"swyx\",\"previous_name\":\"swyx\",\"photo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/703cf3dd-3bab-4f7b-86fa-f4443f15f8a4_152x152.jpeg\",\"bio\":\"Writer, curator, latent space explorer. Main blog: https://swyx.io Devrel/Dev community: https://dx.tips/ Twitter: https://twitter.com/swyx\",\"profile_set_up_at\":\"2022-04-29T22:19:27.544Z\",\"reader_installed_at\":\"2022-12-28T23:31:54.445Z\"}},\"subscribe_auth_token\":\"eyJwdWJJZHMiOlsxMDg0MDg5XSwiaWF0IjoxNzU4NDg1MzAwLCJleHAiOjE3NTg1NzE3MDAsInN1YiI6InN1YnNjcmliZV9hdXRoX3Rva2VuIn0.dT14L5AAaVAO8g3FOU1ficX6aZNTTx_qzSKOYD1vnfY\"},{\"id\":634697,\"recommended_publication_id\":1176501,\"recommending_publication_id\":1174659,\"created_at\":\"2023-01-19T15:48:27.585Z\",\"updated_at\":\"2023-01-19T15:48:27.585Z\",\"blurb_active\":false,\"description\":null,\"email_sent_at\":\"2023-01-19T16:41:01.867Z\",\"recommendedPublication\":{\"id\":1176501,\"name\":\"The Palindrome\",\"subdomain\":\"thepalindrome\",\"custom_domain\":\"thepalindrome.org\",\"custom_domain_optional\":false,\"hero_text\":\"mathematics \u222A machine learning\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/f8b68cf8-d3f4-42f6-b8dd-cccde036005f_720x720.png\",\"author_id\":10322584,\"primary_user_id\":10322584,\"theme_var_background_pop\":\"#9D6FFF\",\"created_at\":\"2022-11-05T19:02:46.937Z\",\"email_from_name\":\"The Palindrome\",\"copyright\":\"Tivadar Danka\",\"founding_plan_name\":\"Founding Member\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false,\"author\":{\"id\":10322584,\"name\":\"Tivadar Danka\",\"handle\":\"tivadardanka\",\"previous_name\":\"Tivadar\",\"photo_url\":\"https://substackcdn.com/image/fetch/$s_!09ow!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3b26cd48-153a-4207-b1e3-e14e1ec8d5e8_400x400.jpeg\",\"bio\":\"Just an Eastern European punk, writing about tech, math, and machine learning. INTJ personality. Chaotic good.\",\"profile_set_up_at\":\"2022-11-05T18:59:57.000Z\",\"reader_installed_at\":\"2022-12-09T10:24:21.362Z\"}},\"subscribe_auth_token\":\"eyJwdWJJZHMiOlsxMTc2NTAxXSwiaWF0IjoxNzU4NDg1MzAwLCJleHAiOjE3NTg1NzE3MDAsInN1YiI6InN1YnNjcmliZV9hdXRoX3Rva2VuIn0.FGIdSdwM9-zDBC3ZaNywaEHSzvw8ZTqH3EV8rSv5V5w\"},{\"id\":581053,\"recommended_publication_id\":1273940,\"recommending_publication_id\":1174659,\"created_at\":\"2023-01-06T13:02:34.335Z\",\"updated_at\":\"2023-01-06T13:02:34.335Z\",\"blurb_active\":false,\"description\":\"I really enjoyed reading the insightful essays that discuss the limitations of current AI language models.\",\"email_sent_at\":\"2023-01-06T13:39:44.723Z\",\"recommendedPublication\":{\"id\":1273940,\"name\":\"AI: A Guide for Thinking Humans\",\"subdomain\":\"aiguide\",\"custom_domain\":null,\"custom_domain_optional\":false,\"hero_text\":\"I write about interesting new developments in AI.\",\"logo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b8e2ab82-bc00-40f5-9d8b-d818e893dda0_883x883.png\",\"author_id\":15187849,\"primary_user_id\":15187849,\"theme_var_background_pop\":\"#B599F1\",\"created_at\":\"2022-12-30T19:41:21.051Z\",\"email_from_name\":null,\"copyright\":\"Melanie Mitchell\",\"founding_plan_name\":null,\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"disabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false,\"author\":{\"id\":15187849,\"name\":\"Melanie Mitchell\",\"handle\":\"aiguide\",\"previous_name\":null,\"photo_url\":\"https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9546a58b-b372-439d-aa96-9e3b01dbba61_1070x883.jpeg\",\"bio\":\"Melanie Mitchell, Professor at the Santa Fe Institute, is the award-winning author of Artificial Intelligence: A Guide for Thinking Humans. She works in the fields of AI, cognitive science, and complex systems.\",\"profile_set_up_at\":\"2022-12-30T19:40:31.037Z\",\"reader_installed_at\":null}},\"subscribe_auth_token\":\"eyJwdWJJZHMiOlsxMjczOTQwXSwiaWF0IjoxNzU4NDg1MzAwLCJleHAiOjE3NTg1NzE3MDAsInN1YiI6InN1YnNjcmliZV9hdXRoX3Rva2VuIn0.uAfxkkWQBUdU_eSBUDUYkB8USoP3hGHG4F-pEm378fg\"},{\"id\":4458001,\"recommended_publication_id\":48206,\"recommending_publication_id\":1174659,\"created_at\":\"2024-11-05T14:45:02.555Z\",\"updated_at\":\"2024-11-05T14:45:02.555Z\",\"blurb_active\":false,\"description\":\"Good and timely coverage of LLM related happenings with a nice focus on evaluations and RLHF research.\",\"email_sent_at\":\"2024-11-05T15:32:21.004Z\",\"recommendedPublication\":{\"id\":48206,\"name\":\"Interconnects\",\"subdomain\":\"robotic\",\"custom_domain\":\"www.interconnects.ai\",\"custom_domain_optional\":false,\"hero_text\":\"The cutting edge of AI, from inside the frontier AI labs, minus the hype. The border between high-level and technical thinking. Read by leading engineers, researchers, and investors on Wednesday mornings.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/e70f9dbf-4fe6-404c-b6bb-1831d1b7ed0b_590x590.png\",\"author_id\":10472909,\"primary_user_id\":10472909,\"theme_var_background_pop\":\"#ff6b00\",\"created_at\":\"2020-05-21T02:59:47.895Z\",\"email_from_name\":\"Interconnects by Nathan Lambert\",\"copyright\":\"Interconnects AI, LLC\",\"founding_plan_name\":\"Founding Member\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false,\"author\":{\"id\":10472909,\"name\":\"Nathan Lambert\",\"handle\":\"natolambert\",\"previous_name\":null,\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8fedcdfb-e137-4f6a-9089-a46add6c6242_500x500.jpeg\",\"bio\":\"ML researcher making sense of AI research, products, and the uncertain technological future. PhD from Berkeley AI. Experience at Meta, DeepMind, HuggingFace.\",\"profile_set_up_at\":\"2021-04-24T01:19:33.371Z\",\"reader_installed_at\":\"2022-03-09T17:52:30.690Z\"}},\"subscribe_auth_token\":\"eyJwdWJJZHMiOls0ODIwNl0sImlhdCI6MTc1ODQ4NTMwMCwiZXhwIjoxNzU4NTcxNzAwLCJzdWIiOiJzdWJzY3JpYmVfYXV0aF90b2tlbiJ9.Y-wo9TCz0KDcZxhGn7FbmVpdHOKehN-kyuvQTvOs7do\"}],\"topPosts\":[{\"id\":168650848,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The Big LLM Architecture Comparison\",\"social_title\":\"The Big LLM Architecture Comparison\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"the-big-llm-architecture-comparison\",\"post_date\":\"2025-07-19T11:11:10.901Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[1174659],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1181},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":1,\"subtitle\":\"From DeepSeek-V3 to gpt-oss: A Look At Modern LLM Architecture Design\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":168650848,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"From DeepSeek-V3 to Kimi K2: A Look At Modern LLM Architecture Design\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It has been seven years since the original GPT architecture was developed. At first glance, looking back at GPT-2 (2019) and forward to DeepSeek-V3 and Llama 4 (2024-2025), one might be surprised at how structurally similar these models still are.\",\"wordcount\":7249,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":{\"post_id\":168650848,\"starts_at\":\"2025-07-19T11:11:11.298Z\",\"ended_at\":\"2025-07-19T12:11:11.487Z\",\"planned_duration_ms\":3600000,\"test_cohort_percent\":5,\"test_cohort_emailed\":true,\"main_cohort_emailed\":true,\"created_at\":\"2025-07-18T17:48:26.613Z\",\"updated_at\":\"2025-07-19T12:11:26.309Z\",\"creator_id\":27393275,\"ended_early\":false,\"winner_overridden\":false},\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[89,193,146],\"population\":57},\"DarkVibrant\":{\"rgb\":[28,25,68],\"population\":350},\"LightVibrant\":{\"rgb\":[251,228,197],\"population\":9},\"Muted\":{\"rgb\":[100,116,148],\"population\":2},\"DarkMuted\":{\"rgb\":[94,99,128],\"population\":49},\"LightMuted\":{\"rgb\":[189,168,205],\"population\":245}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1181,\"comment_count\":60,\"child_comment_count\":24,\"audio_items\":[{\"post_id\":168650848,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/168650848/tts/582abd24-ce98-43b6-81ac-1339a0d403d5/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":156484949,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Reasoning LLMs\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"understanding-reasoning-llms\",\"post_date\":\"2025-02-05T12:11:39.216Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-reasoning-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1098},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":2,\"subtitle\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!QwUc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6ebc5c9-461f-4d3a-889b-b8ea4e14e5ba_1600x830.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":156484949,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This article describes the four main approaches to building reasoning models, or how we can enhance LLMs with reasoning capabilities. I hope this provides valuable insights and helps you navigate the rapidly evolving literature and hype surrounding this topic.\",\"wordcount\":4028,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[169,25,6],\"population\":87},\"DarkVibrant\":{\"rgb\":[128.0537142857143,18.942857142857143,4.546285714285711],\"population\":0},\"LightVibrant\":{\"rgb\":[252,235,228],\"population\":408},\"Muted\":{\"rgb\":[116,132,148],\"population\":1},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":7},\"LightMuted\":{\"rgb\":[164,188,200],\"population\":2}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1098,\"comment_count\":40,\"child_comment_count\":21,\"audio_items\":[{\"post_id\":156484949,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/156484949/tts/410051a7-e938-4017-8671-68e5f1fae779/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":140464659,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding and Coding Self-Attention, Multi-Head Attention, Causal-Attention, and Cross-Attention in LLMs\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":\"This article codes the self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama from scratch in PyTorch.\",\"type\":\"newsletter\",\"slug\":\"understanding-and-coding-self-attention\",\"post_date\":\"2024-01-14T11:55:06.449Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":386},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":3,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":140464659,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama. Self-attention and related mechanisms are core components of LLMs, making them a useful topic to understand when working with these models.\",\"wordcount\":4738,\"postTags\":[{\"id\":\"2e792e1c-c4e1-4a7c-a303-bdac25c1f3a8\",\"publication_id\":1174659,\"name\":\"Vision Transformers\",\"slug\":\"vision-transformers\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[172,144,204],\"population\":2},\"DarkVibrant\":{\"rgb\":[64.66296296296294,41.74444444444444,90.85555555555557],\"population\":0},\"LightVibrant\":{\"rgb\":[204,173,241],\"population\":13},\"Muted\":{\"rgb\":[104,104,128],\"population\":2},\"DarkMuted\":{\"rgb\":[102,97,112],\"population\":6},\"LightMuted\":{\"rgb\":[178,212,212],\"population\":5}},\"publishedBylines\":[],\"reaction\":false,\"reaction_count\":386,\"comment_count\":41,\"child_comment_count\":18,\"audio_items\":[{\"post_id\":140464659,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":115060492,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Large Language Models\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":\"Explore the transformative power of large language models in AI. Dive into a curated reading list for ML enthusiasts. Discover the impact of transformers on NLP, vision, and biology.\",\"type\":\"newsletter\",\"slug\":\"understanding-large-language-models\",\"post_date\":\"2023-04-16T12:33:46.854Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-large-language-models\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":922},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":4,\"subtitle\":\"A Cross-Section of the Most Relevant Literature To Get Up to Speed\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/d9a0766d-2e52-4af0-96c5-3e07a30d6ecb_1868x1130.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":115060492,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"A Cross-Section of the Most Relevant Literature To Get Up to Speed\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"Large language models have taken the public attention by storm \u2013 no pun intended. In just half a decade large language models \u2013 transformers \u2013 have almost completely changed the field of natural language processing. Moreover, they have also begun to revolutionize fields such as computer vision and computational biology.\",\"wordcount\":3347,\"postTags\":[],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[172,120,228],\"population\":6},\"DarkVibrant\":{\"rgb\":[64.66296296296302,22.100000000000016,110.49999999999999],\"population\":0},\"LightVibrant\":{\"rgb\":[188,148,236],\"population\":1},\"Muted\":{\"rgb\":[148,116,188],\"population\":1},\"DarkMuted\":{\"rgb\":[116,108,108],\"population\":1},\"LightMuted\":{\"rgb\":[204,204,164],\"population\":2}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":922,\"comment_count\":53,\"child_comment_count\":25,\"audio_items\":[{\"post_id\":115060492,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/115060492/tts/1c050ea7-59a1-42f7-aae5-0db5e030919e/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":170506328,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"From GPT-2 to gpt-oss: Analyzing the Architectural Advances\",\"social_title\":\"From GPT-2 to gpt-oss: Analyzing the Architectural Advances\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"from-gpt-2-to-gpt-oss-analyzing-the\",\"post_date\":\"2025-08-09T11:23:07.237Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":563},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":5,\"subtitle\":\"And How They Stack Up Against Qwen3\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/529c4cc7-161c-4d7c-b186-06e68c771776_1564x926.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":170506328,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"And How They Stack Up Against Qwen3\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"OpenAI just released their new open-weight LLMs this week: gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019. And yes, thanks to some clever optimizations, they can run locally (but more about this later).\",\"wordcount\":5221,\"postTags\":[{\"id\":\"5cf0ea83-392e-495a-9745-dc0aaa7f7d4f\",\"publication_id\":1174659,\"name\":\"Reasoning Models\",\"slug\":\"reasoning-models\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[92,199,180],\"population\":16},\"DarkVibrant\":{\"rgb\":[33.90684931506849,98.69315068493151,87.18904109589042],\"population\":0},\"LightVibrant\":{\"rgb\":[135,164,235],\"population\":14},\"Muted\":{\"rgb\":[100,116,148],\"population\":1},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":5},\"LightMuted\":{\"rgb\":[135,188,181],\"population\":318}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":563,\"comment_count\":45,\"child_comment_count\":23,\"audio_items\":[{\"post_id\":170506328,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/170506328/tts/d2f3c50e-08e5-4c36-a942-d3a52acf3214/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":138081202,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation)\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"practical-tips-for-finetuning-llms\",\"post_date\":\"2023-11-19T12:11:26.382Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":295},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":6,\"subtitle\":\"Things I Learned From Hundreds of Experiments\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!i3QH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dfbd169-eb7e-41e1-a050-556ccd6fb679_1600x672.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":138081202,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Things I Learned From Hundreds of Experiments\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"Low-rank adaptation (LoRA) is among the most widely used and effective techniques for efficiently training custom LLMs. For those interested in open-source LLMs, it's an essential technique worth familiarizing oneself with.\",\"wordcount\":3592,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[5,116,187],\"population\":193},\"DarkVibrant\":{\"rgb\":[4,100,156],\"population\":1},\"LightVibrant\":{\"rgb\":[169,203,227],\"population\":40},\"Muted\":{\"rgb\":[127,127,127],\"population\":68},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":4},\"LightMuted\":{\"rgb\":[188,188,188],\"population\":42}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":295,\"comment_count\":48,\"child_comment_count\":20,\"audio_items\":[{\"post_id\":138081202,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/138081202/tts/947b81e4-5402-4fa3-b078-19b86a1b0a74/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":151078631,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Multimodal LLMs\",\"social_title\":\"Understanding Multimodal LLMs\",\"search_engine_title\":null,\"search_engine_description\":\"An introduction to the main multimodal LLM techniques and latest models\",\"type\":\"newsletter\",\"slug\":\"understanding-multimodal-llms\",\"post_date\":\"2024-11-03T12:44:00.421Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-multimodal-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":540},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":7,\"subtitle\":\"An introduction to the main techniques and latest models\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/c534f387-f776-41eb-9c65-f0032b91daee_1988x1430.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":151078631,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"An introduction to the main techniques and latest models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It was a wild two months. There have once again been many developments in AI research, with two Nobel Prizes awarded to AI and several interesting research papers published.\",\"wordcount\":4421,\"postTags\":[{\"id\":\"1496f84a-084b-4bf8-9930-a33eca71b372\",\"publication_id\":1174659,\"name\":\"Computer Vision\",\"slug\":\"computer-vision\",\"hidden\":false},{\"id\":\"2e792e1c-c4e1-4a7c-a303-bdac25c1f3a8\",\"publication_id\":1174659,\"name\":\"Vision Transformers\",\"slug\":\"vision-transformers\",\"hidden\":false},{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[180,22,5],\"population\":151},\"DarkVibrant\":{\"rgb\":[4,116,188],\"population\":58},\"LightVibrant\":{\"rgb\":[197,222,239],\"population\":75},\"Muted\":{\"rgb\":[145,103,93],\"population\":24},\"DarkMuted\":{\"rgb\":[98,73,50],\"population\":17},\"LightMuted\":{\"rgb\":[207,178,173],\"population\":41}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":540,\"comment_count\":57,\"child_comment_count\":28,\"audio_items\":[{\"post_id\":151078631,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/151078631/tts/1548c000-1339-4ad7-9834-b5616d93e113/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":162934205,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Coding LLMs from the Ground Up: A Complete Course\",\"social_title\":\"Coding LLMs from the Ground Up: A Complete Course\",\"search_engine_title\":null,\"search_engine_description\":\"Why build an LLM from scratch? It's probably the best and most efficient way to learn how LLMs really work. Plus, many readers have told me they had a lot of fun doing it.\",\"type\":\"newsletter\",\"slug\":\"coding-llms-from-the-ground-up\",\"post_date\":\"2025-05-10T11:03:17.769Z\",\"audience\":\"only_paid\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":true,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/coding-llms-from-the-ground-up\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":233},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":8,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/752b6486-73db-4293-9465-854d4a005a5c_2406x1350.jpeg\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":null,\"videoUpload\":null,\"podcastFields\":{\"post_id\":162934205,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Why build LLMs from scratch? It's probably the best and most efficient way to learn how LLMs really work. Plus, many readers have told me they had a lot of fun doing it.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"I wrote a lot about reasoning models in recent months (4 articles in a row)! Next to everything \\\"agentic,\\\" reasoning is one of the biggest LLM topics of 2025.\",\"wordcount\":997,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":false,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[57.24489795918357,130.10204081632648,197.75510204081644],\"population\":0},\"DarkVibrant\":{\"rgb\":[29.767346938775457,67.65306122448978,102.83265306122455],\"population\":0},\"LightVibrant\":{\"rgb\":[217,231,244],\"population\":9},\"Muted\":{\"rgb\":[108,116,132],\"population\":2},\"DarkMuted\":{\"rgb\":[52,52,52],\"population\":5},\"LightMuted\":{\"rgb\":[156,180,204],\"population\":110}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":233,\"comment_count\":4,\"child_comment_count\":3,\"audio_items\":[{\"post_id\":162934205,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":null,\"type\":\"tts\",\"status\":\"paywalled\"}],\"is_geoblocked\":false,\"hidden\":true,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":148329414,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Building LLMs from the Ground Up: A 3-hour Coding Workshop\",\"social_title\":\"Building LLMs from the Ground Up: A 3-hour Coding Workshop\",\"search_engine_title\":null,\"search_engine_description\":\"A 3-hour coding workshop presentation on implementing, training, and using LLMs.\",\"type\":\"newsletter\",\"slug\":\"building-llms-from-the-ground-up\",\"post_date\":\"2024-08-31T10:39:35.940Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":433},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":9,\"subtitle\":\"\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/367b547c-9d22-4a3d-b466-1d56ccc6b055_1844x1224.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":148329414,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"If your weekend plans include catching up on AI developments and understanding Large Language Models (LLMs), I've prepared a 1-hour presentation on the development cycle of LLMs, covering everything from architectural implementation to the finetuning stages.\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"If you\u2019d like to spend a few hours this weekend to dive into Large Language Models (LLMs) and understand how they work, I've prepared a 3-hour coding workshop presentation on implementing, training, and using LLMs.\",\"wordcount\":343,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"b0939572-2637-42f9-8d08-9792c2228a8c\",\"publication_id\":1174659,\"name\":\"PyTorch\",\"slug\":\"pytorch\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[204,124,164],\"population\":34},\"DarkVibrant\":{\"rgb\":[64,40,20],\"population\":2},\"LightVibrant\":{\"rgb\":[236,143,189],\"population\":45},\"Muted\":{\"rgb\":[101,130,152],\"population\":17},\"DarkMuted\":{\"rgb\":[84,44,72],\"population\":2},\"LightMuted\":{\"rgb\":[167,178,191],\"population\":23}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":433,\"comment_count\":16,\"child_comment_count\":11,\"audio_items\":[{\"post_id\":148329414,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/148329414/tts/ead5fd00-a385-4a95-a7dc-9ff942b29fb3/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false}]},\"maybeLaunchWelcomePage\":true,\"topThreePosts\":[{\"id\":168650848,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"The Big LLM Architecture Comparison\",\"social_title\":\"The Big LLM Architecture Comparison\",\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"the-big-llm-architecture-comparison\",\"post_date\":\"2025-07-19T11:11:10.901Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[1174659],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1181},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":1,\"subtitle\":\"From DeepSeek-V3 to gpt-oss: A Look At Modern LLM Architecture Design\",\"cover_image\":\"https://substack-post-media.s3.amazonaws.com/public/images/45c50202-0e8b-4e64-8296-4e2ccf4cb287_1756x1227.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":168650848,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"From DeepSeek-V3 to Kimi K2: A Look At Modern LLM Architecture Design\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"It has been seven years since the original GPT architecture was developed. At first glance, looking back at GPT-2 (2019) and forward to DeepSeek-V3 and Llama 4 (2024-2025), one might be surprised at how structurally similar these models still are.\",\"wordcount\":7249,\"postTags\":[{\"id\":\"3c6fd695-d92d-4589-888a-ce59b6cebe46\",\"publication_id\":1174659,\"name\":\"Deep Learning\",\"slug\":\"deep-learning\",\"hidden\":false},{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"67aecb81-dcbe-4fed-8c4a-eee7d97c5bb0\",\"publication_id\":1174659,\"name\":\"Machine Learning\",\"slug\":\"machine-learning\",\"hidden\":false},{\"id\":\"6e0b1665-018b-43ee-a244-f438573378e1\",\"publication_id\":1174659,\"name\":\"Attention\",\"slug\":\"attention\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false},{\"id\":\"e904cab3-967f-4c2e-bda2-b44d159bc31d\",\"publication_id\":1174659,\"name\":\"Open-Source\",\"slug\":\"open-source\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":{\"post_id\":168650848,\"starts_at\":\"2025-07-19T11:11:11.298Z\",\"ended_at\":\"2025-07-19T12:11:11.487Z\",\"planned_duration_ms\":3600000,\"test_cohort_percent\":5,\"test_cohort_emailed\":true,\"main_cohort_emailed\":true,\"created_at\":\"2025-07-18T17:48:26.613Z\",\"updated_at\":\"2025-07-19T12:11:26.309Z\",\"creator_id\":27393275,\"ended_early\":false,\"winner_overridden\":false},\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[89,193,146],\"population\":57},\"DarkVibrant\":{\"rgb\":[28,25,68],\"population\":350},\"LightVibrant\":{\"rgb\":[251,228,197],\"population\":9},\"Muted\":{\"rgb\":[100,116,148],\"population\":2},\"DarkMuted\":{\"rgb\":[94,99,128],\"population\":49},\"LightMuted\":{\"rgb\":[189,168,205],\"population\":245}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1181,\"comment_count\":60,\"child_comment_count\":24,\"audio_items\":[{\"post_id\":168650848,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/168650848/tts/582abd24-ce98-43b6-81ac-1339a0d403d5/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false},{\"id\":156484949,\"editor_v2\":false,\"publication_id\":1174659,\"title\":\"Understanding Reasoning LLMs\",\"social_title\":null,\"search_engine_title\":null,\"search_engine_description\":null,\"type\":\"newsletter\",\"slug\":\"understanding-reasoning-llms\",\"post_date\":\"2025-02-05T12:11:39.216Z\",\"audience\":\"everyone\",\"podcast_duration\":null,\"video_upload_id\":null,\"podcast_upload_id\":null,\"write_comment_permissions\":\"everyone\",\"should_send_free_preview\":false,\"free_unlock_required\":false,\"default_comment_sort\":null,\"canonical_url\":\"https://magazine.sebastianraschka.com/p/understanding-reasoning-llms\",\"section_id\":null,\"top_exclusions\":[],\"pins\":[],\"is_section_pinned\":false,\"section_slug\":null,\"section_name\":null,\"reactions\":{\"\u2764\":1098},\"restacked_post_id\":null,\"restacked_post_slug\":null,\"restacked_pub_name\":null,\"restacked_pub_logo_url\":null,\"position\":2,\"subtitle\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"cover_image\":\"https://substackcdn.com/image/fetch/$s_!QwUc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6ebc5c9-461f-4d3a-889b-b8ea4e14e5ba_1600x830.png\",\"cover_image_is_square\":false,\"cover_image_is_explicit\":false,\"podcast_url\":\"\",\"videoUpload\":null,\"podcastFields\":{\"post_id\":156484949,\"podcast_episode_number\":null,\"podcast_season_number\":null,\"podcast_episode_type\":null,\"should_syndicate_to_other_feed\":null,\"syndicate_to_section_id\":null,\"hide_from_feed\":false,\"free_podcast_url\":null,\"free_podcast_duration\":null},\"podcast_preview_upload_id\":null,\"podcastUpload\":null,\"podcastPreviewUpload\":null,\"voiceover_upload_id\":null,\"voiceoverUpload\":null,\"has_voiceover\":false,\"description\":\"Methods and Strategies for Building and Refining Reasoning Models\",\"body_json\":null,\"body_html\":null,\"truncated_body_text\":\"This article describes the four main approaches to building reasoning models, or how we can enhance LLMs with reasoning capabilities. I hope this provides valuable insights and helps you navigate the rapidly evolving literature and hype surrounding this topic.\",\"wordcount\":4028,\"postTags\":[{\"id\":\"5e263784-abbd-4549-a8c3-69a981a6c7f2\",\"publication_id\":1174659,\"name\":\"AI\",\"slug\":\"ai\",\"hidden\":false},{\"id\":\"6fc1db5b-5505-4e83-8cc9-00977c4f24e3\",\"publication_id\":1174659,\"name\":\"AI Research\",\"slug\":\"ai-research\",\"hidden\":false},{\"id\":\"c396248a-8283-4a1c-90cb-4cc6677a0260\",\"publication_id\":1174659,\"name\":\"Large language models\",\"slug\":\"large-language-models\",\"hidden\":false},{\"id\":\"d363cca5-e117-4aed-8ef4-0c07863fea32\",\"publication_id\":1174659,\"name\":\"LLMs\",\"slug\":\"llms\",\"hidden\":false}],\"teaser_post_eligible\":true,\"postCountryBlocks\":[],\"headlineTest\":null,\"coverImagePalette\":{\"Vibrant\":{\"rgb\":[169,25,6],\"population\":87},\"DarkVibrant\":{\"rgb\":[128.0537142857143,18.942857142857143,4.546285714285711],\"population\":0},\"LightVibrant\":{\"rgb\":[252,235,228],\"population\":408},\"Muted\":{\"rgb\":[116,132,148],\"population\":1},\"DarkMuted\":{\"rgb\":[68,68,68],\"population\":7},\"LightMuted\":{\"rgb\":[164,188,200],\"population\":2}},\"publishedBylines\":[{\"id\":27393275,\"name\":\"Sebastian Raschka, PhD\",\"handle\":\"rasbt\",\"previous_name\":\"Sebastian Raschka\",\"photo_url\":\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F61f4c017-506f-4e9b-a24f-76340dad0309_800x800.jpeg\",\"bio\":\"I'm an LLM research engineer 10+ years of experience in artificial intelligence. My expertise lies in AI & LLM research focusing on code-driven implementations. I am also the author of \\\"Build a Large Language Model From Scratch\\\" (amzn.to/4fqvn0D).\",\"profile_set_up_at\":\"2022-10-09T16:19:59.744Z\",\"reader_installed_at\":\"2022-11-07T19:56:32.129Z\",\"publicationUsers\":[{\"id\":1127862,\"user_id\":27393275,\"publication_id\":1174659,\"role\":\"admin\",\"public\":true,\"is_primary\":true,\"publication\":{\"id\":1174659,\"name\":\"Ahead of AI\",\"subdomain\":\"sebastianraschka\",\"custom_domain\":\"magazine.sebastianraschka.com\",\"custom_domain_optional\":false,\"hero_text\":\"Ahead of AI specializes in Machine Learning & AI research and is read by tens of thousands of researchers and practitioners who want to stay ahead in the ever-evolving field.\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/49f25d0a-212b-4853-8bcb-128d0a3edbbf_1196x1196.png\",\"author_id\":27393275,\"primary_user_id\":27393275,\"theme_var_background_pop\":\"#2096FF\",\"created_at\":\"2022-11-04T18:30:05.218Z\",\"email_from_name\":null,\"copyright\":\"Raschka AI Research (RAIR) Lab LLC\",\"founding_plan_name\":\"Founding plan\",\"community_enabled\":true,\"invite_only\":false,\"payments_state\":\"enabled\",\"language\":null,\"explicit\":false,\"homepage_type\":\"newspaper\",\"is_personal_mode\":false}}],\"twitter_screen_name\":\"rasbt\",\"is_guest\":false,\"bestseller_tier\":100,\"status\":{\"bestsellerTier\":100,\"subscriberTier\":1,\"leaderboard\":null,\"vip\":false,\"badge\":{\"type\":\"bestseller\",\"tier\":100}}}],\"reaction\":false,\"reaction_count\":1098,\"comment_count\":40,\"child_comment_count\":21,\"audio_items\":[{\"post_id\":156484949,\"voice_id\":\"en-US-OnyxTurboMultilingualNeural\",\"audio_url\":\"https://substack-video.s3.amazonaws.com/video_upload/post/156484949/tts/410051a7-e938-4017-8671-68e5f1fae779/en-US-OnyxTurboMultilingualNeural.mp3\",\"type\":\"tts\",\"status\":\"completed\"}],\"is_geoblocked\":false,\"hasCashtag\":false,\"is_saved\":false,\"saved_at\":null,\"is_viewed\":false,\"read_progress\":0,\"max_read_progress\":0,\"audio_progress\":0,\"max_audio_progress\":0,\"video_progress\":0,\"max_video_progress\":0,\"restacked\":false}],\"topThreeSubscribers\":[{\"id\":2007748,\"name\":\"Olivier Ziller\",\"photo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/8191e859-21ae-4495-bf56-59156580ac72_96x96.png\",\"bestseller_tier\":null,\"primary_publication\":{\"id\":4455692,\"subdomain\":\"olivierziller734764\",\"custom_domain_optional\":false,\"name\":\"Olivier Ziller\",\"author_id\":2007748,\"user_id\":2007748,\"handles_enabled\":false,\"explicit\":false,\"is_personal_mode\":false,\"payments_state\":\"disabled\",\"pledges_enabled\":true},\"is_subscribed\":false},{\"id\":2080303,\"name\":\"Sugato Ray\",\"photo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/46d1bee2-5f77-4abd-91ba-2ffb6ce5b6cc_1284x1282.jpeg\",\"bestseller_tier\":null,\"primary_publication\":{\"id\":1135033,\"subdomain\":\"sugatoray\",\"custom_domain_optional\":false,\"name\":\"Sugato\u2019s Newsletter\",\"author_id\":2080303,\"user_id\":2080303,\"handles_enabled\":false,\"explicit\":false,\"is_personal_mode\":false,\"payments_state\":\"disabled\",\"pledges_enabled\":true},\"is_subscribed\":false},{\"id\":2712973,\"name\":\"Bernardo Neves\",\"photo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/f35cb4d1-0d20-4ddd-b2d7-8a9623188daa_1664x1664.png\",\"bestseller_tier\":null,\"primary_publication\":{\"id\":3672612,\"subdomain\":\"prescriptionai\",\"custom_domain_optional\":false,\"name\":\"Prescription AI\",\"logo_url\":\"https://substack-post-media.s3.amazonaws.com/public/images/b7226ab9-79f0-4875-976d-05b167b6e56c_1024x1024.png\",\"author_id\":2712973,\"user_id\":2712973,\"handles_enabled\":false,\"explicit\":false,\"is_personal_mode\":false,\"payments_state\":\"enabled\",\"pledges_enabled\":false},\"is_subscribed\":false}],\"twitterCardUrl\":null,\"activeLiveStream\":null,\"freeTrialCoupon\":null,\"isChatActive\":false,\"isMeetingsActive\":false,\"hasViralGiftsCount\":0,\"iba\":false,\"features\":{},\"browser\":{\"name\":\"Chrome\",\"version\":\"140.0.0.0\",\"major\":\"140\"},\"showCookieBanner\":false,\"disabledCookies\":[],\"dd_env\":\"prod\",\"dd_ti\":true}")</script>
        <script>window._analyticsConfig = JSON.parse("{\"anonymousId\":\"acef0839-2611-45cc-ab3b-ce6483a56022\",\"properties\":{\"subdomain\":\"sebastianraschka\",\"publication_id\":1174659,\"has_plans\":true,\"pub_community_enabled\":true,\"is_personal_publication\":false,\"is_subscribed\":false,\"is_free_subscribed\":false,\"is_author\":false,\"is_contributor\":false,\"is_admin\":false,\"is_founding\":false,\"country\":\"IN\",\"language\":\"en\"},\"adwordsAccountId\":\"AW-316245675\",\"adwordsEventSendTo\":\"Tf76CKqcyL4DEKuN5pYB\"}")</script>

        
        
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8909.2cd480ea.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2199.5f552266.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8546.e24694b7.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2020.01118b77.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5621.0f954901.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4490.70115a71.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/881.17a1b129.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9106.5a053775.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5977.e8fdd0e5.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1832.1b6d6095.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6722.99f03731.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/247.b024ec59.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8438.d892045d.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7491.7d7275c8.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/76.68b85afd.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8206.c027e28b.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/main.2f5c3c95.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/540.48305f0f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2013.78bb41a5.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1553.a169fcec.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8665.6d3fde9f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6400.58c45c46.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/828.471f75be.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9335.d48205f9.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6371.a9a82180.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1797.abe73545.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2250.76b28e19.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4511.273a77df.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7833.aed8ad3f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1481.ca002e3f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9294.960be875.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7248.f0da3333.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9601.706f3481.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4121.0de680ac.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/236.50c1d138.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8336.23f1718a.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2736.1a64d68d.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8491.f6cc4a9e.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5790.4f8dd4a8.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4903.bd262ac4.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9669.41147939.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6163.1db4d192.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9923.3d24f4ff.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1484.8ed70740.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8618.2a44cf5f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9609.17e84027.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8041.0e22e6a7.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6225.47ee0d5e.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5758.1a205ca5.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6247.078b07a1.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9366.d3c0286f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4163.c990856e.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1262.33c17ad0.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2768.41ca10b2.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7913.673eeb90.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1076.e716f4fe.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2344.ec68af70.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3451.d0ad0bd5.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8549.dce26afd.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1333.d399a473.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2341.cd432220.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2909.97509e9d.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8915.9972e506.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6364.29606904.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4036.033a5f72.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/221.6a595268.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2779.c2bec061.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1482.1a779c15.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/907.64fff851.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5924.78fb1361.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2035.58660d40.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4388.1d6b35ab.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8381.15d661d8.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1697.16cf9de0.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2889.e27ae69a.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1354.47971ce3.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2291.f09a5dde.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/546.1e81f03f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9760.3b93fbba.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7065.18c0dbcf.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/6042.8ebed607.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/8038.010acf71.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4405.88ee6abc.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3324.e3ed73f8.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/9124.59032715.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3414.c27139fa.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7541.c14a4f48.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7797.cda2dec6.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/4278.ca482e8f.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/7424.95847c04.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3191.b5bcd62d.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/2044.cc604cb5.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/3961.b9d0d3a1.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/1421.52f2b09a.js.download" charset="utf-8"></script>
            
                <script defer="" type="module" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/5581.21b7568d.js.download" charset="utf-8"></script>
            
        
        <script nomodule="">
            (function() {
                var message = 'Your browser does not support modern JavaScript modules. Please upgrade your browser for the best experience.';
                var warningDiv = document.createElement('div');
                warningDiv.style.color = 'red';
                warningDiv.style.padding = '10px';
                warningDiv.style.margin = '10px 0';
                warningDiv.style.border = '1px solid red';
                warningDiv.style.backgroundColor = 'lightyellow';
                warningDiv.innerText = message;
                document.body.prepend(warningDiv);
            })();
        </script>

        
            <!-- Datadog Analytics -->
            <script>
              (function(h,o,u,n,d) {
                h=h[d]=h[d]||{q:[],onReady:function(c){h.q.push(c)}}
                d=o.createElement(u);d.async=1;d.src=n
                n=o.getElementsByTagName(u)[0];n.parentNode.insertBefore(d,n)
              })(window,document,'script','https://www.datadoghq-browser-agent.com/us1/v5/datadog-rum.js','DD_RUM')
              window.DD_RUM.onReady(function() {
                window.DD_RUM.init({
                  clientToken: 'puba71073f072643721169b68f352438710',
                  applicationId: '2e321b35-c76b-4073-8d04-cc9a10461793',
                  site: 'datadoghq.com',
                  service: 'substack-web',
                  env: window._preloads.dd_env,
                  version: '5b5ec257d2826e0dd7cbc7c88ae99980ebfdf815',
                  sessionSampleRate: 1,
                  sessionReplaySampleRate: 100,
                  trackUserInteractions: window._preloads.dd_ti,
                  trackResources: true,
                  trackLongTasks: true,
                  defaultPrivacyLevel: 'mask-user-input',
                  allowedTracingUrls: [/https?:\/\/(.+\/.)?substack(cdn)?\.com/]
                });
              })
            </script>
            <!-- End Datadog Analytics -->

            <!-- Cloudflare Web Analytics -->
            <script defer="" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/beacon.min.js.download" data-cf-beacon="{&quot;token&quot;: &quot;216309cffb464db4b0e02daf0b8e8060&quot;}"></script>
            <!-- End Cloudflare Web Analytics -->
        

        <!-- Fallback tracking pixels -->
        

        

        <noscript>
    <style>
        #nojs-banner {
            position: fixed;
            bottom: 0;
            left: 0;
            padding: 16px 16px 16px 32px;
            width: 100%;
            box-sizing: border-box;
            background: red;
            color: white;
            font-family: -apple-system, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            font-size: 13px;
            line-height: 13px;
        }
        #nojs-banner a {
            color: inherit;
            text-decoration: underline;
        }
    </style>

    <div id="nojs-banner">
        This site requires JavaScript to run correctly. Please <a href="https://enable-javascript.com/" target="_blank">turn on JavaScript</a> or unblock scripts
    </div>
</noscript>


        

        

        
        
    <script defer="" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon="{&quot;rayId&quot;:&quot;982c31a50b1414c8&quot;,&quot;serverTiming&quot;:{&quot;name&quot;:{&quot;cfExtPri&quot;:true,&quot;cfEdge&quot;:true,&quot;cfOrigin&quot;:true,&quot;cfL4&quot;:true,&quot;cfSpeedBrain&quot;:true,&quot;cfCacheStatus&quot;:true}},&quot;version&quot;:&quot;2025.9.1&quot;,&quot;token&quot;:&quot;68cfe66b5c4749e2ba64d4d9640c04c0&quot;}" crossorigin="anonymous"></script><iframe height="0" width="0" style="display: none; visibility: hidden;" src="./From GPT-2 to gpt-oss_ Analyzing the Architectural Advances_files/saved_resource(2).html"></iframe>


</body></html>